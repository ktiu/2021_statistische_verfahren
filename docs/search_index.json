[["index.html", "Statistische Verfahren in der Geographie Inhalt Terminüberblick Formelsammlung und Wertetabellen", " Statistische Verfahren in der Geographie Till Straube Institut für Humangeographie Goethe-Universität Frankfurtstraube@geo.uni-frankfurt.de Sommersemester 2021 Inhalt Terminüberblick Alle Sitzungen finden von 14 bis 16h c.t. statt Datum Sitzung Inhalt 13. April 2021 1 Datenerhebung und Häufigkeiten 20. April 2021 2 Maßzahlen 27. April 2021 3 z-Werte und Normalverteilung 04. Mai 2021 4 Schätzstatistik 11. Mai 2021 5 Grundlagen der Teststatistik 18. Mai 2021 6 Testverfahren mit zwei Stichproben 25. Mai 2021 7 Korrelation 01. Juni 2021 8 Lineare Regression 08. Juni 2021 9 Kreuztabellen 15. Juni 2021 10 Chi-Quadrat-Tests Formelsammlung und Wertetabellen Formelsammlung und Wertetabellen (PDF) "],["datenerhebung-und-häufigkeiten.html", "Sitzung 1 Datenerhebung und Häufigkeiten 1.1 Lernziele dieser Sitzung 1.2 Statistische Praxis 1.3 Grundlagen der Datenerhebung 1.4 Häufigkeitsverteilungen 1.5 Aufgaben 1.6 Tipps zur Vertiefung 1.7 Quellen", " Sitzung 1 Datenerhebung und Häufigkeiten 1.1 Lernziele dieser Sitzung Sie können einige Grundbegriffe der Statistik definieren. Typen von Stichproben unterscheiden. Skalenniveaus von Variablen bestimmen. Häufigkeitsverteilungen beschreiben. 1.2 Statistische Praxis Was ist Statistik? Je nach Perspektive kann Statistik vieles sein: ein Teilgebiet der Mathematik, ein Untersuchungsobjekt kritischer Forschung oder ein unbeliebtes Studienfach. Im Rahmen dieser Veranstaltung soll Statistik als eine Zusammenstellung von Praktiken in der quantitativen Forschung verstanden werden, wobei ihre Anwendung stets im Mittelpunkt steht. Eine hilfreiche Definition findet sich bei Haseloff et al. (1968): Allgemein kann gesagt werden: Die Statistik hat es mit Zahlen zu tun, die entweder aus Abzählvorgängen oder aus Messungen gewonnen wurden. Ihre Aufgabe ist es, ein solches Zahlenmaterial in eine optimal übersichtliche und informationsreiche Form zu bringen, aus ihnen methodische Schlußfolgerungen zu ziehen und gegebenfalls auch die Ursachen der analysierten Zahlenverhältnisse mit sachlichen Methoden aufzudecken. (Haseloff et al. 1968: 27) 1.2.1 Grundbegriffe der Statistik 1.2.1.1 Untersuchungselement Untersuchungselemente (auch Untersuchungseinheiten, Merkmalsträger, bei Personen: Proband*innen, engl. sampling unit) sind die individuellen Gegenstände empirischer Untersuchungen. Bei einer Hochrechnung zur Bundestagswahl ist dies z.B. eine befragte Wählerin. 1.2.1.2 Stichprobe Eine Stichprobe (engl. sample) ist die Menge aller Untersuchungselemente, deren Daten direkt erhoben werden. Die Anzahl der Untersuchungselemente in der Stichprobe wird in Formeln mit \\(n\\) bezeichnet. Bei einer Hochrechnung z.B. bilden alle tatsächlich befragten Wähler*innen die Stichprobe. 1.2.1.3 Grundgesamtheit Die Grundgesamtheit (auch Population, engl. population) ist die Menge aller potentiell untersuchbaren Elemente, über die Aussagen getroffen werden sollen. Die Stichprobe ist eine Teilmenge der Grundgesamtheit. Die Anzahl der Elemente in der Grundgesamtheit wird in Formeln mit \\(N\\) bezeichnet. Bei einer Hochrechnung zur Bundestagswahl sind dies z.B. alle Wähler*innen (bzw. alle Wahlberechtigten, wenn Wahlbeteiligung von Interesse ist). 1.2.1.4 Variable Variablen (auch Merkmale, engl. variable) sind Informationen über die Untersuchungselemente, die in einer Untersuchung von Interesse sind. Typischerweise unterscheiden sie sich von Untersuchungselement zu Untersuchungseelement, sind also variabel. Bei einer Hochrechnung ist dies die Antwort auf die Frage: Welche Partei haben Sie gerade gewählt? 1.2.1.5 Wert Ein Wert (auch Merkmalsausprägung, engl. observation) ist die erfasste Ausprägung einer Variable bei einem Untersuchungselement. In Formeln werden Werte mit \\(x_1, x_2, x_3, ..., x_n\\) durchnummeriert. Bei einer Hochrechnung kann die Variable gewählte Partei für ein Untersuchungselement z.B. den Wert CDU annehmen. 1.2.1.6 Kennwert Kennwerte (auch Maßzahlen, Kennzahlen, engl. summary statistics) sind Zahlen, die aus den beobachteten Werten errechnet werden. Sie können beispielsweise Aufschluss über Mittelwerte und Verteilung einer Variable oder den Zusammenhang mehrerer Variablen geben. Bei einer Hochrechnung sind z.B. die relativen Häufigkeiten (in Prozent) der Variable gewählte Partei von besonderem Interesse. 1.2.2 Taxonomien statistischer Verfahren Statistische Verfahren werden in mehrerlei Hinsicht unterschieden, wie im Folgenden beschrieben. Dabei schließen sich verschiedene Kategorien nicht unbedingt aus, es gibt also durchaus statistische Verfahren, die z.B. als univariat und deskriptiv bezeichnet werden. 1.2.2.1 Uni-, bi- und multivariate Statistik Bei diesen Bezeichnungen ist entscheidend, wie viele Variablen bei den jeweiligen Verfahren zum Einsatz kommen. Im Allgemeinen spricht man bei einer Variable von univariater Statistik, bei zwei Variablen von bivariater Statistik und bei mehr als zwei Variablen von multivariater Statistik. (Manchmal werden allerdings auch Verfahren mit nur zwei Variablen als multivariat bezeichnet.) In dieser Veranstaltung beschäftigen wir uns zunächst mit univariaten, dann mit bivariaten Verfahren. Verfahren mit mehr als zwei Variablen werden nicht behandelt. 1.2.2.2 Deskriptive und schließende Statistik Unabhängig von der Anzahl der Variablen unterscheidet man auch nach der Art und Weise des Vorgehens: 1.2.2.2.1 Deskriptive Statistik Die deskriptive Statistik (auch: beschreibende Statistik) dient der Beschreibung der Verteilung von Merkmalen, indem sie z. B. Durchschnittswerte bildet, Häufigkeiten bestimmt oder etwas über die Streuung eines Merkmals aussagt. Sie kann so große Datenmengen übersichtlicher machen, indem sie diese ordnet, gruppiert oder verdichtet. Sie erleichtert es also, das Charakteristische, Wichtige zu erkennen. 1.2.2.2.2 Schließende Statistik Die schließende Statistik (auch: analytische, operative Statistik, Inferenzstatistik, Prüfstatistik) verhilft dazu, von Eigenschaften einer Stichprobe auf Eigenschaften der Grundgesamtheit verallgemeinern bzw. schließen zu können (deshalb eben auch: schließende Statistik) und diese Einschätzung überprüfen zu können. Die schließende Statistik wird weiter unterteilt in Schätz- und Teststatistik: 1.2.2.2.2.1 Schätzstatistik Die Schätzstatistik schätzt Kennwerte der Grundgesamtheit aus den Kennwerten einer Stichprobe. 1.2.2.2.2.2 Teststatistik Die Teststatistik überprüft, als wie wahrscheinlich oder unwahrscheinlich gemachte Schätzungen bzw. Hypothesen gelten können. 1.2.3 Ablauf einer statistischen Untersuchung Eine typische Anwendung statistischer Verfahren in der Forschung folgt diesem Schema: 1.2.3.1 Datenerhebung Eigene Erhebung z.B. durch Zählen, Messen, Befragung (primärstatistische Daten) Auswahl von Untersuchungseinheiten Wahl der Datenniveaus Rückgriff auf vorhandenes Datenmaterial (sekundärstatistische Daten) 1.2.3.2 Datenaufbereitung Verdichtung des gewonnenen Datenmaterials und Digitalisierung in Form einer Datenmatrix Verschneidung von mehreren Datensätzen Vereinheitlichung und Säuberung der Daten Überblick verschaffen durch einfache Beschreibung von Häufigkeiten und Maßzahlen (deskriptive Statistik) 1.2.3.3 Datenauswertung Verdichtete Beschreibung von Verteilungsmustern einer Variable (univariate deskriptive Statistik) Verdichtete Beschreibung der Beziehung zwischen zwei Variablen (bivariate deskriptive Statistik) Schluss von Stichprobe auf Grundgesamtheit (Schätzstatistik) Testen von Hypothesen über die Grundgesamtheit (Teststatistik) 1.3 Grundlagen der Datenerhebung 1.3.1 Typen von Stichproben 1.3.1.1 Reine Zufallsstichprobe Bei endlichen Grundgesamtheiten können Lotterieverfahren angewendet werden. Dabei wird allen Elementen der Grundgesamtheit eine Zahl zwischen 1 und \\(N\\) zugeordnet. Anschließend werden Zufallszahlen ausgewählt und die entsprechenden Elemente in die Stichprobe übernommen. 1.3.1.2 Systematische Zufallsstichprobe Die Elemente einer endlichen Grundgesamtheit werden in eine Rangordnung gebracht (Nummerierung 1 bis \\(N\\)). Anschließend wählt man jedes \\((N/n)\\)-te Element aus. So entsteht eine Stichprobe der Größe \\(n\\). 1.3.1.3 Geschichtete Zufallsstichprobe Die Elemente einer endlichen Grundgesamtheit werden in Schichten (Klassen) zusammengefasst. Anschließend zieht man eine Zufallsstichprobe aus jeder Schicht. Geschichtete Stichproben setzen die Kenntnis einiger Parameter der Grundgesamtheit voraus. Zur Aufteilung des Stichprobenumfangs auf die einzelnen Schichten wird in der Regel die proportionale Aufteilung gewählt. 1.3.1.4 Klumpenstichprobe Hier ist die Grundgesamtheit schon in natürliche Gruppen aufgeteilt (z.B. Schulklassen) und es werden mehrere dieser Gruppen (Klumpen, engl. cluster) nach einem Zufallsverfahren als Stichprobe gewählt. Man beachte, dass ein einzelner Klumpen () keine Klumpenstichprobe darstellt, sondern eine Ad-hoc-Stichprobe, bei der zufällige Auswahlkriterien praktisch keine Rolle spielen. Die Bezeichnung Klumpenstichprobe ist nur zu rechtfertigen, wenn mehrere zufällig ausgewählte Klumpen vollständig untersucht werden. (Bortz und Schuster 2010: 81) 1.3.2 Variablentypen 1.3.2.1 Qualitative Variablen Qualitative Variablen können nicht der Größe nach, sondern nur im Hinblick auf ihre Eigenschaft/Art (Qualität) unterschieden werden (z.B. Parteizugehörigkeit, Telefonnummer, Automarke). Qualitative Variablen, die nur zwei mögliche Werte annehmen können, nennt man dichotome Variablen (etwa Antworten auf Ja-Nein-Fragen). 1.3.2.2 Quantitative Variablen Quantitative Variablen können der Größe nach unterschieden werden (Bsp. Geburtenzahl, Arbeitslosenzahl). Quantitative Variablen können diskret oder stetig sein: 1.3.2.2.1 Diskrete Variablen Diskrete Variablen (auch diskontinuierliche Variablen) können nur endlich viele, ganzzahlige Werte annehmen. Zwischen zwei Ausprägungen befindet sich eine abzählbare Menge anderer Ausprägungen (z.B. Anzahl eigener Kinder, Haushaltsgröße in Personen). 1.3.2.2.2 Stetige Variablen Stetige Variablen (auch: kontinuierliche Variablen) können in einem bestimmten Bereich jede beliebige Ausprägung annehmen. Der Ausdehnungsbereich kennt keine Lücken, sondern ist als ein fortlaufendes Kontinuum vorstellbar: Bei stetigen Variablen können zwischen zwei Werten oder Ausprägungen unendlich viele weitere Ausprägungen oder Werte liegen (z.B. Körpergröße, Längengrad in Dezimalform). 1.3.3 Skalenniveaus Eine Variable lässt sich aufgrund ihrer Eigenschaften einem Skalenniveau (auch Skalentyp, Messinveau, Datenniveau, engl. level of measurement) zuordnen. Bestimmte Rechenoperationen und statistische Verfahren setzen bestimmte Skalenniveaus voraus. Deshalb ist es wichtig zu wissen, welchem Skalenniveau eine Variable zuzuordnen ist. Variablen lassen sich immer auch einem niedrigeren Skalenniveau zuordnen. Dies geht allerdings mit Informationsverlust einher. Die im Folgenden beschriebenen Skalenniveaus sind nicht deckungsgleich mit den o.g. Variablentypen. Intervall- und Verhältnisskalen können z.B. jeweils diskret oder stetig sein. In Tabelle 1.1 sind die wichtigsten Skalenniveaus im Überblick aufgeführt. Gültige Lagemaße sind dabei als Zusatzinformation aufgelistet und werden erst in der nächsten Sitzung behandelt. Tabelle 1.1: Die vier wichtigsten Skalenniveaus. Skalenart Beispiel Mögliche Aussagen gültige Lagemaße Nominalskala Postleitzahl Gleichheit, Verschiedenheit Modus Ordinalskala Militärischer Rang Größer-kleiner-Relationen Median Intervallskala Temperatur in °C Gleichheit von Differenzen arithmetisches Mittel Verhältnisskala Körpergröße Gleichheit von Verhältnissen geometrisches Mittel 1.3.3.1 Nominalskala Die Merkmalsausprägungen einer Variable stehen je für sich; sie lassen sich nicht sinnvoll in eine Rangordnung bringen oder gar miteinander verrechnen. Die einzige Aussage, die sich über zwei Werte in einer Nominalskala treffen lässt, ist dass sie gleich oder nicht gleich sind. Beispiele: Postleitzahlen, Telefonnummern, Staatsangehörigkeit, Krankheitsklassifikationen 1.3.3.2 Ordinalskala Die Merkmalsausprägungen einer Variablen lassen sich sinnvoll in eine Rangordnung bringen, die Abstände zwischen den Merkmalsausprägungen aber lassen sich nicht sinnvoll quantifizieren. Über zwei Werte in einer Ordinalskala lässt sich nicht nur sagen, ob sie gleich oder verschieden sind (wie in der Nominalskala), sondern darüber hinaus, welcher Wert bei Verschiedenheit größer ist. Beispiele: Militärische Ränge, Windstärken, pauschale Häufigkeitsangaben (sehr oft  nie), Zufriedenheitsangaben (sehr zufrieden  unzufrieden) 1.3.3.3 Metrische Skalen (oder Kardinalskalen) Abstände zwischen den Merkmalsausprägungen lassen sich exakt angeben. Zusätzlich zu den Möglichkeiten der Ordinalskala können auf einer metrischen Skala Rechenoperationen auch sinnvoll auf die Differenzen zwischen den Merkmalsausprägungen angewendet werden. Metrische Skalen werden unterteilt in Intervall- und Verhältnisskalen: 1.3.3.3.1 Intervallskala Maßeinheit und Wahl des Nullpunktes sind willkürlich gewählt. Beispiele: Grad Celsius, Geburtsjahr als Jahreszahl (1961), in der Praxis häufig: subjektive Bewertung auf einer Skala von 1 bis 10. 1.3.3.3.2 Verhältnisskala (auch Ratioskala) Es gibt einen invarianten (absoluten, natürlichen) Nullpunkt. In einer Verhältnisskala lassen sich über alle o.a. Möglichkeiten hinaus auch Aussagen über Verhältnisse zwischen Werten treffen (z.B. \\(x_1\\) ist doppelt so groß wie \\(x_2\\)). Beispiele: Lebensalter in Jahren, Haushaltsgröße, Köpergröße, Körpergewicht 1.4 Häufigkeitsverteilungen 1.4.1 Urliste Die Urliste ist eine ungeordnete Liste aller erfassten Werte. Für die statistische Erhebung Anfangsbuchstaben der Vornamen von Teilnehmenden an einer Statistikvorlesung könnte die Urliste z.B. so aussehen: T J D T E N D F F M A J V T T V A L V P J K P M F M A J N A C I T P B A P H T L N S P C K J K L J R E Y M K H M N L A A L L M L J G P L B F L J J V M P C J M J S A M M M P A A L L O C J L P L V F J R M A V K S B B B N C A A T J P C F L E B L C A K A L T V Y P F L J S T T N R J A S E L M L T A E B M N M V D P P L N L B A A J M L N N S H M 1.4.2 Geordnete Liste Die geordnete Liste bringt die Werte der Urliste in eine geeignete Reihenfolge, so dass die unterschiedlichen Werte leicht gezählt werden können: A A A A A A A A A A A A A A A A A A A B B B B B B B B C C C C C C C D D D E E E E E F F F F F F F G H H H I J J J J J J J J J J J J J J J J J K K K K K K L L L L L L L L L L L L L L L L L L L L L L M M M M M M M M M M M M M M M M M N N N N N N N N N N O P P P P P P P P P P P P P R R R S S S S S S T T T T T T T T T T T V V V V V V V V Y Y 1.4.3 Häufigkeiten Die absoluten Häufigkeiten erhält man durch einfaches Abzählen der jeweiligen Werte. Für die relativen Häufigkeiten teilt man diese Zahl durch \\(n\\). Kumulierte Häufigkeiten zählen die bisherigen Summen bzw. Anteile zusammen (s. Tabelle 1.2). Tabelle 1.2: Tabelle mit kumulierten Häufigkeiten Buchstabe Absolute Häufigkeit \\(f\\) \\(f_{kum}\\) Relative Häufigkeit \\(\\%_{kum}\\) A 19 19 11,2% 11,2% B 8 27 4,7% 15,9% C 7 34 4,1% 20% D 3 37 1,8% 21,8% E 5 42 2,9% 24,7% F 7 49 4,1% 28,8% G 1 50 0,6% 29,4% H 3 53 1,8% 31,2% I 1 54 0,6% 31,8% J 17 71 10% 41,8% K 6 77 3,5% 45,3% L 22 99 12,9% 58,2% M 17 116 10% 68,2% N 10 126 5,9% 74,1% O 1 127 0,6% 74,7% P 13 140 7,6% 82,4% R 3 143 1,8% 84,1% S 6 149 3,5% 87,6% T 11 160 6,5% 94,1% V 8 168 4,7% 98,8% Y 2 170 1,2% 100% 1.4.4 Stabdiagramme Die so ermittelten Häufigkeiten lassen sich als Stabdiagramm (auch Säulen-, Streifen-, Balkendiagramm, engl. bar chart) darstellen (s. Abbildung 1.1). Abbildung 1.1: Stabdiagramm 1.4.5 Quantitative Variablen Das oben beschriebene Verfahren funktioniert gut für qualitative Variablen (und diskrete Variablen mit wenigen unterschiedlichen Werten). Für quantitative Variablen wird ein anderes Verfahren empfohlen. Zur Veranschaulichung soll diese geordnete Liste von Messwerten des Stammdurchmessers von Schwarzkirschen (Beispieldatensatz trees aus R Core Team 2018) dienen: 8,3 8,6 8,8 10,5 10,7 10,8 11,0 11,0 11,1 11,2 11,3 11,4 11,4 11,7 12,0 12,9 12,9 13,3 13,7 13,8 14,0 14,2 14,5 16,0 16,3 17,3 17,5 17,9 18,0 18,0 20,6 Für solche Verteilungen müssen zuerst Klassen (engl. bins) gebildet werden, in denen die Werte dann zusammengefasst werden (s. Tabelle 1.3). Tabelle 1.3: Häufigkeitstabelle mit klassierten Werten Durchmesser Absolute Häufigkeit \\(f\\) \\(f_{kum}\\) Relative Häufigkeit \\(\\%_{kum}\\) über 8 bis 10 Zoll 3 3 9,7% 9,7% über 10 bis 12 Zoll 12 15 38,7% 48,4% über 12 bis 14 Zoll 6 21 19,4% 67,7% über 14 bis 16 Zoll 3 24 9,7% 77,4% über 16 bis 18 Zoll 6 30 19,4% 96,8% über 18 bis 20 Zoll 0 30 0% 96,8% über 20 bis 22 Zoll 1 31 3,2% 100% Für die Wahl der Klassengrenzen gibt es zwei feste Regeln: Alle Werte müssen abgedeckt sein. Die Klassen dürfen sich nicht überlappen. Zusätzlich sollten folgende Konventionen nach Möglichkeit befolgt werden: Klassen sollten gleich große Wertebereiche abdecken. Alle Klassen sollten besetzt sein. Klassengrenzen sollten möglichst glatte Zahlen sein. Aus Gründen der Übersichtlichkeit sollten nicht mehr als 20 Klassen gewählt werden. Klassengrenzen sollten Klumpen mit ähnlichen Werten nicht trennen. Die Darstellung erfolgt in so genannten Histogrammen (engl. histogram). Abbildung 1.2 enthält ein Beispiel für ein Histogramm. Abbildung 1.2: Histogramm 1.4.6 Polygone Statt ausgefüllten Flächen wie im Histogramm lassen sich für die Häufigkeiten auch Punkte setzen, die dann mit Linien verbunden werden. So entsteht ein Häufigkeitspolygon (s. Abbildung 1.3). Abbildung 1.3: Polygonzug 1.4.7 Eigenschaften von Häufigkeitsverteilungen Polygone von Häufigkeitsverteilungen (insbesondere in geglätteter Form) ergeben Annäherungen an so gennannte Dichtefunktionen (engl. density functions). Diese lassen sich mit Attributen (uni-/bimodal, schmal-/breitgipflig, etc.) beschreiben, wie in Abbildung 4 veranschaulicht. Merkmale von Verteilungen (aus: Bortz und Schuster 2010: 42) 1.5 Aufgaben Die folgenden Aufgaben sind zur eigenständigen Überprüfung Ihrer Lernleistung gedacht (als Vor- oder Nachbereitung der Vorlesung, oder als Klausurübung) und nicht etwa als Hausaufgabe. 1.5.1 Aufgabe 1 Bestimmen Sie das Skalenniveau der folgenden Variablen. Kennzeichnen Sie darüber hinaus, ob die Variable qualitativ, diskret oder stetig ist. Lebensalter in Jahren Regenmenge in mm Güteklasse Passagieraufkommen Baujahr Geschwindigkeit in km/h Sozialstatus (Unter-, Mittel und Oberschicht) Temperatur in °F Fläche eines Bundeslands in km² Temperatur in K Einwohnerzahl Pegelstand Staatsangehörigkeit Interesse an Statistik (gering bis hoch) Klausurnote Bodentyp Entfernung zum Stadtzentrum in km Körpergröße Kleidergröße (S bis XXL) Monatliches Nettoeinkommen 1.5.2 Aufgabe 2 Folgende Werte seien erfasst über die Lebensdauer von Klimaanlagen in Stunden (Beispieldatensatz aircondit7 aus R Core Team 2018): 14 23 15 139 13 39 188 22 50 3 36 46 30 5 102 5 88 22 197 72 210 97 79 44 Erstellen Sie eine Häufigkeitstabelle. Welche Klassen wählen Sie und warum? Zeichnen Sie ein Histogramm. Beschreiben Sie die Verteilung. 1.6 Tipps zur Vertiefung 1.6.1 Grundbegriffe YouTube-Kanal Kurzes Tutorium Statistik: Statistische Grundbegriffe Kapitel 1.1 in Bortz und Schuster (2010) Kapitel 1.1 in Benninghaus (2007) Kapitel 2.1 in Bahrenberg, Giese und Nipper (2010) 1.6.2 Stichproben Kapitel 6.1 in Bortz und Schuster (2010) Kapitel 2.3 in Bahrenberg, Giese und Nipper (2010) 1.6.3 Skalenniveaus Kapitel 1.2 in Bortz und Schuster (2010) Kapitel 2.1 in Benninghaus (2007) Kapitel 2.2 in Bahrenberg, Giese und Nipper (2010) YouTube-Kanal Kurzes Tutorium Statistik: Skalenniveaus 1.6.4 Häufigkeiten und Diagramme YouTube-Kanal Kurzes Tutorium Statistik: Stabdiagramme und Histogramme Kapitel 3.1 und 3.2 in Bortz und Schuster (2010) Kapitel 1.2 in Benninghaus (2007) Kapitel 4.1 in Bahrenberg, Giese und Nipper (2010) 1.7 Quellen "],["maßzahlen.html", "Sitzung 2 Maßzahlen 2.1 Lernziele dieser Sitzung 2.2 Einleitende Bemerkungen 2.3 Lagemaße 2.4 Streumaße 2.5 Boxplot 2.6 Aufgaben 2.7 Tipps zur Vertiefung 2.8 Quellen", " Sitzung 2 Maßzahlen 2.1 Lernziele dieser Sitzung Sie können die wichtigsten Lagemaße von Stichproben bestimmen. die wichtigsten Streumaße von Stichproben bestimmen. Boxplots interpretieren. 2.2 Einleitende Bemerkungen Die im Folgenden besprochenen Maßzahlen (oder Kennzahlen, Parameter) verdichten (oder aggregieren) Häufigkeitsverteilungen einer Variable. Durch diese Parameter kann das Charakteristische einer Verteilung schnell erfasst und vergleichbar gemacht werden. Die Verdichtung auf Maßzahlen geht jedoch immer auch mit Informationsverlust einher. Die Möglichkeit der Angabe statistischer Maßzahlen ist abhängig vom Skalenniveau der Daten, wie der Überblick in Tabelle 2.1 zeigt. Tabelle 2.1: Die wichtigsten Maßzahlen Parameter Typ Mindestes Skalenniveau Formel Modalwert Lagemaß nominal \\(\\mathit{Mo}\\) Median Lagemaß ordinal \\(\\def\\arraystretch{1.2} \\mathit{Md} = \\Bigg\\{\\begin{array}{@{}c@{}}\\frac{x_{(\\frac{n}{2})}+x_{(\\frac{n}{2}+1)}}{2} \\quad \\textrm{falls }n \\textrm{ gerade}\\\\[6pt] x_{(\\frac{n+1}{2})}\\quad \\textrm{falls }n \\textrm{ ungerade}\\end{array}\\) Arithmetisches Mittel Lagemaß metrisch \\(\\bar{x}=\\frac{\\sum\\limits_{i=1}^{n}x _{i}}{n}\\) Spannweite Streumaß ordinal \\(R=x_{(n)}-x_{(1)}\\) Quartilsabstand Streumaß ordinal \\(\\mathit{IQR}=Q_3-Q_1\\) Varianz Streumaß metrisch \\(s^2=\\frac{\\sum\\limits_{i=1}^{n}(x_{i}-\\bar{x})^2}{n-1}\\) Standardabweichung Streumaß metrisch \\(s=\\sqrt{s^2}\\) 2.2.1 Beispielverteilung Alle Berechnungen von Maßzahlen werden am folgenden Beispiel illustriert: Für die 14 Gemeinden im Landkreis Rothenberge wurde die jeweilige Anzahl an Gaststätten erhoben. Die Zählung ergab die Wertereihe in Tabelle (tab:werte). Tabelle 2.2: Beispielverteilung \\(x_{1}\\) \\(x_{2}\\) \\(x_{3}\\) \\(x_{4}\\) \\(x_{5}\\) \\(x_{6}\\) \\(x_{7}\\) \\(x_{8}\\) \\(x_{9}\\) \\(x_{10}\\) \\(x_{11}\\) \\(x_{12}\\) \\(x_{13}\\) \\(x_{14}\\) 4 1 4 1 5 5 0 1 8 5 1 25 3 3 2.3 Lagemaße Lagemaße (auch Maße der Zentraltendenz, Lokalisationsparameter, Mittelwerte, engl. measures of central tendency) bezeichnen alle statistischen Maßzahlen, die eine Verteilung repräsentieren, indem sie die Lage der mittleren oder häufigsten Variablenwerte angeben. Im Falle einer unimodalen, perfekt symmetrischen Verteilung (z.B. Glockenform) haben alle drei Lageparameter den gleichen Wert. Je weiter Verteilungen von dieser Form abweichen  durch Mehrgipfligkeit oder Asymmetrie  desto unpräziser ist die Beschreibung der Verteilung durch einen einzigen Parameter. 2.3.1 Median Der Median (engl. median) einer Verteilung ist der Wert, der größer als genau 50% aller Werte ist. Da dies eine Größer-kleiner-Relation der Werte voraussetzt, kann der Median nur für ordinale und metrische Skalenniveaus angegeben werden. Im Folgenden wird die (einfachere) Bestimmung des Medians nach Bortz und Schuster (2010) verwendet. Benninghaus (2007) beschreibt ein anderes Verfahren, welches zu anderen Ergebnissen kommen kann. Um den Median zu bestimmen, wird zunächst eine geordnete Liste angefertigt, indem die Werte aufsteigend sortiert werden. Diese sortierten Werte werden mit \\(x_{(1)}, x_{(2)}, x_{(3)}, ..., x_{(n)}\\) bezeichnet (also mit Klammern). Für unsere Beispielverteilung ergibt sich Tabelle 2.3. Tabelle 2.3: Sortierte Wertereihe \\(x_{(1)}\\) \\(x_{(2)}\\) \\(x_{(3)}\\) \\(x_{(4)}\\) \\(x_{(5)}\\) \\(x_{(6)}\\) \\(x_{(7)}\\) \\(x_{(8)}\\) \\(x_{(9)}\\) \\(x_{(10)}\\) \\(x_{(11)}\\) \\(x_{(12)}\\) \\(x_{(13)}\\) \\(x_{(14)}\\) 0 1 1 1 1 3 3 4 4 5 5 5 8 25 Bei einer ungeraden Stichprobengröße \\(n\\) teilt der \\((\\frac{n+1}{2})\\)-te Wert (also der Wert genau in der Mitte) die Stichprobe in zwei Hälften, weshalb gilt: \\[ \\mathit{Md} = x_{(\\frac{n+1}{2})} \\quad \\text{falls }n\\text{ ungerade.} \\tag{2.1} \\] Bei geradem \\(n\\) entstehen zwei gleich große Hälften der Stichprobe: \\(x_{(1)}\\) bis \\(x_{(\\frac{n}{2})}\\) einerseits, und \\(x_{(\\frac{n}{2}+1)}\\) bis \\(x_{(n)}\\) andererseits. Der Durchschnitt zwischen \\(x_{(\\frac{n}{2})}\\) und \\(x_{(\\frac{n}{2}+1)}\\) teilt die Stichprobe in zwei Hälften. Es gilt: \\[ \\mathit{Md} = \\frac{x_{(\\frac{n}{2})} + x_{(\\frac{n}{2}+1)}}{2} \\quad \\text{falls } n \\text{ gerade.} \\tag{2.2} \\] In unserem Beispiel ist \\(n=14\\) und damit gerade. Der Median errechnet also nach Formel (2.2) wie folgt: \\[ \\begin{aligned} \\mathit{Md} &amp; = \\frac{x_{(7)} + x_{(8)}}{2} \\\\[4pt] &amp; = \\frac{3 + 4}{2} \\\\[4pt] &amp; = 3,5 \\end{aligned} \\] 2.3.2 Modalwert Der Modalwert \\(\\mathit{Mo}\\) (auch Modus, engl. mode) gibt den häufigsten Wert oder die häufigsten Werte einer Verteilung an. Der Modalwert kann so auch (als einziger Mittelwert) für nominalskalierte Variablen angegeben werden. Bei ordinalen und metrischen Skalenniveaus sind folgende Besonderheiten zu beachten: Wird der Modus einer Verteilung durch unmittelbar benachbarte Werte gebildet, wird er als Kombination (bei metrischen Variablen als arithmetisches Mittel) dieser Werte angegeben. Bei bimodalen (multimodalen) Verteilungen werden beide (alle) Modalwerte angegeben. Hierzu müssen die Häufigkeiten der Werte bekannt sein, bzw. bestimmt werden (s. Tabelle 2.4). Tabelle 2.4: Häufigkeiten der Beispielverteilung Wert \\(x_i\\) Häufigkeit \\(f_i\\) 0 1 1 4 3 2 4 2 5 3 8 1 25 1 Der Modalwert der Beispielverteilung beträgt 1, da der Wert 1 am häufigsten (viermal) vorkommt. 2.3.3 Arithmetisches Mittel Das arithmetische Mittel (auch Mittelwert, Durchschnitt, engl. mean) ist das gebräuchlichste Lagemaß und Grundlage für viele statistische Verfahren. Das arithmetische Mittel setzt ein metrisches Skalenniveau voraus. Die Berechnung des arithmetischen Mittels einer Stichprobe erfolgt durch die Formel: \\[ \\bar{x}=\\frac{\\sum\\limits _{i=1}^{n}x_{i}}{n} \\tag{2.3} \\] Für unsere Beispielverteilung ergibt sich durch einsetzen in Formel (2.3): \\[ \\begin{aligned} \\bar{x}&amp;=\\frac{\\sum\\limits _{i=1}^{14}x_{i}}{14} \\\\[4pt] &amp;=\\frac{4+1+4+1+5+5+0+1+8+5+1+25+3+3}{14} \\\\[4pt] &amp;=\\frac{63}{14}\\\\[4pt] &amp;\\approx 4,71 \\end{aligned} \\] 2.4 Streumaße Streumaße (auch Streuungs-, Variabilitäts-, Dispersionswerte, engl. measures of variability) geben Auskunft darüber, wie heterogen die Werte einer Verteilung sind, d.h. wie breit sie gestreut sind. Während Lagemaße den typischen Wert einer Verteilung ermitteln, zeigen Streumaße, wie gut (oder eigentlich: wie schlecht) dieser typische Wert die Verteilung repräsentiert. 2.4.1 Spannweite Die Spannweite (engl. range) gibt Auskunft darüber, wie groß der Wertebereich ist, der von einer Verteilung abgedeckt wird. Sie wird (für metrische Skalen) als die Differenz vom größten zum kleinsten Wert (also vom letzten zum ersten Wert einer geordneten Werteliste) angegeben: \\[ R=x_{(n)} - x_{(1)} \\tag{2.4} \\] Für unsere Beispielstichprobe ergibt sich (mit Blick auf Tabelle 2.3): \\[ \\begin{aligned} R&amp;=x_{(14)} - x_{(1)} \\\\[4pt] &amp;=25-0 \\\\[4pt] &amp;=25 \\end{aligned} \\] 2.4.2 Quartilsabstand Der Quartilsabstand (auch Interquartilsabstand, engl. interquartile range / IQR) gibt die Größe des Wertebereichs der mittleren 50% einer Verteilung an. Genau so wie der Median eine Messwertreihe in zwei gleich große Hälften schneidet, schneiden die Quartile die Werte in Viertel. Dabei liegt der so genannte untere Angelpunkt \\(Q_1\\) genau über 25% der Werte, \\(Q_2\\) ist identisch mit dem Median und der obere Angelpunkt \\(Q_3\\) liegt genau über 75% der Werte. Der Angelpunkt \\(Q_1\\) wird ermittelt, indem der Median für die unteren 50% (\\(Q_3\\): die oberen 50%) der Werte bestimmt wird  also jener Werte, die theoretisch unterhalb des Medians der Gesamtverteilung liegen. Dabei folgen wir Bortz und Schuster (2010) und nehmen im Fall eines ungeraden \\(n\\) den Median auf beiden Seiten hinzu. Die Formel für den Quartilsabstand lautet: \\[ \\begin{aligned} \\mathit{IQR}=Q_3-Q_1 \\end{aligned} \\tag{2.5} \\] Der Quartilsabstand ist Ausreißern gegenüber stabiler als die Spannweite, da extreme hohe oder niedrige Wert nicht in die Berechnung einfließen. In unserem Beispiel (mit \\(n=14\\)) ist die untere Hälfte der Verteilung: \\(x_{(1)}\\) \\(x_{(2)}\\) \\(x_{(3)}\\) \\(x_{(4)}\\) \\(x_{(5)}\\) \\(x_{(6)}\\) \\(x_{(7)}\\) 0 1 1 1 1 3 3 \\(Q_1\\) ist der Median dieser Werte, also \\(x_{(4)}=1\\). Die oberen 7 Werte lauten: \\(x_{(8)}\\) \\(x_{(9)}\\) \\(x_{(10)}\\) \\(x_{(11)}\\) \\(x_{(12)}\\) \\(x_{(13)}\\) \\(x_{(14)}\\) 4 4 5 5 5 8 25 \\(Q_3\\) ist also \\(x_{(11)} = 5\\). Für den Quartilsabstand ergibt sich durch einsetzen in Formel (2.5): \\[ \\begin{aligned} \\mathit{IQR}&amp;=5-1 \\\\[4pt] &amp;=4 \\\\[4pt] \\end{aligned} \\] 2.4.3 Varianz Die Varianz einer Messwertreihe (engl. variance) kann verstanden werden als der durschnittliche quadrierte Abstand der Werte zum arithmetischen Mittel. Die Formel lautet: \\[ s^2=\\frac{\\sum\\limits_{i=1}^{n}(x_{i}-\\bar{x})^2}{n-1} \\tag{2.6} \\] Die Quadrierung der Differenz hat dabei einen doppelten Effekt: Zum einen bekommen auch negative Differenzen ein positives Vorzeichen, so dass sich positive und negative Differenzen nicht neutralisieren. Zum anderen werden hierdurch besonders große Abweichungen zum arithmetischen Mittel stärker gewichtet als dies ohne Quadrierung der Fall wäre. Zudem fällt auf, dass im Gegensatz zur Formel für das arithmetische Mittel im Nenner \\(n-1\\) steht und nicht etwa \\(n\\). Dies hat mit so genannten Freiheitsgraden zu tun, die wir allerdings erst in Sitzung 5 genauer kennenlernen. Für unsere Beispielstichprobe wird die Berechnung für alle einzelnen \\((x_i-\\bar{x})^2\\) schnell aufwendig und unübersichtich. Deshalb berechnen wir ihre Summe hier mit Hilfe einer Häufigkeitstabelle (s. Tabelle 2.5). Dabei werden alle distinkten Werte einzeln transformiert und in der letzten Spalte mit ihrer Häufigkeit multipliziert. Tabelle 2.5: Häufigkeitstabelle zur Berechnung der Varianz Wert Häufigkeit Abweichung vom Mittel Quadrat der Abweichung Produkt mit Häufigkeit \\(x_i\\) \\(f_i\\) \\((x_i- \\bar{x})\\) \\((x_i- \\bar{x})^2\\) \\(f_i\\cdot(x_i -\\bar{x})^2\\) 0 1 -4,71 22,18 22,18 1 4 -3,71 13,76 55,04 3 2 -1,71 2,92 5,84 4 2 -0,71 0,50 1,00 5 3 0,29 0,08 0,24 8 1 3,29 10,82 10,82 25 1 20,29 411,68 411,68 Schließlich werden die Werte in Formel (2.6) eingesetzt: \\[\\begin{aligned} s^2&amp;=\\frac{\\sum\\limits_{i=1}^{14}(x_{i}-\\bar{x})^2}{14-1} \\\\[4pt] &amp;\\approx\\frac{22,18+55,04+5,84+1+0,24+10,82+411,68}{13} \\\\[4pt] &amp;=\\frac{506,80}{13}\\\\[4pt] &amp;\\approx 38,98 \\end{aligned}\\] Eine solche Tabelle lässt sich analog auch für die Berechnung von Summen größerer Messwertreihen für das arithmetische Mittel verwenden. Zudem lässt dieses Verfahren sich auf klassierte Daten anwenden, wenn für \\(x_i\\) der Mittelwert der Klassen eingesetzt wird (womit allerdings Informations- und Präzisionsverlust einhergeht). 2.4.4 Standardabweichung Die Standardabweichung (engl. standard deviation) ist das gebräuchlichste Streumaß und spielt eine herausragende Rolle in den allermeisten statistischen Verfahren. Die Standardabweichung einer Messwertreihe ist definiert als die Quadraturzel ihrer Varianz: \\[ \\begin{aligned} s=\\sqrt{s^2} \\end{aligned} \\tag{2.7} \\] Indem hier die Wurzel gezogen wird, wird in gewisser Weise die Quadrierung der Differenzen für die Varianz wieder korrigiert. Insbesondere wird die Quadrierung der Maßeinheit wieder aufgehoben  die Standardabweichung hat also die gleiche Einheit wie die Messreihe selbst. In unserem Beispiel beträgt die Standardabweichung also: \\[ \\begin{aligned} s&amp;\\approx\\sqrt{38,98} \\approx6,24 \\end{aligned} \\] 2.5 Boxplot Der Boxplot (auch Box-and-whisker-plot) kombiniert einige der gebräuchlichsten Maßzahlen in einer übersichtlichen Grafik (s. Abbildung 2.1). Abbildung 2.1: Boxplot der Beispielverteilung Die Höhe der Box definiert sich durch den Quartilsabstand, der mittlere Strich markiert den Median und die Whisker markieren den Wertebereich insgesamt  wobei Ausreißer, deren Abstand zur Box mehr als das 1,5-Fache des Quartilsabstands beträgt, üblicherweise gar nicht oder (wie hier) gesondert mit Punkten markiert werden. 2.6 Aufgaben Die folgenden Aufgaben sind zur eigenständigen Überprüfung Ihrer Lernleistung gedacht (als Vor- oder Nachbereitung der Vorlesung, oder als Klausurübung) und nicht etwa als Hausaufgabe. 2.6.1 Aufgabe 1 Bei einer Befragung jedes 500. Studierenden im Matrikel einer privaten Hochschule wurden folgende Angaben zur Haushaltsgröße gemacht: 1 4 4 2 3 2 3 5 2 7 2 1 1 Welches Skalenniveau liegt vor? (Sitzung 1) Berechnen Sie Modalwert, Median und arithmetisches Mittel der Stichprobe. Berechnen Sie außerdem die Spannweite, den Quartilsabstand, die Varianz und die Standardabweichung der Stichprobe. Zeichnen Sie einen Boxplot der Stichprobenverteilung. 2.6.2 Aufgabe 2 In Australien betrug die durchnittliche Niederschlagsmenge in den 1970er und 80er Jahren:1 Jahr Niederschlag (mm) 1970 384,52 1971 493,65 1972 364,65 1973 661,32 1974 785,27 1975 603,45 1976 527,75 1977 471,81 1978 525,65 1979 455,64 1980 433,01 1981 535,12 1982 421,36 1983 499,29 1984 555,21 1985 398,88 1986 391,96 1987 453,41 1988 459,84 1989 483,78 Welches Skalenniveau liegt vor? (Sitzung 1) Legen Sie eine klassierte Häufigkeitstabelle an. Begründen Sie die Wahl der Klassen. (Sitzung 1) Was ist der Modalwert der klassierten Verteilung? Wie groß ist der Quartilsabstand? Bestimmen Sie das arithmetische Mittel der klassierten Verteilung. Berechnen Sie die Standardabweichung. Zeichnen Sie einen Boxplot für die Verteilung. 2.7 Tipps zur Vertiefung 2.7.1 Lagemaße Kapitel 3.3.1 in Benninghaus (2007) Kapitel 2.1 in Bortz und Schuster (2010) Kapitel 4.2.1 in Bahrenberg, Giese und Nipper (2010) YouTube-Kanal Kurzes Tutorium Statistik: Arithmetisches, harmonisches und geometrisches Mittel YouTube-Kanal Kurzes Tutorium Statistik: Boxplots, Median, Quartile 2.7.2 Streumaße Kapitel 3.1.2 in Benninghaus (2007) Kapitel 2.2 in Bortz und Schuster (2010) Kapitel 4.2.2 in Bahrenberg, Giese und Nipper (2010) YouTube-Kanal Kurzes Tutorium Statistik: Streumaße - Varianz, Standardabweichung, Variationskoeffizient und mehr! 2.7.3 Boxplot Kapitel 3.4 in Bortz und Schuster (2010) YouTube-Kanal Kurzes Tutorium Statistik: Boxplots, Median, Quartile 2.8 Quellen Auszug aus dem Datensatz bomsoi in Haseloff et al. (1968) "],["z-werte-und-normalverteilung.html", "Sitzung 3 z-Werte und Normalverteilung 3.1 Lernziele dieser Sitzung 3.2 Variationskoeffizient 3.3 \\(z\\)-Transformation 3.4 Normalverteilung 3.5 Standardnormalverteilung 3.6 Crash-Kurs Wahrscheinlichkeitsrechnung 3.7 Wahrscheinlichkeitsdichtefunktionen 3.8 Wahrscheinlichkeitsrechnung mit Standardnormalverteilung 3.9 Aufgaben 3.10 Tipps zur Vertiefung 3.11 Quellen", " Sitzung 3 z-Werte und Normalverteilung 3.1 Lernziele dieser Sitzung Sie können z-Werte ermitteln. Merkmale der Normalverteilung wiedergeben. anhand einer normalverteilten Dichtefunktion Wahrscheinlichkeiten errechnen. Perzentile errechnen. 3.2 Variationskoeffizient Die Berechnung von Maßzahlen (Sitzung 2) vereinfacht es uns, auch große Verteilungen miteinander zu vergleichen. Voraussetzung dafür ist jedoch, dass die Kennwerte (wie arithmetisches Mittel, Standardabweichung) in derselben Maßeinheit (kg, cm, °C, etc.) vorliegen und einen vergleichbaren Maßstab haben. Eine Möglichkeit, unabhängig hiervon eine Aussage über die relative Streuung zu treffen, ist der Variationskoeffizient (engl. coefficient of variation) \\(v\\). Er ist definiert als das (prozentuale) Verhältnis von Standardabweichung zu Mittelwert: \\[\\begin{aligned} v=\\frac{s}{|\\bar{x}|}\\cdot 100\\% \\end{aligned} \\tag{3.1} \\] Zur Illustration: An zufälligen Tagen hat die Wetterstation auf dem Feldberg folgende Luftdruckwerte gemessen (in hPa): 1007,1 1003,4 990,7 994,2 1000,9 993,0 1016,0 983,9 1007,4 997,8 997,9 1000,2 Mit den bekannten Methoden (Sitzung 2) können wir das arithmetische Mittel \\(\\bar{x}\\approx 999,37\\) und die Standardabweichung \\(s\\approx8,56\\) der Stichprobe bestimmen. Durch einsetzen dieser Werte in (3.1) ergibt sich: \\[\\begin{aligned} v&amp;\\approx\\frac{8,56}{999,37}\\cdot 100\\%\\\\[4pt] &amp;\\approx0,86\\% \\end{aligned} \\] Da die Standardabweichung im Vergleich zu den absoluten Werten sehr klein ist, ist der Variationskoeffizient hier sehr klein. Ein Problem ergibt sich, wenn der Mittelwert einer Verteilung nahe Null liegt (z.B. wenn die Reihe auch negative Messwerte enthält). Der Variationskoeffizient wird in diesem Fall sehr groß und verliert stark an Aussagekraft. 3.3 \\(z\\)-Transformation Ein weiterer Ansatz, Verteilungsmuster vergleichbar zu machen, ist die \\(z\\)-Transformation (auch Standardisierung, engl. standardization). Für jeden der Messwerte lässt sich ein entsprechender \\(z\\)-Wert mit dieser Formel errechnen: \\[ z=\\frac{x-\\bar{x}}{s} \\tag{3.2} \\] Der \\(z\\)-Wert eines Werts \\(x\\) ist also der Abstand des Werts zum arithmetischen Mittel \\(\\bar{x}\\) der Verteilung, ausgedrückt im Verhältnis zu ihrer Standardabweichung \\(s\\). Die einzelnen \\(z\\)-Werte für die Luftdruckmessungen ergeben sich wie in 3.1 dargestellt. Tabelle 3.1: \\(z\\)-Transformation \\(x_i\\) Berechnung \\(z_i\\) 1007,1 \\(z_{1}=\\frac{1007,1-999,37}{8,56}\\) 0,90 1003,4 \\(z_{2}=\\frac{1003,4-999,37}{8,56}\\) 0,47 990,7 \\(z_{3}=\\frac{990,7-999,37}{8,56}\\) -1,01 994,2 \\(z_{4}=\\frac{994,2-999,37}{8,56}\\) -0,60 1000,9 \\(z_{5}=\\frac{1000,9-999,37}{8,56}\\) 0,18 993,0 \\(z_{6}=\\frac{993-999,37}{8,56}\\) -0,74 1016,0 \\(z_{7}=\\frac{1016-999,37}{8,56}\\) 1,94 983,9 \\(z_{8}=\\frac{983,9-999,37}{8,56}\\) -1,81 1007,4 \\(z_{9}=\\frac{1007,4-999,37}{8,56}\\) 0,94 997,8 \\(z_{10}=\\frac{997,8-999,37}{8,56}\\) -0,18 997,9 \\(z_{11}=\\frac{997,9-999,37}{8,56}\\) -0,17 1000,2 \\(z_{12}=\\frac{1000,2-999,37}{8,56}\\) 0,10 Eine so \\(z\\)-transformierte Verteilung hat immer automatisch das arithmetische Mittel \\(\\bar{z}=0\\) und die Standardabweichung \\(s_z=1\\). Außerdem haben \\(z\\)-Werte keine Maßeinheit. So kann jede Verteilung standardisiert und systematisch vergleichbar gemacht werden. Andersherum lassen sich \\(z\\)-Werte folgendermaßen wieder umwandeln in \\(x\\)-Werte: \\[ x=s\\cdot z+\\bar{x} \\tag{3.3} \\] 3.4 Normalverteilung Abbildung 3.1: Dichtefunktionen verschiedener Normalverteilungen Die Normalverteilung (auch: Gaußverteilung, engl. normal distribution) ist unimodal und symmetrisch. Die Normalverteilung ist eine theoretische Verteilung, für die bekannt ist, mit welcher Wahrscheinlichkeit bestimmte Werte unter- und überschritten werden bzw. mit welcher Wahrscheinlichkeit Werte in einem bestimmten Intervall liegen. Die Dichtefunktion einer Normalverteilung hat eine markante Glockenform (s. Abbildungen 3.1 und 3.2). Die beiden Wendepunkte einer Normalverteilung (also dort, wo die Steigung zwischen zu- und abnehmend wechselt; oder mathematisch: wo die Ableitung der Dichtefunktion einen Extremwert annimmt) sind je eine Standardabweichung vom Mittelwert entfernt. Die Dichtefunktion nimmt nie den Wert Null an  Extremwerte sind also sehr selten bzw. unwahrscheinlich, aber nie unmöglich. Perfekte Normalverteilungen kommen in empirischen Beobachtungen nicht vor, sondern nur Annäherungen. Da es sich um eine theoretische Verteilung handelt, ist die Normalverteilung zunächst insbesondere in Bezug auf die Grundgesamtheit interessant. Im Kontext der Grundgesamtheit wird das arithmetische Mittel mit \\(\\mu\\) (Mü) und die Standardabweichung mit \\(\\sigma\\) (Sigma) bezeichnet (s. 3.2). Tabelle 3.2: Bezeichnung von Parametern in Stichprobe und Grundgesamtheit Parameter Stichprobe Grundgesamtheit Anzahl Elemente \\(n\\) \\(N\\) Arithmetisches Mittel \\(\\bar{x}\\) \\(\\mu\\) Varianz \\(s^2\\) \\(\\sigma^2\\) Standardabweichung \\(s\\) \\(\\sigma\\) Jede Normalverteilung lässt sich anhand von zwei Parametern beschreiben: ihr arithmetisches Mittel und ihre Standardabweichung. Normalverteilte Grundgesamtheiten werden so notiert: \\[\\begin{aligned} x \\sim N(\\mu,\\enspace\\sigma^2) \\end{aligned} \\tag{3.4}\\] Der Mittelwert \\(\\mu\\) bestimmt die Lage der Kurve auf der x-Achse, die Varianz \\(\\sigma^2\\) bestimmt die Stauchung der Kurve (je größer desto flacher). Es gibt also unendlich viele verschiedene Normalverteilungen (s. 3.1). 3.5 Standardnormalverteilung Die Standardnormalverteilung (engl. standard normal distribution) ist sozusagen das Grundmuster aller Normalverteilungen. Sie hat den Mittelwert \\(\\mu=0\\) und die Standardabweichung \\(\\sigma=1\\) (s. 3.2). Alle Normalverteilungen lassen sich durch die \\(z\\)-Transformation auf die Standardnormalverteilung standardisieren. Abbildung 3.2: Dichtefunktion der Standardnormalverteilung 3.6 Crash-Kurs Wahrscheinlichkeitsrechnung Ein Zufallsexperiment ist ein beliebig oft wiederholbarer, nach bestimmten Vorschriften ausgeführter Versuch, dessen Ergebnis zufallsbedingt ist (d. h. nicht eindeutig voraussagbar ist). Jedem zufälligen Ereignis \\(A\\) ist eine bestimmte Wahrscheinlichkeit des Auftretens (engl. probability) \\(P(A)\\) zugeordnet, die der Ungleichung \\(0 \\leq P(A) \\leq 1\\) genügt (d. h. zwischen 0 und 1 liegt). Die Wahrscheinlichkeit eines sicheren Ergebnisses A ist \\(P(A) = 1\\). Hingegen würde \\(P(B) = 0\\) bedeuten, dass das Ereignis B nicht eintreten kann. Die Summe der Wahrscheinlichkeiten aller möglichen Ereignisse beträgt 1. Der Additionssatz besagt: Die Wahrscheinlichkeit, dass eins von verschiedenen zufälligen, sich gegenseitig ausschließenden Ereignissen eintritt, ist die Summe ihrer Wahrscheinlichkeiten. Der Multiplikationssatz besagt: Die Wahrscheinlichkeit für das Eintreten zweier voneinander unabhängiger Ereignisse ist gleich dem Produkt der Einzelwahrscheinlichkeiten. 3.7 Wahrscheinlichkeitsdichtefunktionen Die Fläche unter einer Wahrscheinlichkeitsdichtefunktion (engl. probability density function) beträgt genau 1. Das Perzentil \\(x_p\\) (engl. percentile) ist definiert als der Wert, unter dem der Anteil \\(p\\) der Verteilung liegt. In Sitzung 2 haben wir also bereits den Median \\(x_{50\\%}\\) sowie die Angelpunkte \\(Q1=x_{25\\%}\\) und \\(Q3=x_{75\\%}\\) kennengelernt. Die Fläche unter einer Wahrscheinlichkeitsdichtefunktion innerhalb der Limits \\(-\\infty\\) und \\(x_p\\) beträgt \\(p\\). Für einen zufälligen Wert \\(x\\) ist die Wahrscheinlichkeit \\(P(x &lt; x_p) = p\\), dass er kleiner als \\(x_p\\) ausfällt. Für die Standardnormalverteilung finden sich die \\(p\\)-Werte für positive \\(z\\) in der Formelsammlung.2 3.8 Wahrscheinlichkeitsrechnung mit Standardnormalverteilung Für die im Rest dieser Sitzung vorgestellten Verfahren müssen folgende Voraussetzungen gegeben sein: Die Grundgesamtheit ist (annähernd) normalverteilt. Arithmetisches Mittel \\(\\mu\\) und Standardabweichung \\(\\sigma\\) der Grundgesamtheit sind bekannt. Die Verfahren sollen anhand eines Beispiels illustriert werden: Es sei bekannt, dass der Luftdruck auf dem Feldberg annähernd normalverteilt ist, und zwar mit dem arithmetischen Mittel \\(\\mu=1003\\) und Varianz \\(\\sigma^2=73\\). Graphisch stellt sich die Wahrscheinlichkeitsdichtefunktion wie in 3.3 dar. Abbildung 3.3: Theoretische Wahrscheinlichkeitsdichtefunktion des Luftdrucks Wir können auch (analog zu (3.4)) schreiben: \\[ x \\sim N(1003, 73) \\] Daraus ergibt sich für die Standardabweichung \\(\\sigma\\): \\[\\begin{aligned} \\sigma&amp;=\\sqrt{\\sigma^2}\\\\ &amp;=\\sqrt{73}\\\\ &amp;\\approx8,54\\end{aligned}\\] 3.8.1 Unterschreitungswahrscheinlichkeit Die einfachste Art der Fragestellung ist nun, mit welcher Wahrscheinlichkeit ein bestimmter Wert \\(x_p\\) unterschritten wird. Nehmen wir an, es sei gefragt, mit welcher Wahrscheinlichkeit zu einem beliebigen Zeitpunkt der Luftdruck weniger als 1015 hpa beträgt. Anders gesagt interessiert uns der Anteil der Fläche unter der Verteilung, der zwischen \\(-\\infty\\) und \\(x_p=1015\\) liegt (s. 3.4). Abbildung 3.4: Unterschreitung eines Messwerts Um den entsprechenden Wert für \\(P(x &lt; x_p)\\) (also die Wahrscheinlichkeit, dass ein zufälliges \\(x\\) unser Perzentil \\(x_p\\) unterschreitet) in Erfahrung zu bringen, müssen wir die Verteilung zunächst standardisieren. Der Wert \\(z_p\\) ergibt sich aus der Formel für die \\(z\\)-Transformation, diesmal jedoch mit \\(\\mu\\) statt \\(\\bar{x}\\) und \\(\\sigma\\) statt \\(s\\), da es sich um die Grundgesamtheit handelt: \\[\\begin{aligned} z_p &amp;= \\frac{x_p-\\mu}{\\sigma} \\\\[4pt] &amp;\\approx \\frac{1015-1003}{8,54}\\\\[4pt] &amp;\\approx 1,41 \\end{aligned} \\] Graphisch ist das standardisierte Perzentil in 3.5 dargestellt. Abbildung 3.5: Standardnormalverteilung des Luftdrucks Die Formelsammlung gibt für \\(z\\)-Werte die Wahrscheinlichkeit ihrer Unterschreitung in ener Normalverteilung an. Diese Wahrscheinlichkeit kann notiert werden als \\(P(z&lt;z_p)\\). Der Formelsammlung können wir den Wert \\(P(z &lt; 1,41) \\approx 0,9207\\) entnehmen. Die Wahrscheinlichkeit, dass der Luftdruck zu einem zufälligen Zeitpunkt weniger als 1015 hPA beträgt, ist somit 92,07%. 3.8.1.1 Überschreitungswahrscheinlichkeit Wird nach der Wahrscheinlichkeit der Überschreitung eines Werts gefragt, ist in anderen Worten die Fläche unter der Wahrscheinlichkeitsdichtefunktion zwischen \\(x_p\\) und \\(\\infty\\) gemeint. Wir bleiben bei unserem Beispiel \\(x_p=1015\\) (s. 3.6). Abbildung 3.6: Überschreitung eines Messwerts Hier können wir genauso wie bei der Unterschreitung \\(z_p=1,41\\) errechnen. Jetzt stehen wir zunächst vor dem Problem, dass die \\(p\\)-Werte in der Tabelle immer die Wahrscheinlichkeit der Unterschreitung darstellen. Wir wissen jedoch: Die gesamte Fläche unter der Verteilung ist 1, und die Wahrscheinlichkeiten der Unter- und Überschreitung sind komplementär, d.h. einer von beiden Fällen tritt sicher (mit einer Wahrscheinlichkeit von 100%) ein. (Den Sonderfall \\(x=x_p\\) können wir bei stetigen Variablen vernachlässigen.) Hieraus ergibt sich ganz allgemein: \\[ \\begin{aligned} P(x \\geq x_p) = 1-P(x&lt;x_p) \\end{aligned} \\tag{3.5} \\] Und für unser Beispiel: \\[ \\begin{aligned} P(x \\geq 1015) &amp;= 1-P(x &lt; 1015) \\\\ &amp;\\approx1-P(z &lt; 1,41)\\\\ &amp;\\approx1-0,9207\\\\ &amp;= 0,0793 \\end{aligned} \\] In 7,93% der Fälle beträgt der Luftdruck also über 1015 hPA. 3.8.1.2 Negativer \\(z\\)-Wert Wenn nach der Unterschreitungswahrscheinlichkeit eines unterdurchschnittlichen Werts gefragt ist (z.B. 990 hPA), dann ergibt sich ein negativer Wert für \\(z_p\\): \\[\\begin{equation} \\begin{aligned} z_p &amp;= \\frac{x_p-\\mu}{\\sigma} \\\\[4pt] &amp;= \\frac{990-1003}{8,54} \\\\[4pt] &amp;\\approx -1,52 \\end{aligned} \\end{equation}\\] Die Formelsammlung enthält keine \\(p\\) für negative \\(z_p\\). Da die Standardnormalverteilung jedoch um \\(z=0\\) symmetrisch ist, gilt ganz allgemein: \\[ \\begin{aligned} P(z &lt; -z_p) = 1 - P(z &lt; z_p) \\end{aligned} \\tag{3.6} \\] Für unser Beispiel ergibt sich (mit dem Wert \\(P(z &lt; 1,52) = 0,9357\\) aus der Tabelle): \\[ \\begin{aligned} P(z &lt; -1,52) &amp;= 1 - P(z &lt; 1,52) \\\\ &amp;\\approx 1-0,9357 \\\\ &amp;=0,0643 \\end{aligned} \\] Ein Luftdruck von 990 hPa wird also nur in ca. 6,43% der Fälle unterschritten. 3.8.1.3 Wert in einem Intervall Nun wollen wir wissen, mit welcher Wahrscheinlichkeit ein zufälliger Meßwert zwischen 1005 und 1015 hPa liegt. Graphisch ist dies in 3.7 aufbereitet. Abbildung 3.7: Messwertintervall Rechnerisch müssen wir also von den (günstigen) Fällen, in denen 1015 hPA unterschritten werden, noch jene (ungünstige) Fälle abziehen, in denen die 1005 hPA ebenfalls unterschritten werden. Ganz allgemein heißt das für die Untergrenze \\(x_u\\) und die Obergrenze \\(x_o\\): \\[ \\begin{aligned} P(x_{u} \\leq x &lt; x_{o}) = P(x &lt; x_{o}) - P(x &lt; x_{u}) \\end{aligned} \\tag{3.7} \\] Für unseren Fall ist \\(x_u=1005\\) und \\(x_o=1015\\). In den vorherigen Aufgaben haben wir \\(z_o\\approx1,41\\) bereits ermittelt. Wir müssen aber noch \\(z_u\\) ermitteln: \\[ \\begin{aligned}5 z_u &amp;= \\frac{x_u-\\mu}{\\sigma} \\\\[4pt] &amp;= \\frac{1005-1003}{8,54} \\\\[4pt] &amp;\\approx 0,23 \\end{aligned} \\] Dann können wir die entsprechende Wahrscheinlichkeit berechnen, indem wir wieder die Werte aus der Formelsammlung einsetzen: \\[ \\begin{aligned} P(1005 \\leq x &lt; 1015) &amp;= P(x &lt; 1015) - P(x &lt; 1005) \\\\ &amp;\\approx P(z &lt; 1,41) - P(z &lt; 0,23) \\\\ &amp;\\approx 0,9207- 0,5910 \\\\ &amp;= 0,3297 \\end{aligned} \\] Der Luftdruck liegt also mit einer Wahrscheinlichkeit von 32,97% zwischen 1005 und 1015 hPa. 3.8.1.4 Gesuchter Wert bei gegebener Wahrscheinlichkeit Die Fragerichtung lässt sich umdrehen: Welche Marke wird beim Messen des Luftdrucks nur in 5% der Fälle überschritten? 5% Überschreitungswahrscheinlichkeit entsprechen einer Unterschreitungswahrscheinlichkeit von 95%. Welcher Wert wird also mit 95% Wahrscheinlichkeit unterschritten? Der Tabelle entnehmen wir, dass einer Unterschreitungswahrscheinlichkeit von 0,95 ein \\(z\\)-Wert zwischen 1,64 und 1,65 entspricht. Da es bei dieser Fragestellungen oft darum geht, einen kritischen Wert zu nennen, der nur in Ausnahmefällen überschritten wird, nehmen wir hier üblicherweise den extremeren Wert, also \\(z_{95\\%}\\approx 1,65\\). Mit der umgekehrten \\(z\\)-Transformation erhalten wir: \\[ \\begin{aligned} x_{95\\%}&amp;=z_{95\\%}\\cdot \\sigma + \\mu \\\\ &amp;\\approx 1,65\\cdot 8,54 + 1003\\\\ &amp;\\approx 1017,10 \\end{aligned} \\] Die Marke von 1017,10 hPa wird also nur in 5% der Fälle überschritten. 3.8.1.5 Gesuchte Grenzwerte eines Intervalls Eine übliche Art der Fragestellung ist auch: Zwischen welchen beiden Werten liegen die mittleren 85% der Fälle (s. Abbiddung 3.8)? Abbildung 3.8: Die mittleren 85% der Normalverteilung Da die Verteilung symmetrisch ist, teilen sich die ungünstigen 15% der Fälle gleichmäßig an den oberen und unteren Rand der Verteilung auf. Die Obergrenze \\(x_o\\) ist also der Wert, der zu 7,5% über- und damit zu 92,5% unterschritten wird. Der Tabelle entnehmen wir den Wert \\(z_o=z_{92,5\\%}\\approx1,44\\). Die Untergrenze ist entsprechend der Wert, der in 7,5% der Fälle unterschritten wird. Der Wert für \\(z_u=z_{7,5\\%}\\) ist in der Tabelle nicht enthalten. Weil die Verteilung aber symmetrisch ist, wissen wir uns zu helfen: \\[ \\begin{aligned} z_u=z_{7,5\\%}=-z_{92,5\\%}\\approx-1,44 \\end{aligned} \\] Die absoluten Werte ergeben sich schließlich aus: \\[ \\begin{aligned} x_u&amp;=z_u\\cdot \\sigma + \\mu \\\\ &amp;\\approx-1,44 \\cdot 8,54 + 1003\\\\ &amp;\\approx990,70 \\end{aligned} \\] Und: \\[ \\begin{aligned} x_o&amp;=z_o\\cdot \\sigma + \\mu \\\\ &amp;\\approx1,44 \\cdot 8,54 + 1003\\\\ &amp; \\approx 1015,30 \\end{aligned} \\] Die mittleren 85% der Messwerte liegen also zwischen 990,7 und 1015,3 hPa. 3.9 Aufgaben Die folgenden Aufgaben sind zur eigenständigen Überprüfung Ihrer Lernleistung gedacht (als Vor- oder Nachbereitung der Vorlesung, oder als Klausurübung) und nicht etwa als Hausaufgabe. 3.9.1 Aufgabe 1 Deiche werden durch Wasserdruck bei Hochwasser belastet und dadurch beschädigt. Bei einem 12 m hohen Deich gilt als kritische Marke ein Wasserstand von 10 m. Die jährlichen Höchstwasserstände des Flusses sind normalverteilt mit einem Mittelwert von 9,01 m und einer Standardabweichung von 2,23 m. In den folgenden Teilaufgaben beantworten wir Schritt für Schritt die Frage, wie wahrscheinlich es (für ein beliebiges Jahr) ist, dass der Deich das jährliche Hochwasser ohne Beschädigung übersteht, d.h. dass ein Höchstwasserstand von 10 m oder weniger eintritt. Zeichnen Sie die Wahrscheinlichkeitsdichtefunktion (ganz grob, ohne y-Achse). Markieren Sie den kritischen Wert 10 m. Welchem \\(z\\)-Wert entspricht die kritische Marke von 10 m? Mit welcher Wahrscheinlichkeit bleibt der Deich in einem gegebenen Jahr unbeschädigt (Höchstwasserstand unter der kritischen Marke von 10 m)? 3.9.2 Aufgabe 2 Wir bleiben beim Deich aus Aufgabe 1. Mit welcher Wahrscheinlichkeit wird der Deich beschädigt (Wasserstand über 10 m)? Mit welcher Wahrscheinlichkeit wird der Deich nicht nur beschädigt, sondern läuft über (Wasserstand über 12 m)? Mit welcher Wahrscheinlichkeit wird der Deich beschädigt, läuft aber nicht über (Wasserstand zwischen 10 und 12 m)? In welchen Grenzen liegen die mittleren 80% der Hochwasserstände? 3.9.3 Aufgabe 3 Es ist ein neuer Deich zu bauen, der so sicher sein soll, dass er nur alle 200 Jahre vom Hochwasser übertreten wird. Welcher Wahrscheinlichkeitswert \\(p=P(x &lt; x_p)\\) ist anzuwenden, d.h. wie wahrscheinlich ist die Unterschreitung eines zweihundertjähriges Hochwassers? Mit welchem \\(z\\)-Wert korrespondiert der gesuchte Wert \\(x_p\\)? Wie hoch muss dieser Deich sein? (Welcher Wert \\(x_p\\) entspricht diesem \\(z_p\\)?) 3.9.4 Aufgabe 4 Die jährlichen Niederschlagsmengen in Mittelstedt betragen im Mittel 400 mm bei annähernder Normalverteilung und einer Standardabweichung von 100 mm. Wie groß ist die Wahrscheinlichkeit, dass mehr als 500 mm Niederschlag fallen? Wie oft pro hundert Jahre kann mit weniger als 200 mm Niederschlag gerechnet werden? Mit welcher Wahrscheinlichkeit fallen zwischen 200 mm und 550 mm Niederschlag? Welche Niederschlagsmenge wird wahrscheinlich in nur 2 von 100 Jahren übertroffen? In welchen Grenzen liegen die mittleren 75% der jährlichen Niederschlagsmenge? 3.10 Tipps zur Vertiefung 3.10.1 Variationskoeffizient Kapitel 4.2.2 in Bahrenberg, Giese und Nipper (2010) YouTube-Kanal Kurzes Tutorium Statistik: Streumaße - Varianz, Standardabweichung, Variationskoeffizient und mehr! 3.10.2 z-Transformation Kapitel 2.4 in Bortz und Schuster (2010) Kapitel 4.2.2 in Bahrenberg, Giese und Nipper (2010) Kapitel 3.3.3 in Benninghaus (2007) YouTube-Kanal Methodenlehre Mainz: WT.012.09 Äpfel mit Birnen vergleichen: Die z-Standardisierung 3.10.3 Normalverteilung Kapitel 5.4 in Bortz und Schuster (2010) Kapitel 5.2.2 in Bahrenberg, Giese und Nipper (2010) YouTube-Kanal Mathe by Daniel Jung: Was ist die Normalverteilung, Gauß-Verteilung, Schaubilder, Übersicht 3.10.4 Wahrscheinlichkeitsdichtefunktion Kapitel 5.3 in Bortz und Schuster (2010) Kapitel 5.2.2 in Bahrenberg, Giese und Nipper (2010) YouTube-Kanal Kurzes Tutorium Statistik: Zufallsvariable, Massenfunktion, Dichtefunktion und Verteilungsfunktion 3.11 Quellen Manchmal wird die Funktion \\(z_p \\rightarrow P(z &lt; z_p)\\) für normalverteilte Werte auch mit \\(\\Phi(z)\\) bezeichnet (z.B. in Bahrenberg, Giese und Nipper 2010). "],["schätzstatistik-1.html", "Sitzung 4 Schätzstatistik 4.1 Lernziele dieser Sitzung 4.2 Stichprobenverteilung 4.3 Punktschätzung 4.4 Intervallschätzung 4.5 Aufgaben 4.6 Tipps zur Vertiefung 4.7 Quellen", " Sitzung 4 Schätzstatistik 4.1 Lernziele dieser Sitzung Sie können eine Punktschätzung für \\(\\mu\\) und \\(\\sigma\\) durchführen. den Standardfehler der Stichprobenverteilung von \\(\\bar{x}\\) bestimmen. eine Intervallschätzung für \\(\\mu\\) durchführen. 4.2 Stichprobenverteilung Die Stichprobenverteilung ist eine theoretische Verteilung, welche die möglichen Ausprägungen eines statistischen Kennwertes (z.B. \\(\\bar{x}\\)) sowie deren Auftretenswahrscheinlichkeit beim Ziehen von Zufallsstichproben des Umfanges \\(n\\) beschreibt. (Bortz und Schuster 2010: 83) Hier ist zunächst die theoretische Verteilung des Mittelwerts einer Stichprobe relevant. Insbesondere interessiert uns, wie sich die theoretische Verteilung des Mittelwerts abhängig von der Stichprobengröße verhält. 4.2.1 Szenario 1: Normalverteilte Grundgesamtheit Die Grundgesamtheit (Population) einer Variable \\(x\\) sei normalverteilt mit \\(\\mu=50\\) und \\(\\sigma^2=25\\). Wir können also schreiben: \\[ x \\sim N(50,25) \\] Die Standardabweichung der Population beträgt entsprechend: \\[\\begin{aligned} \\sigma&amp;=\\sqrt{\\sigma^2}\\\\[4pt] &amp;=\\sqrt{25}=5\\end{aligned}\\] Graphisch ist die Dichtefunktion der Verteilung in 4.1 veranschaulicht. Abbildung 4.1: Dichtefunktion der Grundgesamtheit Wenn eine einzelne Stichprobe der Größe \\(n=3\\) aus dieser Verteilung gezogen würde, hätte sie drei konkrete Werte (\\(x_1\\), \\(x_2\\) und \\(x_3\\)) sowie ein konkretes arithmetisches Mittel (\\(\\bar{x}\\)). Es lässt sich jedoch auch eine Wahrscheinlichkeitsdichtefunktion der Mittelwerte aller theoretisch möglichen Stichproben der Größe \\(n=3\\) (und zusätzlich der Größe \\(n=6\\)) zeichnen (s. 4.2). Abbildung 4.2: Dichtefunktionen der Stichprobenverteilungen 4.2.1.1 Erwartungswert Es fällt auf, dass die Stichprobenverteilungen für \\(\\bar{x}\\) normalverteilt sind und um das arithmetische Mittel der Grundgesamtheit (\\(\\mu\\)) symmetrisch sind. Das arithmetische Mittel der Stichprobenverteilung \\(\\mu_{\\bar{x}}\\) wird auch als Erwartungswert (engl. expected value) von \\(\\bar{x}\\) bezeichnet. Es gilt: \\[ \\mu_{\\bar{x}} = \\mu \\tag{4.1} \\] Wir können auch sagen: \\(\\bar{x}\\) ist ein ertwartungstreuer Schätzparameter für \\(\\mu\\); nicht weil er in der Empirie zwangsläufig identisch mit \\(\\mu\\) wäre, sondern weil er mit zunehmender Stichprobengröße immer stärker zu \\(\\mu\\) tendiert. 4.2.1.2 Standardfehler Zusätzlich fällt in 4.2 auf: Je größer die Stichprobe, desto gestauchter die Dichtekurve der Stichprobenverteilung: Die theoretische Verteilung von \\(\\bar{x}\\) bei \\(n=6\\) weist eine kleinere Varianz auf als bei \\(n=3\\). Das ist einigermaßen intuitiv, denn wir können uns vorstellen, dass das arithmetische Mittel \\(\\bar{x}\\) bei steigender Stichprobengröße ein immer präziserer Schätzwert für \\(\\mu\\) wird. Die Varianz der Stichprobenverteilung für \\(\\bar{x}\\) bezeichnen wir mit \\(\\sigma^2_{\\bar{x}}\\). Sie hängt von der Varianz der Population ab und ist invers proportional zur Stichprobengröße. Es gilt: \\[ \\sigma^2_{\\bar{x}} = \\frac{\\sigma^2}{n} \\tag{2.6} \\] Die Standardabweichung der Stichprobenverteilung (\\(\\sigma_{\\bar{x}}\\)) wird auch Standardfehler (engl. standard error) genannt. Durch Wurzelziehen ergibt sich: \\[ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} \\tag{2.7} \\] Zusammenfassend lässt sich sagen: \\[\\begin{aligned} \\bar{x} \\sim N(\\mu, {\\textstyle \\frac{\\sigma^2}{n}}) \\quad \\textrm{für} \\quad x\\sim N(\\mu, \\sigma^2) \\end{aligned} \\tag{3.4}\\] 4.2.2 Szenario 2: Nicht normalverteilte Grundgesamtheit Die Gleichungen (4.1), (2.6) und (2.7) gelten uneingeschränkt auch für die Stichprobenverteilungen von nicht normalverteilten Populationen. Nur die Normalverteilung der Stichprobenverteilung ((3.4)) ist bei nicht normalverteilten Grundgesamtheiten grundsätzlich nicht gegeben. Das zentrale Grenzwerttheorem (engl. central limit theorem) besagt jedoch: Die Verteilung von Mittelwerten aus Stichproben des Umfangs \\(n\\), die derselben Grundgesamtheit entnommen wurden, geht mit wachsendem Stichprobenumfang in eine Normalverteilung über. (Bortz und Schuster 2010: 86) 4.3 veranschaulicht diesen Effekt für eine nicht normalverteilte Grundgesamtheit. Abbildung 4.3: Stichprobenverteilung bei nicht normalverteilter Population In der Praxis gilt die Faustregel: Ab einer Stichprobengröße von \\(n=30\\) können wir statistische Verfahren anwenden, die von einer theoretischen Normalverteilung von \\(\\bar{x}\\) ausgehen  und zwar unabhängig von der Verteilung der Grundgesamtheit. 4.3 Punktschätzung Bei statistischen Untersuchungen geht es oft darum, ausgehend von der empirischen Verteilung einer Stichprobe auf Parameter der Grundgesamtheit zu schließen. Die Punktschätzung (engl. point estimation) ist dabei eine vergleichsweise einfache und intuitive Vorgehensweise. 4.3.1 Punktschätzung des arithmetischen Mittels Wenn eine Stichprobe vorliegt, dann ist ihr arithmetisches Mittel (\\(\\bar{x}\\)) als erwartungstreuer Punktschätzer der wahrscheinlichste Wert für das arithmetische Mittel der Grundgesamtheit (\\(\\mu\\)). Beispiel: Zehn Studierende der Humangeographie werden zufällig ausgewählt, um ihre Pendelzeit zum IG-Farben-Campus zu erfassen. Die Angaben in Minuten lauten: 22 26 12 23 48 31 15 71 17 35 Das arithmetische Mittel der Messreihe lässt sich  wie in Sitzung 2 ausführlich besprochen  berechnen: \\(\\bar{x}=30\\) Da es sich um eine erwartungstreue Schätzgröße (und eine valide Zufallsstichprobe) handelt, kann die durchschnittliche Pendelzeit aller Studierenden der Humangeographie auf \\(\\mu=30\\) Minuten geschätzt werden. Gleichzeitig wissen wir jedoch, dass diese Punktschätzung des arithmetischen Mittels vermutlich nicht ganz präzise ist, sondern einem Standardfehler (\\(\\sigma_{\\bar{x}}\\)) unterliegt. Woher wissen wir, wie groß dieser Standardfehler ist (und wie unpräzise damit unsere Schätzung)? 4.3.2 Schätzung des Standardfehlers Wir führen das obige Beispiel fort: Die Varianz der Stichprobe können wir berechnen: \\(s^2\\approx319{,}78\\) (s. Sitzung 2). Dabei handelt es sich ebenfalls um einen erwartungstreuen Punktschätzer für die Varianz der Grundgesamtheit (\\(\\sigma^2\\)). Die Varianz der Grundgesamtheit kann also auch auf \\(\\sigma^2=s^2\\approx319{,}78\\) geschätzt werden. Analog können wir die Standardabweichung der Population auf \\(\\sigma=s\\approx17,88\\) schätzen. Den Standardfehler können wir mit diesem Schätzwert anhand (2.7) berechnen. Allerdings benutzen wir statt \\(\\sigma_{\\bar{x}}\\) das Symbol \\(s_{\\bar{x}}\\), da es sich um einen Schätzwert handelt: \\[\\begin{aligned} s_{\\bar{x}} &amp;= \\frac{s}{\\sqrt{n}}\\\\[4pt] &amp;\\approx \\frac{17{,}88}{\\sqrt{10}}\\approx5{,}65 \\end{aligned}\\] Je größer die Stichprobe, desto genauer lassen sich also Parameter der Population schätzen. Die statistische Antwort auf die Frage, wie groß die Stichprobe denn sein müsse, lautet demnach zunächst immer: Möglichst groß! Bemerkernswert ist jedoch, dass dabei die Größe der Grundgesamtheit (\\(N\\), im Beispiel die Anzahl aller Studierenden der Humangeographie) bei diesen Überlegungen überhaupt keine Rolle spielt. 4.4 Intervallschätzung Um eine Intervallschätzung durchführen zu können, muss: die Standardabweichung der Grundgesamtheit \\(\\sigma\\) bekannt und die theoretische Verteilung von \\(\\bar{x}\\) normalverteilt sein. Das bedeutet: Entweder es ist bekannt, dass die Grundgesamtheit normalverteilt ist Und/oder die Stichprobengröße ist \\(n\\geq30\\) Für das obige Beispiel der Pendelzeiten wissen wir nicht, wie die Verteilung der Grundgesamtheit aussieht, und die Stichprobengröße (\\(n=10\\)) ist kleiner als 30. Eine Intervallschätzung können wir hier also nicht durchführen! Auch bei der Intervallschätzung (engl. interval estimation) geht es darum, das arithmetische Mittel der Population (\\(\\mu\\)) zu schätzen. Allerdings geben wir nicht einfach nur den wahrscheinlichsten Wert an, sondern einen Bereich (ein Intervall), in dem \\(\\mu\\) mit einer bestimmten Wahrscheinlichkeit liegt. Die Grundüberlegung ist dabei folgende: Wir haben eine empirische Stichprobe vorliegen (und können ihren Mittelwert \\(\\bar{x}\\) und ihre Standardabweichung \\(s\\) berechnen). Wir wissen dass die theoretische Verteilung aller möglichen Stichproben normalverteilt ist, und um den gesuchten Wert \\(\\mu\\) symmetrisch ist. Den Mittelwert unserer empirischen Stichprobe \\(\\bar{x}\\) können wir uns als zufälligen Wert der theoretischen Stichprobenverteilung von \\(\\bar{x}\\) vorstellen. Wo genau in dieser theoretischen Verteilung wir mit unserem empirischen Wert gelandet sind, wissen wir nicht. Wenn wir den Wert \\(\\mu\\) kennen würden, könnten wir (mit den Methoden aus Sitzung 3) die Wahrscheinlichkeit für einen beliebeigen Bereich angeben, in den ein zufälliges \\(\\bar{x}\\) fällt. Der entscheidende Trick: Weil die Normalverteilung symmetrisch ist, sind diese Wahrscheinlichkeiten analog anzuwenden auf die Bereiche einer konstruierten Verteilung mit gleichem \\(\\sigma_{\\bar{x}}\\) um unser \\(\\bar{x}\\), in die der wirkliche Wert \\(\\mu\\) fällt. (s. 4.4). Abbildung 4.4: Konstruierte Verteilung um \\(\\bar{x}\\) Dabei heißt der Bereich Konfidenzintervall (engl. confidence interval), und seine Breite wird mit \\(\\textrm{KIB}\\) abgekürzt. Die Wahrscheinlichkeit, dass wir mit unserer Schätzung außerhalb des Konfidenzintervalls liegen wird mit \\(\\alpha\\) gekennzeichnet. Ein 95%-Konfidenzintervall hat also ein \\(\\alpha\\) von 0,05 (s. 4.5). Abbildung 4.5: Konfidenzintervall Tabelle 4.1: Jahresniederschlag in Hessen Jahr Niederschlag (l/m²) 2011 855,3 2012 839,5 2013 850,6 2014 873,1 2015 858,3 2016 857,1 2017 861,4 Ein Beispiel soll dies verdeutlichen: Wir wissen, dass die jährliche Niederschlagsmenge in Hessen normalverteilt ist mit \\(\\sigma=10{,}23\\). Wir haben die Messwerte in Tabelle 1 erhoben und möchten den Mittelwert (\\(\\mu\\)) per Intervallschätzung angeben. Zunächst errechnen wir den Mittelwert unserer empirischen Stichprobe: \\[\\begin{aligned} \\bar{x}&amp;\\approx856{,}47 \\end{aligned}\\] Dann errechnen wir anhand (2.7) den Standardfehler der theoretischen Verteilung von \\(\\bar{x}\\): \\[\\begin{aligned} \\sigma_{\\bar{x}}&amp;=\\frac{\\sigma}{\\sqrt{n}}\\\\[4pt] &amp;\\approx\\frac{10{,}23}{\\sqrt{7}}\\approx3,86 \\end{aligned}\\] 4.4.1 Gesuchtes \\(\\alpha\\) Nun könnte eine Fragerichtung lauten: Wie groß ist die Wahrscheinlichkeit, dass der Mittelwert der Population \\(\\mu\\) in einem Korridor von ± 5 l/m² um \\(\\bar{x}\\) liegt?3 Gesucht ist bei einer Konfidenzintervallbreite von \\(\\textit{KIB}=10\\) also die Wahrscheinlichkeit: \\[1-\\alpha\\approx P(851{,}47 &lt; \\mu &lt; 861{,}47)\\] Generalisierend lässt sich schreiben: \\[ 1-\\alpha=P(x_{\\alpha/2} &lt; \\mu &lt; x_{(1-\\alpha/2)}) \\] wobei \\(x_{\\alpha/2}\\) die Untergrenze darstellt und \\(x_{(1-\\alpha/2)}\\) die Obergrenze. In \\(z\\)-Werten ausgedrückt: \\[ 1-\\alpha=P(z_{\\alpha/2} &lt; z_{\\mu} &lt; z_{(1-\\alpha/2)}) \\tag{4.2} \\] In Sitzung 3 haben wir bereits gelernt, wie diese Wahrscheinlichkeit berechnet werden kann. Im Folgenden wird der Rechenweg noch einmal am Beispiel dargelegt. 4.4.1.1 Die umständliche Variante Zunächst müssen wir die Intervallgrenzen in\\(z\\)-Werte umwandeln, um die Unter- bzw. Überschreitungswahrscheinlichkeiten ermitteln zu können. Die z-Transformation muss hier jedoch anhand des Standardfehlers \\(\\sigma_{\\bar{x}}\\) geschehen, da wir ja an der Stichprobenverteilung interessiert sind. Durch \\(z\\)-Transformation mit \\(\\bar{x}\\) und dem Standardfehler \\(\\sigma_{\\bar{x}}\\) erhalten wir die standardisierten Intervallgrenzen. Untergrenze: \\[\\begin{aligned} z_{\\alpha/2} &amp;= \\frac{x_{\\alpha/2}-\\bar{x}}{\\sigma_{\\bar{x}}}\\\\[4pt] &amp;\\approx\\frac{851{,}47-856,47}{3,86}\\approx-1,30 \\end{aligned}\\] Obergrenze: \\[\\begin{aligned} z_{(1-\\alpha/2)} &amp;= \\frac{x_{(1-\\alpha/2)}-\\bar{x}}{\\sigma_{\\bar{x}}}\\\\[4pt] &amp;\\approx\\frac{861{,}47-856,47}{3,86}\\approx1,30 \\end{aligned}\\] Es ist wenig überraschend, dass die \\(z\\)-transformierten Werte symmetrisch sind. Wir setzen in (4.2) ein: \\[ 1-\\alpha\\approx P(-1{,}30 &lt;z_{\\mu} &lt; 1{,}30) \\] Dies lässt sich umformen in: \\[ 1-\\alpha\\approx P(z_{\\mu}&lt;1{,}08) - P(z_{\\mu}&lt;-1{,}08) \\] Die jeweiligen Wahrscheinlichkeiten lassen sich in der Tabelle für \\(p\\)-Werte der Normalverteilung nachschauen (bzw. für den negativen \\(z\\)-Wert errechnen, s. Formelsammlung): \\[\\begin{aligned} 1-\\alpha&amp;\\approx 0,9032 - 0,0968\\\\[4pt] &amp;=0,8064 \\end{aligned}\\] Die Wahrscheinlichkeit, dass \\(\\mu\\) im Konfidenzintervalls 856,47 ± 5 l/m² liegt, beträgt also 80,64%. 4.4.1.2 Die schnelle Variante Wir können den \\(z\\)-Wert für die Obergrenze des Konfidenzintervalls ganz einfach ausrechnen, weil wir wissen, dass die Obergrenze um 5 größer ist als \\(\\bar{x}\\) und dass \\(z_{\\bar{x}}=0\\): \\[\\begin{aligned} z_{(1-\\alpha/2)}&amp;=\\frac{5}{\\sigma_{\\bar{x}}}\\\\[4pt] &amp;\\approx\\frac{5}{3,86}\\\\[4pt] &amp;\\approx1{,}30 \\end{aligned}\\] Oberhalb dieses Werts liegt bekanntermaßen der Anteil \\(\\frac{\\alpha}{2}\\), woraus sich mit Blick auf die Tabelle ergibt: \\[\\begin{aligned} \\frac{\\alpha}{2}&amp;=1-0,9032\\\\[4pt] \\alpha&amp;=0,1936 \\end{aligned}\\] 4.4.2 Gesuchtes Konfidenzintervall Eine weitere Möglichkeit der Fragestellung lautet: In welchem Bereich liegt das arithmetische Mittel \\(\\mu\\) mit einer Wahscheinlichkeit von 90%? Vorgegeben ist also \\(\\alpha=0{,}1\\), und gesucht sind die Unter- und die Obergrenze des Konfidenzintervalls. Wir setzen ein: \\[\\begin{aligned} 1-\\alpha&amp;=P(z_{\\alpha/2} &lt; z_{\\mu} &lt; z_{(1-\\alpha/2)})\\\\[4pt] 0{,}9 &amp;= P(z_{5\\%} &lt; z_{\\mu} &lt; z_{95\\%}) \\end{aligned}\\] Die entsprechenden \\(z\\)-Werte der Intervallgrenzen lassen sich (in umgekehrter Suchrichtung) aus der Tabelle ablesen: \\[\\begin{aligned} z_{5\\%}&amp;\\approx-1{,}64\\\\[4pt] z_{95\\%}&amp;\\approx 1{,}64 \\end{aligned}\\] Durch umgekehrte z-Transformation  auch hier weider mit \\(\\bar{x}\\) und \\(\\sigma_{\\bar{x}}\\)  ergeben sich die Intervallgrenzen. Untergrenze: \\[\\begin{aligned} x_{5\\%} &amp;= z_{5\\%} \\cdot \\sigma_{\\bar{x}} + \\bar{x}\\\\[4pt] &amp;\\approx -1{,}64 \\cdot 3,86 + 856{,}47\\\\[4pt] &amp;\\approx 850,14\\\\[6pt] \\end{aligned}\\] Obergrenze: \\[\\begin{aligned} x_{95\\%}&amp;= z_{95\\%} \\cdot \\sigma_{\\bar{x}} + \\bar{x}\\\\[4pt] &amp;\\approx 1{,}64 \\cdot 3,86 + 856{,}47\\\\[4pt] &amp;\\approx 862,80 \\end{aligned}\\] Auch hier gibt es wieder eine kleine Abkürzung: Aufgrund der Symmetrie unserer theoretischen Verteilung gilt für die Konfidenzintervallbreite generell: \\[ \\frac{\\mathit{KIB}}{2} = z_{(1-\\alpha/2)} \\cdot \\sigma_{\\bar{x}} \\tag{4.3} \\] Wir setzen einfach unsere Werte ein: \\[\\begin{aligned} \\frac{\\mathit{KIB}}{2} &amp;= z_{95\\%} \\cdot s_{\\bar{x}}\\\\[4pt] &amp;\\approx1{,}64 \\cdot 3,86\\\\[4pt] &amp;\\approx 6,33 \\end{aligned}\\] Die Intervallgrenzen ergeben sich dann trivial aus \\(\\bar{x} \\pm \\frac{\\mathit{KIB}}{2}\\). 4.4.3 Gesuchtes \\(n\\) Eine letzte Fragerichtung lautet: Wie viele Messwerte müssten vorliegen, um den durchschnittlichen Niederschlag mit einem Konfidenzniveau von 99% und einer Genauigkeit von ± 5 l/m² schätzen zu können? Gegeben sind also das Konfidenzintervall und \\(\\alpha=0{,}01\\), gesucht wird \\(n\\). Wir wissen, dass die Stichprobengröße \\(n\\) den Standardfehler \\(\\sigma_{\\bar{x}}\\) bestimmt. Also benutzen wir zunächst (4.3) und formen um: \\[\\begin{aligned} \\frac{\\mathit{KIB}}{2} &amp;= z_{(1-\\alpha/2)} \\cdot \\sigma_{\\bar{x}}\\\\[4pt] \\sigma_{\\bar{x}} &amp;= \\frac{\\mathit{KIB}}{2\\cdot z_{(1-\\alpha/2)}} \\end{aligned}\\] Durch Einsetzen und mit Blick auf die Tabelle erhalten wir: \\[\\begin{aligned} \\sigma_{\\bar{x}} &amp;= \\frac{10}{2\\cdot z_{99{,}5\\%}}\\\\[4pt] &amp;\\approx \\frac{10}{2\\cdot 2{,}58}\\\\[4pt] &amp;\\approx 1{,}94 \\end{aligned}\\] Dieser Standardfehler \\(\\sigma_{\\bar{x}}\\approx1{,}94\\) würde unseren Anforderungen genügen. Welches \\(n\\) ist nötig, um diesen Standardfehler zu erreichen? Wir formen (2.7) um \\[\\begin{aligned} \\sigma_{\\bar{x}} &amp;= \\frac{\\sigma}{\\sqrt{n}}\\\\[4pt] n &amp;= \\Big(\\frac{\\sigma}{\\sigma_{\\bar{x}}}\\Big)^2 \\end{aligned}\\] und setzen den angestrebten Standardfehler sowie die Standardabweichung der Population (\\(\\sigma=10{,}23\\)) ein: \\[\\begin{aligned} n&amp;=\\Big(\\frac{\\sigma}{\\sigma_{\\bar{x}}}\\Big)^2\\\\[4pt] n&amp;\\approx\\bigg(\\frac{10{,}23}{1{,}94}\\bigg)^2\\\\[4pt] &amp;\\approx27{,}80 \\end{aligned}\\] Wir müssten also 28 Stichproben vorliegen haben. 4.5 Aufgaben Die folgenden Aufgaben sind zur eigenständigen Überprüfung Ihrer Lernleistung gedacht (als Vor- oder Nachbereitung der Vorlesung, oder als Klausurübung) und nicht etwa als Hausaufgabe. 4.5.1 Aufgabe 1 Eine Messreihe habe die Werte: 165 173 155 179 158 142 Führen Sie eine Punktschätzung für \\(\\mu\\) und \\(\\sigma\\) der Grundgesamtheit durch. Welcher Standardfehler für \\(\\bar{x}\\) ist zu erwarten? 4.5.2 Aufgabe 2 Die Sonnenstunden auf einer Ferieninsel (pro Tag, im Jahresdurschnitt) sind annähernd normalverteilt mit einer Standardabweichung von vier Minuten. Der Mittelwert \\(\\mu\\) ist unbekannt, es liegen neun Messwerte vor. Welcher Standardfehler für \\(\\bar{x}\\) ist zu erwarten? Welche Konfidenzintervallbreite korrespondiert mit einem Konfidenzniveau von 95%? Mit welchem Konfidenzniveau lässt sich \\(\\mu\\) auf die Minute genau (± 30 Sekunden) schätzen? Welche Stichprobengröße ist nötig um den Mittelwert mit einer Konfidenzintervallbreite von zwei Minuten und -niveau von 90% zu schätzen? 4.5.3 Aufgabe 3 Sie intressieren sich für das Durchschnittseinkommen (in EUR) der Haushalte eines Stadtteils. Die Varianz ist mit \\(\\sigma^2=4096\\) bekannt. Eine Zufallsstichprobe von 40 befragten Haushalten weist einen Mittelwert von \\(\\bar{x}=2650\\) auf. Wie lautet das 90%-Konfidenzintervall? Mit welcher Wahrscheinlichkeit liegt das Durchschnittseinkommen zwischen 2640 und 2660 EUR? 4.6 Tipps zur Vertiefung YouTube-Kanal Kurzes Tutorium Statistik: Intervallschätzungen - Konfidenzintervalle Kapitel 8 in Klemm (2002) Kapitel 6.26.4 in Bortz und Schuster (2010) Kapitel 5.3.1 in Bahrenberg, Giese und Nipper (2010) 4.7 Quellen Genau genommen ist das nicht ganz korrekt, denn tatsächlich kann der Parameter nur innerhalb oder außerhalb des gefundenen Bereichs liegen. Die Wahrscheinlichkeit, dass ein Parameter in einen bestimmten Bereich fällt, ist damit entweder 0 oder 1. (Bortz und Schuster 2010: 93). Mathematisch korrekt müsste es heißen: Die Wahrscheinlichkeit, dass \\(\\bar{x}\\) zu einer Population gehört, deren Parameter \\(\\mu\\) in diesem Bereich liegt "],["grundlagen-der-teststatistik.html", "Sitzung 5 Grundlagen der Teststatistik 5.1 Lernziele dieser Sitzung 5.2 Statistische Tests 5.3 \\(z\\)-Test 5.4 Die \\(t\\)-Verteilung 5.5 1-Stichproben-\\(t\\)-Test 5.6 Aufgaben 5.7 Tipps zur Vertiefung 5.8 Quellen", " Sitzung 5 Grundlagen der Teststatistik 5.1 Lernziele dieser Sitzung Sie können Hypothesen formulieren. einen \\(z\\)-Test durchführen. einen 1-Stichproben-\\(t\\)-Test durchführen. 5.2 Statistische Tests Gemeinsam mit der Schätzstatistik bildet die Test- bzw. Prüfstatistik jenen Teil statistischer Verfahren, die ausgehend von einer Stichprobenverteilung Rückschlüsse auf die Beschaffenheit von Grundgesamtheiten anstreben (schließende Statistik). Dabei haben Schätz- und Teststatistik jedoch grundlegend verschiedene Vorgehensweisen. Wie in Sitzung 4 besprochen ermöglicht die Schätzstatistik die Angabe statistischer Parameter einer Grundgesamtheit anhand von Stichprobenwerten, und unter Angabe von Wahrscheinlichkeiten. Ziel statistischer Tests hingegen ist es, mit Hilfe von Stichproben Hypothesen (also Vermutungen) über die Grundgesamtheit zu prüfen. Geprüft wird dabei ein empirischer Sachverhalt gegen die Zufälligkeit seiner Realisierung. Ein statistischer Test fragt, ab welcher Größenordnung ein Stichprobenergebnis nicht mehr als zufällig, sondern als signifikant anzusehen ist. Dabei folgt die grundsätzliche Vorgehensweise von (hier behandelten) statistischen Tests immer diesem Schema: Test wählen und Voraussetzungen prüfen Hypothesen formulieren Signifikanzniveau entscheiden Ablehnungsbereich bestimmen Prüfgröße berechnen Ergebnis interpretieren Die einzelnen Schritte werden im Folgenden direkt anhand des \\(z\\)-Tests besprochen. 5.3 \\(z\\)-Test Die mathematischen Grundlagen des \\(z\\)-Tests leiten sich direkt aus der in Sitzung 4 besprochenen Stichprobenverteilung für \\(\\bar{x}\\) ab. Ein illustrierendes Beispiel: Wir wissen, dass die Anzahl der täglichen Besucher*innen einer Eissporthalle annähernd normalverteilt ist, und zwar mit dem arithmetischen Mittel \\(\\mu=94{,}2\\) und der Standardabweichung \\(\\sigma=11{,}8\\). Wir vermuten, dass die Anzahl der Besucher*innen an bewölkten Tagen größer ist, weil an sonnigen Tagen andere Freizeitbeschäftigungen attraktiver sind. An fünf zufälligen bewölkten Tagen zählen wir die Besucher*innen und kommen auf einen Mittelwert der Stichprobe von \\(\\bar{x} = 103{,}0\\). Dieser Wert ist höher als das arithmetische Mittel der Grundgesamtheit (\\(\\mu\\)). Aber heißt das auch, dass unsere Vermutung stimmt? Wir wissen aus Sitzung 4, dass die Stichprobenverteilung einem Standardfehler (\\(\\sigma_{\\bar{x}}\\)) unterliegt (s. 5.1). Ist das Ergebnis also nur zufällig zustande gekommen, oder liegt ein statistisch signifikantes Ergebnis vor? Mit anderen Worten: Ist die Stichprobe überhaupt der Verteilung \\(x_0\\) um \\(\\mu_0\\) entnommen, oder gibt es eine andere Verteilung (\\(x\\) um ein anderes \\(\\mu\\)) für bewölkte Tage, denen unser Stichprobenmittelwert \\(\\bar{x}\\) entstammt? Genau diese Art von Frage versuchen statistische Tests zu beantworten. Abbildung 5.1: Theoretische Stichprobenverteilung (unter Annahme der Nullhypothese) 5.3.1 Test wählen und Voraussetzungen prüfen Je nachdem, was überprüft werden soll, was über die Grundgesamtheit bekannt ist und wie die Stichprobe beschaffen ist, müssen verschiedene Testverfahren angewendet werden. Statistische Tests unterscheiden sich zunächst in Bezug auf ihre Prüfgröße (und sind auch nach ihrer Prüfgröße benannt). Wir werden zunächst den \\(z\\)-Test kennenlernen, der mit dem (uns seit Sitzung 3 bekannten) \\(z\\)-Wert als Prüfgröße arbeitet. Der \\(z\\)-Test hat zum Ziel, den Mittelwert einer Stichprobe mit den zu erwartenden Werten bei einer bekannten Verteilung zu vergleichen. Um den \\(z\\)-Test anwenden zu können, müssen also folgende Voraussetzungen gegeben sein: - Das Ziel der Untersuchung ist es, eine signifikante Abweichung des Mittelwerts festzustellen. - Das arithmetische Mittel \\(\\mu\\) und die Standardabweichung \\(\\sigma\\) der (ursprünglichen) Grundgesamtheit müssen bekannt sein. - Der Test muss anhand einer reinen Zufallsstichprobe erfolgen. - Die Stichprobenverteilung muss (annähernd) normalverteilt sein, das heißt: - entweder die Grundgesamtheit ist (annähernd) normalverteilt, - oder die Stichprobe hat die Größe \\(n\\geq30\\). 5.3.1.1 Beispiel In unserem Beispiel (Besucherzahlen der Eissporthalle) sind diese Voraussetzungen gegeben. Wir können und wollen also einen \\(z\\)-Test durchführen. 5.3.2 Hypothesen formulieren Es müssen immer zwei Hypothesen formuliert werden: die Nullhypothese und die Alternativhypothese. Die Nullhypothese geht immer davon aus, dass es keine Abweichung gibt, die Alternativhypothese formuliert eine Abweichung. Dabei werden zwei Verteilungen konstruiert: Die bekannte Grundgesamtheit (in unserem Beispiel: Besucherzahlen insgesamt) \\(x_0\\) mit Mittelwert \\(\\mu_0\\) und eine neue Verteilung (Besucherzahlen an bewölkten Tagen) \\(x\\) mit Mittelwert \\(\\mu\\). Die Hypothesen sind theoriegeleitet (formulieren also eine begründete Vermutung) und stehen stets am Anfang der statistischen Untersuchung. Es ist unzulässig, sie im Nachhinein anzupassen. 5.3.2.1 Nullhypothese Die Nullhypothese (engl. null hypothesis) geht immer davon aus, das die forscherische Vermutung nicht stimmt. Im \\(z\\)-Test besagt die Nullhypothese, dass es zwischen dem Mittelwert \\(\\mu_0\\) und dem Mittelwert \\(\\mu\\) keinen Unterschied gibt. Generell heißt die Nullhypothese: \\[ H_0 : \\mu = \\mu_0 \\tag{5.1} \\] 5.3.2.2 Alternativhypothese Die Alternativhypothese (engl. alternative hypothesis) stellt die Vermutung dar, die überprüft werden soll. Dabei gibt es zwei unterschiedliche Möglichkeiten: ungerichtete und gerichtete Alternativhypothesen. 5.3.2.2.1 Ungerichtete Alternativhypothese Die ungerichtete Alternativhypothese besagt nur, dass es einen Unterschied zwischen \\(\\mu\\) und \\(\\mu_0\\) gibt, aber nicht in welche Richtung (größer oder kleiner). Sie lautet daher: \\[ H_1 : \\mu \\neq \\mu_0 \\tag{5.2} \\] 5.3.2.2.2 Gerichtete Alternativhypothese Die gerichtete Alternativhyptothese gibt eine Richtung des vermuteten Unterschieds (nach oben oder unten) vor. Sie lautet entweder: \\[ H_1 : \\mu &lt; \\mu_0 \\quad \\textrm{(abwärts gerichtet)} \\tag{5.3} \\] oder: \\[ H_1 : \\mu &gt; \\mu_0 \\quad \\textrm{(aufwärts gerichtet)} \\tag{5.4} \\] 5.3.2.3 Beispiel In unserem Beispiel geben wir eine Richtung vor, denn wir vermuten ja, dass die Besucherzahlen an bewölkten Tagen höher sind. Wir schreiben also: \\[\\begin{aligned} H_0: \\mu = 94{,}2\\\\[4pt] H_1: \\mu&gt;94{,}2 \\end{aligned}\\] 5.3.3 Signifikanzniveau entscheiden Das Signifikanzniveau \\(\\alpha\\) (engl. significance level) entscheidet, wie unwahrscheinlich eine Prüfgröße unter Annahme der Nullhypothese sein muss, damit wir die Nullhypothese ablehnen können (und damit unsere Annahme bestätigen). Übliche Werte für das Signifikanzniveau sind \\(\\alpha=0{,}05\\) oder \\(\\alpha=0{,}01\\). Für die Wahl des Signifikanzniveaus ist jeweils der Kontext entscheidend: Wenn die irrtümliche Bestätigung der forscherischen Annahme gravierende Auswirkungen hat, möchte man das Signifikanzniveau besonders niedrig wählen um diese Art von Fehler auszuschließen. Auch das Signifikanzniveau muss vor der statistischen Erhebung formuliert werden, und es ist unzulässig, es im Nachhinein an das Ergebnis anzupassen. 5.3.3.1 Beispiel Ein Irrtum in der statistischen Signifikanz der Besucherzahl hat vermutlich keine gravierenden Folgen. Wir legen das Signifikanzniveau auf \\(\\alpha=0{,}05\\) fest. 5.3.4 Ablehnungsbereich bestimmen Zusammen mit der (Un-)Gerichtetheit der Alternativhypothese bestimmt das Signifikanzniveau \\(\\alpha\\) den Ablehnungsbereich  also den Bereich für die zu errechnende Prüfgröße \\(z\\), in dem die Nullhypothese abgelehnt würde. Der Ablehnungsbereich für die ungerichtete Alternativhypothese ist \\(\\frac{\\alpha}{2}\\) auf beiden Seiten (s. 5.2). Die kritischen Werte sind dann die Schwellen des Ablehnungsbereich auf beiden Seiten: \\[ z \\leq z_{\\alpha/2} \\quad \\textrm{und} \\quad z \\geq z_{(1-\\alpha/2)} \\quad \\textrm{für} \\quad H_1: \\mu \\neq \\mu_0 \\tag{5.5} \\] Abbildung 5.2: Kritische Werte für \\(z\\) bei ungerichteter Alternativhypothese und \\(\\alpha=0{,}05\\) Bei den gerichteten Alternativhypothesen ist der Ablehnungsbereich jeweils nur auf einer Seite (s. Abbildungen 5.3 und 5.4). Die kritischen Werte ergeben sich aus: \\[ z \\leq z_{\\alpha} \\quad \\textrm{für} \\quad H_1: \\mu &lt; \\mu_0 \\tag{5.6} \\] \\[ z \\geq z_{(1-\\alpha)} \\quad \\textrm{für} \\quad H_1: \\mu &gt; \\mu_0 \\tag{5.6} \\] Abbildung 5.3: Kritischer Wert für \\(z\\) bei gerichteter Alternativhypothese nach unten und \\(\\alpha=0{,}05\\) Abbildung 5.4: Kritischer Wert für \\(z\\) bei gerichteter Alternativhypothese nach oben und \\(\\alpha=0{,}05\\) 5.3.4.1 Beispiel In unserem Beispiel haben wir eine gerichtete Alternativhypothese nach oben und ein Signifikanzniveau von \\(\\alpha=0{,}05\\) verwendet. Der kritische Wert (bei dessen Überschreitung wir die Nullhypothese ablehnen und unsere Vermutung bestätigt sehen) lautet also: \\[ z \\geq z_{95\\%}\\approx 1{,}65 \\] Der Mittelwert unserer Stichprobe fällt höher aus als \\(\\mu\\). Aber übersteigt er auch den kritischen Wert (und ist damit statistisch signifikant)? 5.3.5 Prüfgröße berechnen Für den \\(z\\)-Test ist die Prüfgröße der \\(z\\)-Wert der Stichprobe, und zwar standardisiert in Bezug auf \\(\\mu_0\\) und den Standardfehler (\\(\\sigma_{\\bar{x}}\\)): \\[ z=\\frac{\\bar{x}-\\mu_0}{\\sigma_{\\bar{x}}} \\tag{5.7} \\] Wie wir bereits wissen, ergibt sich der Standardfehler (\\(\\sigma_{\\bar{x}}\\)) wiederum aus der Stichprobengröße (\\(n\\)) und der Standardabweichung der Grundgesamtheit (\\(\\sigma\\)): \\[ \\sigma_{\\bar{x}}=\\frac{\\sigma}{\\sqrt{n}} \\tag{5.8} \\] Durch einsetzen ergibt sich die generelle Formel für die Prüfgröße des \\(z\\)-Tests: \\[ z=\\sqrt{n}\\cdot\\frac{\\bar{x}-\\mu_0}{\\sigma} \\tag{3.2} \\] Das grundsätzliche Schema dieser Formel werden wir in anderen Tests wiedererkennen. 5.3.5.1 Beispiel An dieser Stelle (also nachdem wir uns für einen Test und ein Signifikanzniveau entschieden und den kritischen Wert berechnet haben) dürften wir streng genommen erst die Stichprobe erheben. Diese ergibt bei \\(n=5\\) den Mittelwert \\(\\bar{x}=103{,}0\\). Die Verteilung \\(x_0\\) (also unter Annahme der Nullhypothese) hatte die Kennwerte \\(\\mu_0=94{,}2\\) und \\(\\sigma=11{,}8\\). Wir setzen ein in die Formel aus (3.2): \\[\\begin{aligned} z&amp;=\\sqrt{n}\\cdot\\frac{\\bar{x}-\\mu_0}{\\sigma}\\\\[4pt] &amp;\\approx\\sqrt{5}\\cdot\\frac{103{,}0-94{,}2}{11{,}8}\\\\[4pt] &amp;\\approx1{,}67 \\end{aligned}\\] 5.3.6 Ergebnis inerpretieren Je nachdem, ob die Prüfgröße in den Ablehnungsbereich fällt (ob der kritische Wert also unter- bzw. überschritten wird), können wir die Nullhypothese ablehnen (und damit unsere Alternativhypothese bestätigen) oder nicht. Eine Ablehnung der Nullhypothese bedeutet, dass wir ein statistisch signifikantes Ergebnis zugunsten unserer Vermutung vorliegen haben. Diese Art von Ergebnis wird oft falsch interpretiert. Bei einem Signifikanzniveau von \\(\\alpha=0{,}01\\) heißt das zum Beispiel, dass die beobachteten Werte nur mit 1% Wahrscheinlichkeit vorkommen, wenn unsere Vermutung nicht stimmt. Wichtig dabei: Das ist etwas ganz anderes als zu behaupten, dass unsere Vermutung zu 99% stimme. Über die Wahrscheinlichkeit, dass eine Hypothese stimmt (oder nicht) können wir mit den Methoden der klassischen Statistik keine Aussage machen! 5.3.6.1 Beispiel In unserem Beispiel liegt der \\(z\\)-Wert knapp über dem kritischen Wert von 1,65. Wir können also die Nullhypothese ablehnen und unsere Alternativhypothese annehmen. Unsere statistische Untersuchung hat gezeigt, dass die Eissporthalle an bewölkten Tagen besser besucht ist als an sonnigen (und zwar mit Signifikanzniveau \\(\\alpha=0,05\\)). Gut, dass wir eine gerichtete Alternativhypothese aufgestellt haben. Hätten wir nur vermutet, dass sich die Besucherzahlen je nach Wetter unterscheiden (ohne Angabe einer Richtung), dann wäre der kritische Wert nicht erreicht worden und wir hätten die Nullhypothese beibehalten müssen. Hinterher die Hypothesen anzupassen ist natürlich nicht zulässig! 5.4 Die \\(t\\)-Verteilung Wenn die Standardabweichung \\(\\sigma\\) eines Merkmals in der Grundgesamtheit unbekannt ist, kann sie durch die Standardabweichung \\(s\\) der Stichprobe geschätzt werden (s. Sitzung 4). Dann ist die Stichprobenverteilung für \\(\\bar{x}\\) jedoch nicht mehr normalverteilt, sondern sie folgt einer \\(t\\)-Verteilung. Im Gegensatz zur Standardnormalverteilung (die wir für den \\(z\\)-Test benutzen) gibt es aber nicht nur eine \\(t\\)-Verteilung, sondern die Form der \\(t\\)-Verteilung hängt von so genannten Freiheitsgraden (engl. degrees of freedom) ab. Mit steigender Zahl der Freiheitsgrade nähert sich die \\(t\\)-Verteilung einer Standardnormalverteilung an (s. 5.5). Abbildung 5.5: \\(t\\)-Verteilungen mit verschiedenen Freiheitsgraden 5.4.1 Freiheitsgrade In Anlehnung an Bortz und Schuster (2010) kürzen wir Freiheitsgrade mit \\(\\mathit{df}\\) ab. Dort findet sich auch eine brauchbare Erklärung dieses Phänomens: Die Freiheitsgrade, welche mit einem Kennwert verbunden sind, entsprechen der Anzahl der Werte, die bei seiner Berechnung frei variieren können. Der Mittelwert \\(\\bar{x}\\) besitzt beispielsweise \\(n\\) Freiheitsgrade, weil es keinerlei Bedingung gibt, der die \\(n\\) Werte genügen müssen. Dies ist für die Varianz \\(s^2=\\mathit{QS}/(n-1)\\) nicht der Fall. Nur \\(n-1\\) Abweichungen, welche in die Berechnung der Quadratsumme \\(\\mathit{QS}=\\sum_i(x_i-\\bar{x})^2\\) eingehen, können frei variieren. [D]ie Summe der Abweichungen von ihrem Mittelwert [ist] null, d.h. \\(\\sum_i(x_i-\\bar{x})=0\\). Von \\(n\\) Abweichungen können deshalb nur \\(n - 1\\) frei variieren. Ergeben sich beispielsweise bei einer Stichprobe aus drei Werten die Abweichungen \\(x_1 - \\bar{x} = -4\\) und \\(x_2 - \\bar{x} = 0\\), muss zwangsläufig \\(x_3 -\\bar{x} = 4\\) sein, damit die Summe aller Abweichungen null ergibt. Bei der Varianzberechnung ist eine der \\(n\\) Abweichungen festgelegt, d.h. die Varianz hat nur \\(n - 1\\) Freiheitsgrade. Man schreibt die Stichprobenvarianz deshalb gelegentlich auch als \\(s^2 = \\mathit{QS}/\\mathit{df}\\). Da die Varianz mit \\(n - 1\\) Freiheitsgraden verbunden ist, gilt dies auch für die Standardabweichung \\(s\\). (Bortz und Schuster 2010: 121) 5.5 1-Stichproben-\\(t\\)-Test Der 1-Stichproben-\\(t\\)-Test vergleicht (wie der \\(z\\)-Test) die Werte einer Stichprobe mit der Grundgesamtheit. Das Vorgehen ist dabei analog zum \\(z\\)-Test, mit dem einzigen Unterschied, dass eine \\(t\\)-Verteilung mit \\((n-1)\\) Freiheitsgraden herangezogen wird. Wir besprechen den 1-Stichproben-\\(t\\)-Test direkt an einem Beispiel: Beim Frankfurter Amt für Wohnungswesen betrage die durchschnittliche Bearbeitungsdauer von Anträgen auf Wohngeld 30,2 Tage und sei normalverteilt. Wir vermuten, dass die Bearbeitungszeit zu Anfang des Wintersemesters höher ist als im Jahresdurchschnitt und planen eine zufällige Stichprobe von 12 Anträgen mit Einreichungsdatum im Oktober. 5.5.1 Test wählen und Voraussetzungen prüfen Um den 1-Stichproben-\\(t\\)-Test durzuführen müssen folgende Voraussetzungen erfüllt sein: Das Ziel der Untersuchung ist es, eine statistisch signifikante Abweichung des Mittelwerts einer Stichprobe im Vergleich zu einer Grundgesamtheit festzustellen. Das zu untersuchende Merkmal ist in der Grundgesamtheit normalverteilt. Das arithmetische Mittel (\\(\\mu\\)) des Merkmals in der Grundgesamtheit ist bekannt. (Im Gegensatz zum \\(z\\)-Test ist \\(\\sigma\\) hier unbekannt!) Der Test erfolgt anhand einer reinen Zufallsstichprobe. 5.5.1.1 Beispiel In unserem Beispiel (Bearbeitungszeit Wohngeldanträge) sind diese Bedingungen erfüllt und wir können einen 1-Stichproben-\\(t\\)-Test durchführen. 5.5.2 Hypothesen formulieren Die Hypothesen werden genauso wie beim \\(z\\)-Test formuliert: 5.5.2.1 Nullhypothese \\[ H_0 : \\mu = \\mu_0 \\tag{5.1} \\] 5.5.2.2 Alternativhypothese \\[ H_1 : \\mu \\neq \\mu_0 \\quad \\textrm{(ungerichtet)} \\tag{5.2} \\] oder \\[ H_1 : \\mu &lt; \\mu_0 \\quad \\textrm{(abwärts gerichtet)} \\tag{5.3} \\] oder \\[ H_1 : \\mu &gt; \\mu_0 \\quad \\textrm{(aufwärts gerichtet)} \\tag{5.4} \\] 5.5.2.3 Beispiel In unserem Beispiel geben wir eine Richtung vor, denn wir vermuten ja, dass die Bearbeitungsdauer zu Semesteranfang höher ist. Wir schreiben also: \\[\\begin{aligned} H_0: \\mu = 30{,}2\\\\ H_1: \\mu&gt;30{,}2 \\end{aligned}\\] 5.5.3 Signifikanzniveau entscheiden Wie beim \\(z\\)-Test entscheidet das Signifikanzniveau \\(\\alpha\\), wie unwahrscheinlich eine Prüfgröße unter Annahme der Nullhypothese sein muss, damit wir die Nullhypothese ablehnen können (und damit unsere Annahme bestätigen). Übliche Werte für das Signifikanzniveau sind auch beim \\(t\\)-Test \\(\\alpha=0{,}05\\) oder \\(\\alpha=0{,}01\\). 5.5.3.1 Beispiel Ein Irrtum zugunsten der Alternativhypothese hat bei unserer Untersuchung keine gravierenden Folgen. Angenommen, wir wollen uns in der Analyse trotzdem ganz sicher sein. Dann entscheiden wir uns für das Signifikanzniveau \\(\\alpha=0{,}01\\). 5.5.4 Ablehnungsbereich bestimmen Genau wie beim \\(z\\)-Test bestimmt das Signifikanzniveau \\(\\alpha\\) den Ablehnungsbereich  also den Bereich für die zu errechnende Prüfgröße \\(t\\), in dem die Nullhypothese abgelehnt würde. Der Ablehnungsbereich für die ungerichtete Alternativhypothese ist \\(\\frac{\\alpha}{2}\\) auf beiden Seiten. Die kritischen Werte sind dann die Schwellen des Ablehnungsbereich auf beiden Seiten: \\[ t \\leq t_{\\mathit{df};\\alpha/2} \\quad \\textrm{und} \\quad t \\geq t_{\\mathit{df};(1-\\alpha/2)} \\quad \\textrm{für} \\quad H_1: \\mu \\neq \\mu_0 \\tag{5.5} \\] Bei den gerichteten Alternativhypothesen ist der Ablehnungsbereich jeweils nur auf einer Seite. Die kritischen Werte ergeben sich aus: \\[ t \\leq t_{\\mathit{df};\\alpha} \\quad \\textrm{für} \\quad H_1: \\mu &lt; \\mu_0 \\tag{5.6} \\] \\[ t \\geq t_{\\mathit{df};(1-\\alpha)} \\quad \\textrm{für} \\quad H_1: \\mu &gt; \\mu_0 \\tag{5.6} \\] Die kritischen Werte für \\(t\\) bei gegebenem Freiheitsgrad \\((n-1)\\) und Flächenabschnitt lassen sich aus der Formelsammlung ablesen. Dabei ist zu beachten, dass aufgrund der Symmetrie die Werte für Flächenanteile unter 50% nicht in der Tabelle verzeichnet sind. Es gilt die Formel: \\[ P(-t_\\mathit{df})=1-P(t_\\mathit{df}) \\tag{5.9} \\] So ist zum Beispiel der Wert für \\(t_{5;1\\%}=-t_{5;99\\%}=-3{,}365\\). 5.5.4.1 Beispiel In unserem Beispiel haben wir eine gerichtete Alternativhypothese nach oben und ein Signifikanzniveau von \\(\\alpha=0{,}01\\) verwendet. Wir haben uns zudem für eine Stichprobengröße von \\(n=12\\) entschieden, woraus der Freiheitsgrad \\(\\mathit{df}=n-1=11\\) resultiert. Der kritische Wert (bei dessen Überschreitung wir die Nullhypothese ablehnen und unsere Vermutung bestätigt sehen) lautet also: \\[\\begin{aligned} t &amp;\\geq t_{\\mathit{df};(1-\\alpha)}\\\\[4pt] t &amp;\\geq t_{11;99\\%}\\\\[4pt] t &amp;\\geq 2,718 \\end{aligned}\\] Graphisch ist der Ablehnungsbereich für unser Beispiel in 5.6 dargestellt. Abbildung 5.6: Ablehnungsbereich bei gerichteter Alternativhypothese nach oben, \\(n=12\\) und \\(\\alpha=0{,}01\\) 5.5.5 Prüfgröße berechnen Die Formel für die Berechnung der Prüfgröße \\(t\\) im 1-Stichproben-\\(t\\)-Test lautet ganz ähnlich wie die für die Prüfgröße \\(z\\) im \\(z\\)-Test  mit dem Unterschied, dass statt der (hier unbekannten) Standardabweichung der Grundgesamtheit (\\(\\sigma\\)) die Standardabweichung der Stichprobe (\\(s\\)) eingesetzt wird: \\[ t=\\sqrt{n}\\cdot\\frac{\\bar{x}-\\mu_0}{s} \\tag{5.10} \\] Zum direkten Vergleich noch einmal die Prüfgröße im \\(z\\)-Test: \\[ z=\\sqrt{n}\\cdot\\frac{\\bar{x}-\\mu_0}{\\sigma} \\] 5.5.5.1 Beispiel (ausführlich) Wir erheben die Stichprobe von \\(n=12\\) Anträgen im Oktober und erhalten folgende Werte für die Bearbeitungsdauer (in Tagen): \\[ 45\\quad41\\quad37\\quad41\\quad35\\quad44\\quad34\\quad44\\quad38\\quad41\\quad39\\quad36 \\] Wir errechnen zunächst das arithmetische Mittel \\(\\bar{x}\\) (s. Sitzung 2): \\[\\begin{aligned} \\bar{x}&amp;=\\frac{\\sum\\limits_{i=1}^nx_i}{n}\\\\[5pt] &amp;=\\frac{45+41+37+41+35+44+34+44+38+41+39+36}{12}\\\\ &amp;\\approx 39{,}58 \\end{aligned}\\] Damit können wir die Standardabweichung \\(s\\) berechnen: \\[\\begin{aligned} s&amp;=\\sqrt{\\frac{\\sum\\limits_{i=1}^n(x_i-\\bar{x})^2}{n-1}}\\\\[6pt] &amp;\\approx\\sqrt{\\frac{29{,}38+2{,}02+6{,}66+2{,}02+20{,}98+19{,}54+31{,}14+19{,}54+2{,}5+2{,}02+0{,}34+12{,}82}{11}}\\\\ &amp;\\approx 3{,}67 \\end{aligned}\\] Schließlich setzen wir diese Werte in die Formel für die Prüfgröße \\(t\\) ((5.10)) ein: \\[\\begin{aligned} t&amp;=\\sqrt{n}\\cdot\\frac{\\bar{x}-\\mu_0}{s}\\\\[6pt] &amp;\\approx\\sqrt{12}\\cdot\\frac{39{,}58-30{,}2}{3{,}67}\\\\ &amp;\\approx8{,}854 \\end{aligned}\\] 5.5.6 Ergebnis interpretieren Genau wie beim \\(z\\)-Test kommt es darauf an, ob die Prüfgröße in den Ablehnungsbereich fällt (ob der kritische Wert also unter- bzw. überschritten wird). Wenn dies der Fall ist, können wir die Nullhypothese ablehnen (und damit unsere Alternativhypothese bestätigen). Wenn nicht, müssen wir die Nullhypothese beibehalten. 5.5.6.1 Beispiel In unserem Beispiel liegt der \\(t\\)-Wert deutlich über dem kritischen Wert von 2,718. Wir können also die Nullhypothese ablehnen und unsere Alternativhypothese annehmen. Unsere statistische Untersuchung hat gezeigt, dass die Bearbeitungsdauer von Anträgen, die im Oktober eingehen, länger ist als im Jahresdurchschnitt (und zwar mit Signifikanzniveau \\(\\alpha=0,01\\)). 5.6 Aufgaben 5.6.1 Aufgabe 1 Sie interessieren sich für die durchschnittliche Haushaltsgröße in Frankfurt im europäischen Vergleich. In der EU sei die durchschnittliche Haushaltsgröße 2,30 Personen mit einer Standardabweichung von 1,42. Sie vermuten, dass Frankfurter Haushalte sich in ihrer Größe vom europäischen Durchschnitt unterscheiden, können aber nicht sagen, in welche Richtung. Welche Stichprobengröße ist für einen \\(z\\)-Test in diesem Fall nötig und warum? Formulieren Sie Null- und Alternativhypothese. Sie entscheiden Sich für ein Signifikanzniveau von \\(\\alpha=0{,}05\\). Notieren Sie die kritischen Werte. Eine Stichprobe von 40 Frankfurter Haushalten ergibt eine durchschnittliche Größe von 1,82. Berechnen Sie die Prüfgröße \\(z\\). Wie bewerten Sie das Ergebnis? 5.6.2 Aufgabe 2 Bestimmen Sie die folgenden kritischen Werte: \\(t_{4;0,5\\%}\\) \\(t_{19;0,1\\%}\\) \\(t_{7;2,5\\%}\\) \\(t_{13;5\\%}\\) \\(t_{11;97,5\\%}\\) \\(t_{3;95\\%}\\) \\(t_{6;99,5\\%}\\) \\(t_{16;99,9\\%}\\) \\(t_{5;99\\%}\\) \\(t_{20;1\\%}\\) 5.6.3 Aufgabe 3 Die Prüfungsergebnisse für eine Klausur im Geographiestudium seien normalverteilt mit einer mittleren Punktzahl von 61,5 und einer Standardabweichung von 10,3. Sie vermuten, dass berufstätige Studierende im Durchschnitt schlechter abschneiden, weil ihnen die Vorbereitungszeit fehlt. Eine Zufallsstichprobe berufstätiger Studierender ergibt die Prüfungsergebnisse: 42 78 46 65 Prüfen Sie Ihre Vermutung. Begründen Sie die Wahl des Tests und des Signifikanzniveaus. 5.6.4 Aufgabe 4 Sie vermuten, dass Angestellte mit Migrationshintergrund in einem bestimmten Betrieb weniger als das Durchschnittsgehalt verdienen. Die Personalabteilung bestätigt Ihnen gegenüber die annähernde Normalverteilung der Bruttogehälter mit Mittelwert \\(\\mu=3042,43\\) (in EUR). Sie planen, das Bruttogehalt von sechs zufälligen Angestellten mit Migrationshintergrund direkt zu ermitteln. Welchen Test führen Sie durch? Formulieren Sie die Hypothesen. Bestimmen Sie den kritischen Wert bei Signifikanzniveau \\(\\alpha=0{,}01\\). 5.6.5 Aufgabe 5 (Fortführung von Aufgabe 4) Sie ermitteln die folgenden Werte (in EUR): \\[ 2927,35\\quad2930,68\\quad2903,58\\quad3032,59\\quad3013,37\\quad2979,4 \\] Berechnen Sie die Prüfgröße. Welche Schlüsse ziehen Sie aus der Untersuchung? 5.7 Tipps zur Vertiefung YouTube-Kanal Kurzes Tutorium Statistik: p-Wert, Nullhypothese, Signifikanzniveau - die Idee erklärt YouTube-Kanal Benedict K: p-Wert: einseitiger und beidseitiger Hypothesentest / Signifikanztest - erklärt YouTube-Kanal Kurzes Tutorium Statistik: Einstichproben t-Test Kapitel 7, 8.1 in Bortz und Schuster (2010) Kapitel 5.5.2 in Bahrenberg, Giese und Nipper (2010) Kapitel 9 in Klemm (2002) 5.8 Quellen "],["testverfahren-mit-zwei-stichproben.html", "Sitzung 6 Testverfahren mit zwei Stichproben 6.1 Lernziele dieser Sitzung 6.2 Statistische Tests 6.3 2-Stichproben-\\(t\\)-Test 6.4 Die \\(F\\)-Verteilung 6.5 \\(F\\)-Test 6.6 Fehlerarten 6.7 Aufgaben 6.8 Tipps zur Vertiefung 6.9 Quellen", " Sitzung 6 Testverfahren mit zwei Stichproben 6.1 Lernziele dieser Sitzung Sie können einen 2-Stichproben-\\(t\\)-Test durchführen. einen \\(F\\)-Test durchführen. Fehler 1. und 2. Art unterscheiden. 6.2 Statistische Tests In Sitzung 5 haben wir mit dem \\(z\\)-Test und dem 1-Stichproben-\\(t\\)-Test die ersten Testverfahren kennengelernt. In dieser Sitzung kommt der 2-Stichproben-\\(t\\)-Test sowie der \\(F\\)-Test dazu. Das grundsätzliche Verfahren bleibt dabei stets das gleiche. Zur Erinnerung noch einmal die sechs Schritte: Test auswählen und Voraussetzungen prüfen Hypothesen formulieren Signifikanzniveau entscheiden Ablenhnungsbereich bestimmen Prüfgröße berechnen Ergebnis interpretieren 6.3 2-Stichproben-\\(t\\)-Test Bei der folgenden Variante des \\(t\\)-Tests (und beim \\(F\\)-Test) wird nicht wie gehabt eine Stichprobe auf signifikante Abweichungen von der Grundgesamtheit überprüft, sondern zwei Stichproben auf signifikante Abweichungen voneinander. An den sechs Schritten ändert sich nichts. Den 2-Stichproben-\\(t\\)-Test gibt es je nach Voraussetzungen bzw. Annahmen in vielen unterschiedlichen Varianten. In dieser Veranstaltung wird nur eine bestimmte (vergleichsweise einfache) Variante behandelt. In der Praxis geht es aber oft darum, für ganz bestimmte empirische Bedinungen den richtigen 2-Stichproben-\\(t\\)-Test auszuwählen. Die hier behandelte Variante soll mit folgendem Beispiel illustriert werden: Wir interessieren uns für die Mietpreise von kleine Gewerbeflächen in den beiden Frankfurter Stadtteilen Höchst und Praunheim. Wir vermuten, dass es einen signifikanten Unterschied gibt, wissen aber nicht in welche Richtung. Wir planen eine Befragung von je 6 Mieter*innen von kleinen Gewerberäumen, die nach Zufallsprinzip ausgewählt werden. 6.3.1 Test wählen und Voraussetzungen prüfen Der hier behandelte 2-Stichproben-\\(t\\)-Test hat folgende Voraussetzungen (bzw. Annahmen): Es soll untersucht werden, ob ein Merkmal in zwei Stichproben signifikant voneinander abweicht. Die Stichproben sind einfache Zufallsstichproben und unabhängig voneinander erhoben. Die Stichproben haben dieselbe Anzahl an Elementen (\\(n_1=n_2\\)). Das Merkmal ist grundsätzlich (annähernd) normalverteilt. Die Varianzen der zu vergleichenden Populationen sind gleich (\\(\\sigma^2_1=\\sigma^2_2\\)).4 6.3.1.1 Beispiel Probleme bereiten hier die Voraussetzungen der Normalverteilung und der gleichen Varianzen. Mit der Annahme der Normalverteilung können wir leben (weil wir uns mit Statistik gut auskennen und wissen, dass der \\(t\\)-Test robust auf nicht-ganz-normalverteilte Merkmale reagiert). Wenn sich während des Tests jedoch herausstellen sollte, dass die Varianzen zu unterschiedlich sind, müssten wir das Vorgehen neu überdenken. 6.3.2 Hypothesen formulieren Im Unterschied zu zuvor besprochenen Verfahren gibt es hier keine übergeordnete Grundgesamtheit, und damit kein \\(\\mu_0\\). Stattdessen werden Hypothesen über die Populationen der beiden Stichproben (\\(\\mu_1\\) und \\(\\mu_2\\)) formuliert. 6.3.2.1 Nullhypothese Die Nullhypothese geht davon aus, dass es keinen Unterschied zwischen den beiden Populationen gibt. Sie lautet daher: \\[ H_0 : \\mu_1 = \\mu_2 \\tag{6.1} \\] 6.3.2.2 Alternativhypothese Die Alternativhypothese stellt üblicherweise die forscherische Vermutung dar, die überprüft werden soll. Dabei gibt es auch hier zwei unterschiedliche Möglichkeiten: ungerichtete und gerichtete Alternativhypothesen. 6.3.2.2.1 Ungerichtete Alternativhypothese Die ungerichtete Alternativhypothese besagt nur, dass es einen Unterschied zwischen \\(\\mu_1\\) und \\(\\mu_2\\) gibt, aber nicht in welche Richtung (größer oder kleiner). Sie lautet daher: \\[ H_1 : \\mu_1 \\neq \\mu_2 \\tag{6.2} \\] 6.3.2.2.2 Gerichtete Alternativhypothese Die gerichtete Alternativhyptothese gibt eine Richtung des vermuteten Unterschieds vor. Sie lautet entweder: \\[ H_1 : \\mu_1 &lt; \\mu_2 \\tag{6.3} \\] oder: \\[ H_1 : \\mu_1 &gt; \\mu_2 \\tag{6.4} \\] 6.3.2.3 Beispiel Wir vermuten zwar einen Unterschied, wissen aber nicht in welche Richtung. Deshalb formulieren wir neben der Nullhypothese eine ungerichtete Alternativhypothese: \\[\\begin{aligned} H_0 : \\mu_1 = \\mu_2\\\\[4pt] H_1 : \\mu_1 \\neq \\mu_2 \\end{aligned}\\] 6.3.3 Signifikanzniveau entscheiden Wie auch sonst sind übliche Werte hier \\(\\alpha=0{,}01\\) und \\(\\alpha=0{,}05\\). 6.3.3.1 Beispiel Wir entscheiden uns für das Signifikanzniveau \\(\\alpha=0{,}05\\). 6.3.4 Ablehnungsbereich bestimmen Der kritische Wert wird genau wie bei dem 1-Stichproben-\\(t\\)-Test aus der Formelsammlung abgelesen. Der einzige (wichtige!) Unterschied ist die Bestimmung der Freiheitsgrade: Bei zwei Stichproben der Größe \\(n\\) werden die Freiheitsgrade bestimmt durch: \\[ \\mathit{df}=2\\cdot n -2 \\tag{6.5} \\] 6.3.4.1 Beispiel Wir planen mit je 6 Stichproben. Deswegen berechnen wir die Freiheitsgrade: \\[\\begin{aligned} \\mathit{df}&amp;=2\\cdot n -2\\\\[4pt] &amp;=2\\cdot6-2=10 \\end{aligned}\\] Kritische Werte gibt es nun in beide Richtungen. Aufgrund der Symmetrie der \\(t\\)-Verteilung reicht es, wenn wir einen Wert (mit \\(\\alpha=0{,}05\\)) nachschlagen: \\[\\begin{aligned} t &amp;\\leq t_{\\mathit{df};\\alpha/2} \\quad \\textrm{und} \\quad t \\geq t_{\\mathit{df};(1-\\alpha/2)}\\\\[4pt] t &amp;\\leq t_{10;2{,}5\\%} \\quad \\textrm{und} \\quad t \\geq t_{10;97{,}5\\%}\\\\[4pt] t &amp;\\leq -2{,}228 \\quad \\textrm{und} \\quad t \\geq 2{,}228 \\end{aligned}\\] 6.3.5 Prüfgröße berechnen Bei zwei Stichproben mit Mittelwert \\(\\bar{x}_1\\) bzw. \\(\\bar{x}_1\\) und Varianz \\(s^2_1\\) bzw. \\(s^2_2\\) lautet die Formel zur Bestimmung der Prüfgröße \\(t\\): \\[ t=\\frac{\\bar{x}_1-\\bar{x}_2}{\\sqrt{\\frac{s^2_1+s^2_2}{n}}} \\tag{6.6} \\] 6.3.5.1 Beispiel Wir erheben folgende Werte für die Kaltmiete pro m²: \\[\\begin{aligned} \\textrm{Höchst} (x_1):\\quad7{,}96\\quad8{,}46\\quad7{,}13\\quad8{,}95\\quad7{,}62\\quad8{,}22\\\\[4pt] \\textrm{Praunheim} (x_2):\\quad5{,}54\\quad5{,}80\\quad8{,}70\\quad7{,}99\\quad6{,}23\\quad6{,}75 \\end{aligned}\\] Für die arithmetischen Mittel ergibt sich (s. Sitzung 2): \\[\\begin{aligned} \\bar{x}_1\\approx8{,}06\\\\[4pt] \\bar{x}_2\\approx6{,}84 \\end{aligned}\\] Die Varianzen (s. Sitzung 2): \\[\\begin{aligned} s^2_1\\approx0{,}41\\\\[4pt] s^2_2\\approx1{,}59 \\end{aligned}\\] Diese Varianzen sehen auf den ersten Blick sehr unterschiedlich aus, was ein Problem ist: Der 2-Stichproben-\\(t\\)-Test hat ja zur Annahme, dass die Varianzen in den beiden Populationen gleich sind. Andererseits sind ja auch die Stichprobenvarianzen zu einem gewissen Grad Zufallsprodukte, und diese beiden Varianzen bewegen sich auch irgendwie noch in der selben Größenordnung  schließlich könnten sie auch 0,1 und 20 lauten. Wir entscheiden uns zunächst dazu, den Test fortzuführen und lernen gleich eine Methode kennen, wie wir überprüfen können, ob das auch gerechtfertigt ist. Um die Prüfgröße \\(t\\) zu bestimmen, setzen wir einfach unsere Stichprobenwerte in die Formel aus (6.6) ein: \\[\\begin{aligned} t&amp;=\\frac{\\bar{x}_1-\\bar{x}_2}{\\sqrt{\\frac{s^2_1+s^2_2}{n}}}\\\\[6pt] &amp;\\approx\\frac{8{,}06-6{,}84}{\\sqrt{\\frac{0{,}41+1{,}59}{6}}}\\\\[4pt] &amp;\\approx2{,}113 \\end{aligned}\\] 6.3.6 Ergebnis interpretieren Genau wie bei den anderen Tests wird je nach erreichen des kritischen Werts (des Ablehnungsbereichs) die Nullhypothese verworfen oder beibehalten. 6.3.6.1 Beispiel Der kritische Wert von \\(t \\geq 2{,}228\\) wurde nicht überschritten. Wir müssen die Nullhypothese beibehalten, d.h. wir konnten keinen signifikanten Unterschied zwischen den Mietpreisen in Höchst und Praunheim feststellen (\\(\\alpha=0{,}05\\)). 6.4 Die \\(F\\)-Verteilung Die Prüfgröße \\(F\\) im \\(F\\)-Test ist unter Annahme der Nullhypothese \\(F\\)-verteilt. Im Gegensatz zu den Verteilungen von \\(z\\) und \\(t\\) ist die \\(F\\)-Verteilung nicht symmetrisch und nimmt nur positive Werte an (s. 6.1). Dazu ist die \\(F\\)-Verteilung nicht wie \\(t\\) von einem, sondern von zwei Freiheitsgraden abhängig. Die Reihenfolge dieser Freiheitsgrade ist auch wichtig: Wir sprechen vom Zähler-Freiheitsgrad (\\(\\mathit{df}_1\\)) und vom Nenner-Freiheitsgrad (\\(\\mathit{df}_2\\)). Die \\(F\\)-Verteilung wird also notiert mit: \\(F_{\\mathit{df}_1;\\mathit{df}_2}\\) Abbildung 6.1: \\(F\\)-Verteilungen mit verschiedenen Freiheitsgraden 6.5 \\(F\\)-Test Auch der \\(F\\)-Test untersucht zwei unabhängige Stichproben. Er unterscheidet sich jedoch insofern grundlegend von den zuvor besprochenen Testverfahren, als dass sein Untersuchungsgegenstand nicht der Mittelwert (\\(\\mu\\)) sondern die Varianz (\\(\\sigma^2\\)) der beiden Populationen ist. Die Prüfgröße \\(F\\) ist dann unter Annahme der Nullhypothese \\(F\\)-verteilt. Unser Beispiel ist eine Fortführung des vorigen Beispiels für den 2-Stichproben-\\(t\\)-Test (Mietpreise für Gewerbeflächen). Uns interessiert: Sind die Varianzen eventuell so unterschiedlich, dass wir den obigen \\(t\\)-Test gar nicht hätten durchführen dürfen? 6.5.1 Test wählen und Voraussetzungen prüfen Das Ziel des \\(F\\)-Tests ist die Feststellung eines signifikanten Unterschieds in der Varianz von zwei Populationen. Die Voraussetzungen lauten: Ausgangspunkt sind zwei unabhängig voneinander erhobene Stichproben (die aber grundsätzlich unterschiedlich groß sein dürfen). Das Merkmal ist in beiden Populationen (annähernd) normalverteilt. 6.5.1.1 Beispiel Die Voraussetzung der Normalverteilung ist hier besonders wichtig, denn der Test wird bei anderen Verteilungen stark verfälscht. (Der \\(F\\)-Test ist also nicht robust, was die Normalverteilung angeht.) Wir müssen also explizit die Annahme treffen, dass die Mietpreise annähernd normalverteilt sind. Das ist einerseits nicht ganz abwegig, andererseits würden wir in der Praxis unsere statistische Untersuchung dadurch angreifbar machen. 6.5.2 Hypothesen formulieren Alles wie gehabt  nur, dass es um die Varianz \\(\\sigma^2\\) der jewiligen Populationen geht. 6.5.2.1 Nullhypothese \\[ H_0: \\sigma^2_1=\\sigma^2_2 \\tag{6.7} \\] 6.5.2.2 Alternativhypothesen 6.5.2.2.1 Ungerichtet \\[ H_1: \\sigma^2_1\\neq\\sigma^2_2 \\tag{6.8} \\] 6.5.2.2.2 Gerichtet \\[ H_1: \\sigma^2_1&gt;\\sigma^2_2 \\tag{6.9} \\] oder \\[ H_1: \\sigma^2_1&lt;\\sigma^2_2 \\tag{6.10} \\] 6.5.2.3 Beispiel Die Nullhypothese ist einfach: \\[ H_0: \\sigma^2_1=\\sigma^2_2 \\] Bei der Alternativhypothese ist die Ausgangslage, dass wir empirisch einen Unterschied zwischen \\(s^2_1\\approx0{,}41\\) und \\(s^2_2\\approx1{,}59\\) festgestellt haben. Die Frage, ob die Varianz der Mietpreise in Höchst tatsächlich signifikant kleiner ist, wird übersetzt in die Alternativhypothese: \\[ H_1: \\sigma^2_1&lt;\\sigma^2_2 \\] Interessanterweise wäre hier (zur Abwechslung) das forscherische Interesse, die Nullhypothese beizubehalten  denn wir wollen ja den \\(t\\)-Test durchführen dürfen. 6.5.3 Signifikanzniveau entscheiden Die Logik ist hier genau dieselbe: Wie unwahrscheinlich muss das empirische Ergebnis unter Annahme der Nullhypothese sein, damit wir diese ablehnen (müssen)? 6.5.3.1 Beispiel Wir entscheiden uns für das (für unsere Zwecke sehr übliche) Signifikanzniveau von \\(\\alpha=0{,}05\\). 6.5.4 Ablehnungsbereich bestimmen Für die ungerichtete Alternativhypothese sind die kritischen Werte: \\[ F \\leq F_{\\mathit{df}_1;\\mathit{df}_2;\\alpha/2} \\quad \\textrm{und} \\quad F \\geq F_{\\mathit{df}_1;\\mathit{df}_2;(1-\\alpha/2)} \\tag{6.11} \\] Für die gerichtete Alternativhypothese: \\[ F \\leq F_{\\mathit{df}_1;\\mathit{df}_2;\\alpha} \\tag{6.12} \\] bzw. \\[ F \\geq F_{\\mathit{df}_1;\\mathit{df}_2;(1-\\alpha)} \\tag{6.13} \\] Die Besonderheit der \\(F\\)-Verteilung ist, dass sie gleich von zwei Freiheitsgraden abhängt: dem Zähler-Freiheitsgrad \\(\\mathit{df}_1\\) und dem Nenner-Freiheitsgrad \\(\\mathit{df}_2\\). Dabei bestimmen sich die Freiheitsgrade wieder durch die Stichprobengrößen: \\[\\begin{aligned} \\mathit{df}_1=n_1-1\\\\ \\mathit{df}_2=n_2-1 \\end{aligned} \\tag{6.14}\\] In der Formelsammlung sind nur die Werte für Flächenanteile von 0,95 vermerkt. Die Werte für Flächenanteile von 0,05 (also am linken Rand) können durch (6.15) bestimmt werden: \\[ F_{\\mathit{df}_1;\\mathit{df}_2;\\alpha}=\\frac{1}{F_{\\mathit{df}_2;\\mathit{df}_1;(1-\\alpha)}} \\tag{6.15} \\] Dabei ist zu beachten, dass im Nenner die Reihenfolge der Freiheitsgrade getauscht wird! Zur Verdeutlichung könnte  losgelöst von unserem Beispiel  ein unterer kritischer Wert berechnet werden durch: \\[\\begin{aligned} F_{13;20;5\\%}&amp;=\\frac{1}{F_{20;13;95\\%}} \\\\[5pt] &amp;\\approx\\frac{1}{2{,}46}\\approx0{,}41 \\end{aligned}\\] 6.5.4.1 Beispiel Die Freiheitsgrade berechnen sich durch (6.14): \\[\\begin{aligned} \\mathit{df}_1=n_1-1=5\\\\[4pt] \\mathit{df}_2=n_2-1=5 \\end{aligned}\\] Durch unsere gerichtete Alternativhypothese ergibt sich der kritische Wert aus (6.12) (unter Anwendung des Tricks aus (6.15)): \\[\\begin{aligned} F &amp;\\leq F_{\\mathit{df}_1;\\mathit{df}_2;\\alpha}\\\\ F &amp;\\leq F_{5;5;5\\%}\\\\[5pt] F &amp;\\leq \\frac{1}{F_{5;5;95\\%}}\\\\[5pt] F &amp;\\leq \\frac{1}{5{,}05}\\\\[4pt] F &amp;\\leq 0{,}20\\\\[4pt] \\end{aligned}\\] Der so berechnete Ablehnungsbereich ist grafisch in 6.2 aufbereitet. Abbildung 6.2: Ablehnungsbereich für \\(F \\leq F_{5;5;5\\%}\\) 6.5.5 Prüfgröße berechnen Die Formel für die Prüfgröße \\(F\\) ist denkbar einfach: \\[\\begin{aligned} F=\\frac{s^2_1}{s^2_2} \\end{aligned} \\tag{6.16}\\] 6.5.5.1 Beispiel Wir hatten die Varianzen der Stichproben berechnet mit: \\[\\begin{aligned} s^2_1\\approx0{,}41\\\\ s^2_2\\approx1{,}59 \\end{aligned}\\] Einsetzen in die Formel aus (6.16) ergibt: \\[\\begin{aligned} F&amp;=\\frac{s^2_1}{s^2_2}\\\\[6pt] &amp;=\\frac{0{,}41}{1{,}59}\\approx0{,}26 \\end{aligned}\\] 6.5.6 Nullhypothese ablehnen oder beibehalten Auch hier gilt dasselbe wie bei allen Tests. 6.5.6.1 Beispiel Der kritische Wert von 0,20 müsste unterschritten werden, um die Nullhypothese abzulehnen. Das ist nicht passiert  wir dürfen die Nullhypothese also beibehalten: Es gibt keinen statistisch signifikanten Unterschied in den beiden Varianzen (\\(\\alpha=0{,}05\\)). Damit haben wir im vorherigen Beispiel die Voraussetzungen des 2-Stichproben-\\(t\\)-Tests also nicht verletzt. 6.6 Fehlerarten Bei statistischen Tests sind Fehler nicht etwa Rechenfehler, sondern Angaben über die Wahrscheinlichkeit, die Nullhypothese aufgrund des Zufalls, dem die Stichprobe ja unterliegt, fälschlicherweise beizubehalten oder abzulehnen. Dabei wird unterschieden zwischen Fehlern 1. und 2. Art. 6.6.1 Fehler 1. Art Der Fehler 1. Art (engl. type I error) steht für die Wahrscheinlichkeit, dass die Nullhypothese fälschlicherweise abgelehnt wird. Das passiert, wenn die Ergebnisse nur zufällig in den Ablehnungsbereich fallen. Konsequenz ist, dass eine Vermutung statistisch belegt wird, obwohl sie gar nicht stimmt. Die Wahrscheinlichkeit dafür ist also gleich dem Signifikanzniveau (\\(\\alpha\\)). 6.6.2 Fehler 2. Art Der Fehler 2. Art (engl. type II error) ist die Wahrscheinlichkeit, dass die Nullhypothese fälschlicherweise beibehalten wird. Das passiert immer dann, wenn die Vermutung also eigentlich stimmt, die Stichprobenwerte aber zufällig so ausfallen, dass der Ablehnungsbereich nicht erreicht wird. Konsequenz ist, dass eine korrekte Vermutung statistisch nicht belegt werden kann. Die Warscheinlichkeit für einen Fehler 2. Art wird mit \\(\\beta\\) gekennzeichnet. 6.7 Aufgaben Die folgenden Aufgaben sind zur eigenständigen Überprüfung Ihrer Lernleistung gedacht (als Vor- oder Nachbereitung der Vorlesung, oder als Klausurübung) und nicht etwa als Hausaufgabe. 6.7.1 Aufgabe 1 Bestimmen Sie die folgenden kritischen Werte: \\(F_{4;1;5\\%}\\) \\(F_{8;9;95\\%}\\) \\(F_{7;10;95\\%}\\) \\(F_{9;4;95\\%}\\) \\(F_{3;15;95\\%}\\) \\(F_{5;6;5\\%}\\) \\(F_{2;2;5\\%}\\) \\(F_{100;100;5\\%}\\) \\(F_{1;20;95\\%}\\) \\(F_{20;50;95\\%}\\) 6.7.2 Aufgabe 2 Sie wissen, dass in städtischen Freibädern die Wassertemperatur an verschiedenen Tagen normalverteilt ist. Sie vermuten, dass die Temperatur in zwei Bädern unterschiedlich stark variiert. Sie planen zwei unabhängige Erhebungen an zufälligen Tagen während der Badesaison. Aus organisatorischen Gründen beträgt die Stichprobengröße in Schwimmbad 1 \\(n_1=5\\) und in Schwimmbad 2 \\(n_2=7\\). Welchen Test führen Sie durch? Formulieren Sie die Hypothesen. Sie wählen das Signifikanzniveau \\(\\alpha=0{,}1\\). Was bedeutet diese Zahl? Bestimmen Sie den Ablehnungsbereich. 6.7.3 Aufgabe 3 (Fortführung von Aufgabe 2) Sie erheben folgende Werte für die Wassertemperatur: \\[\\begin{aligned} \\textrm{Schwimmbad 1}:\\quad 23{,}3\\quad21{,}4\\quad20{,}9\\quad19{,}4\\quad21{,}6&amp;\\\\ \\textrm{Schwimmbad 2} : \\quad 21{,}5\\quad21{,}7\\quad21{,}5\\quad21{,}4\\quad22{,}0&amp;\\quad20{,}9\\quad21{,}8 \\end{aligned}\\] Berechnen Sie die Prüfgröße. Welche Schlüsse ziehen Sie aus der Untersuchung? 6.7.4 Aufgabe 4 Sie interessieren sich für das Kommunikationsverhalten von Jugendlichen über WhatsApp. Sie vermuten, dass Nutzer*innen, die die Gelesen-Benachrichtigung deaktiviert haben, im Durchschnitt langsamer antworten als diejenigen, die die Benachrichtigung aktiviert lassen. Sie finden je Einstellung sechs freiwillige Schüler*innen, die Sie ihre WhatsApp-Protokolle auf die Durchschnittliche Antwortzeit auswerten lassen (natürlich unter Einwilligung der Eltern). Welchen Test wollen Sie durchführen? Prüfen Sie die Voraussetzungen. Was könnte hier problematisch sein? Formulieren Sie die Hypothesen. Bestimmen Sie den Ablehnungsbereich bei Signifikanzniveau \\(\\alpha=0{,}05\\). 6.7.5 Aufgabe 5 (Fortführung von Aufgabe 4) Sie ermitteln die folgenden durchschnittlichen Antwortzeiten der individuellen Nutzer*innen (in Minuten): \\[\\begin{aligned} \\textrm{Ohne Benachrichtigung} &amp;: \\quad 24,7\\quad32,0\\quad48,9\\quad23,7\\quad23,0\\quad10,0\\\\ \\textrm{Mit Benachrichtigung} &amp;: \\quad18,2\\quad14,3\\quad23,4\\quad31,6\\quad36,4\\quad 9,2 \\end{aligned}\\] Berechnen Sie die Prüfgröße. Welche Schlüsse ziehen Sie aus der Untersuchung? 6.8 Tipps zur Vertiefung YouTube-Kanal Methodenlehre Mainz: Inferenzstatistik (Playlist) 3.23.7 YouTube-Kanal \"Methodenlehre Mainz: Irren ist statistisch: Fehler 1. und 2. Art Kapitel 8 in Bortz und Schuster (2010) Kapitel 9.5.1, 10.1.3 und 10.3 in Klemm (2002) Kapitel 5.3.3 in Bahrenberg, Giese und Nipper (2010) 6.9 Quellen Diese Voraussetzung ist etwas merkwürdig, denn beim \\(t\\)-Test kennen wir ja die Varianzen der Grundgesamtheiten gar nicht. Der \\(F\\)-Test kann diese Voraussetzung anhand der Stichprobenverteilungen prüfen. "],["korrelation.html", "Sitzung 7 Korrelation 7.1 Lernziele dieser Sitzung 7.2 Bivariate Statistik 7.3 Kovarianz 7.4 Korrelationskoeffizient 7.5 Aufgaben 7.6 Tipps zur Vertiefung 7.7 Quellen", " Sitzung 7 Korrelation 7.1 Lernziele dieser Sitzung Sie können ein Streudiagramm interpretieren. die Kovarianz von zwei Variablen berechnen. den Korrelationskoeffizienten von zwei Variablen berechnen. 7.2 Bivariate Statistik Grundlage der bivariaten Statistik ist es, dass für eine Reihe von Untersuchungsheinheiten jeweils zwei Merkmale erfasst sind. Diese Merkmale werden üblicherweise mit \\(x\\) und \\(y\\) gekennzeichnet. Für jedes \\(i\\) (laufende Nummer der Merkmalsträger*innen) gibt es dann ein \\(x_i\\) (Ausprägung des Merkmals \\(x\\)) und ein \\(y_i\\) (Ausprägung des Merkmals \\(y\\)). Das Streudiagramm (engl. scatter plot) stellt alle erfassten Werte dar, indem es die Untersuchungseinheiten als Punkte arrangiert  und zwar anhand ihres jeweiligen Werts der Variable \\(x\\) entlang der \\(x\\)-Achse und entlang der \\(y\\)-Achse anhand des \\(y\\)-Werts (s. 7.1). 7.2.1 Beispiel Die statistischen Verfahren dieser Sitzung sollen wieder an einem Beispiel illustriert werden. Wir fragen uns, ob der jährliche Ertrag in einem bestimmten Anbaugebiet für Klebreis in Nordostthailand mit dem jährlichen Niederschlag zusammenhängt. Die erfassten Werte sind in 7.1 festgehalten (Rai ist ein in Thailand übliches Flächenmaß). Tabelle 7.1: Niederschlag und Ertrag im Reisanbau Laufende Nr. Jahr Niederschlag (mm) Ertrag (kg/Rai) \\(i\\) \\(x_i\\) \\(y_i\\) 1 2008 1449 1860 2 2009 1472 2118 3 2010 1607 2225 4 2011 1494 2172 5 2012 1390 1816 6 2013 1764 2430 7 2014 1767 2580 8 2015 1765 2563 9 2016 1671 2276 10 2017 1838 2455 In einem Streudiagramm können diese Werte veranschaulicht werden. Dabei ist es üblich, die unabhängige Variable auf der \\(x\\)-Achse und die abhängige Variable auf der \\(y\\)-Achse einzutragen. Im Beispiel liegt nahe, dass der Ertrag vom Regen abhängt, und nicht etwa umgekehrt. 7.1 ist das Streudiagramm für unser Beispiel. Es fällt schon rein optisch auf, dass ein Zusammenhang zu bestehen scheint: Je mehr Regen, desto reicher die Ernte. Doch wie lässt sich dieser Zusammenhang beziffern? Abbildung 7.1: Streudiagramm zum Reisanbau 7.3 Kovarianz Die Kovarianz (engl. covariance) \\(s_{xy}\\) gibt an, inwiefern die beiden Variablen \\(x\\) und \\(y\\) gemeinsam variieren. Die Kovarianz ergibt sich durch die Summe der jeweiligen Produkte der Differenzen zu den Mittelwerten \\((x_i-\\bar{x})\\) und \\((y_i-\\bar{y})\\), geteilt durch \\((n-1)\\). Die Formel lautet also: \\[ s_{xy}=\\frac{\\sum\\limits^n_{i=1}(x_i-\\bar{x})\\cdot(y_i-\\bar{y})}{n-1} \\tag{7.1} \\] (7.1) lässt erahnen: Wenn sowohl \\(x\\) als auch \\(y\\) in die gleiche Richtung vom jeweiligen Mittelwert abweichen (also beide Differenzen positiv oder beide Differenzen negativ), dann ist das Produkt positiv, sonst ist es negativ. Eine positive Kovarianz lässt also auf einen positiven Zusammenhang schließen (je größer \\(x\\), desto größer auch \\(y\\)), eine negative Kovarianz auf einen negativen Zusammenhang (je größer \\(x\\), desto kleiner \\(y\\)). 7.3.1 Beispiel Es macht Sinn, eine Tabelle anzulgen, in der Teilrechenschritte durchgeführt werden. 7.2 veranschaulicht dies. Tabelle 7.2: Hilfstabelle für die Berechnung der Kovarianz \\(i\\) \\(x_i\\) \\(y_i\\) \\((x_i-\\bar{x})\\) \\((y_i-\\bar{y})\\) \\((x_i-\\bar{x})\\cdot(y_i-\\bar{y})\\) 1 1449 1860 -172,7 -389,5 67266,65 2 1472 2118 -149,7 -131,5 19685,55 3 1607 2225 -14,7 -24,5 360,15 4 1494 2172 -127,7 -77,5 9896,75 5 1390 1816 -231,7 -433,5 100441,95 6 1764 2430 142,3 180,5 25685,15 7 1767 2580 145,3 330,5 48021,65 8 1765 2563 143,3 313,5 44924,55 9 1671 2276 49,3 26,5 1306,45 10 1838 2455 216,3 205,5 44449,65 Summe: 16217 22495 362038,5 Als Zwischenschritt müssen die Mittelwerte \\(\\bar{x}\\) und \\(\\bar{y}\\) berechnet werden, wofür die Summen der ersten beiden Spalten herangezogen werden können: \\[ \\begin{aligned} \\bar{x}&amp;=\\frac{\\sum\\limits^n_{i=1}x_i}{n}\\\\[5pt] &amp;=\\frac{16217}{10}=1621,7\\\\[6pt] \\bar{y}&amp;=\\frac{\\sum\\limits^n_{i=1}y_i}{n}\\\\[5pt] &amp;=\\frac{22495}{10}=2249,5 \\end{aligned} \\] Schließlich ergibt Einsetzen der Produktsumme in (7.1) die Kovarianz: \\[\\begin{aligned} s_{xy}&amp;=\\frac{\\sum\\limits^n_{i=1}(x_i-\\bar{x})\\cdot(y_i-\\bar{y})}{n-1}\\\\[5pt] &amp;\\approx\\frac{362038,5}{9}=40226,5 \\end{aligned}\\] Die Kovarianz ist also \\(s_{xy}=40226,5\\). Was sagt uns diese Zahl? Zunächst ist sie positiv, womit wir von einer positiven Korrelation (je mehr Regen, desto mehr Ertrag) ausgehen können. Sie ist auch irgendwie ziemlich groß, was einen deutlichen Zusammenhang nahelegt. Aber die Kovarianz ist abhängig vom Maßstab  wäre der Ertrag nicht in Kilogramm pro Rai, sondern (wie in Deutschland üblich) in Dezitonnen pro Hektar angegeben, dann wäre die Zahl deutlich kleiner (2514,156 um genau zu sein). Wie lässt sich die Stärke der Korrelation also unabhängig von den Maßeinheiten angeben? 7.4 Korrelationskoeffizient Der Korrelationskoeffizent \\(r\\) (auch Produkt-Moment-Korrelation, Bravais-Pearson-Korrelation, Pearsons \\(r\\), engl. correlation coefficient) standardisiert die Kovarianz \\(s_{xy}\\) anhand der Standardabweichungen \\(s_x\\) und \\(s_y\\). Die Formel lautet: \\[ r=\\frac{s_{xy}}{s_x\\cdot s_y} \\tag{7.2} \\] Durch diese Standardisierung kann der Korrelationskoeffizient nur noch Werte zwischen \\(r=-1\\) (perfekte negative Korrelation) und \\(r=1\\) (perfekte positive Korrelation) annehmen. Ein Korrelationskoeffizient nahe \\(r=0\\) bedeutet, dass es keinen Zusammenhang zwischen den Variablen \\(x\\) und \\(y\\) gibt (s. 7.2). Abbildung 7.2: Verschiedene Korrelationskoeffizienten 7.4.1 Beispiel In der Formel für den Korrelationskoeffizienten \\(r\\) ((7.2)) werden die Standardabweichungen \\(s_x\\) und \\(s_y\\) benötigt. Es ist daher sinnvoll, die Hilfstabelle um die Quadrate der Differenzen (und deren Summen) zu erweitern (s. 7.3). Tabelle 7.3: Hilfstabelle für die Berechnung des Korrelationskoeffizienten \\(i\\) \\(x_i\\) \\(y_i\\) \\((x_i-\\bar{x})\\) \\((y_i-\\bar{y})\\) \\((x_i-\\bar{x})^2\\) \\((y_i-\\bar{y})^2\\) 1 1449 1860 -172,7 -389,5 29825,29 151710,25 2 1472 2118 -149,7 -131,5 22410,09 17292,25 3 1607 2225 -14,7 -24,5 216,09 600,25 4 1494 2172 -127,7 -77,5 16307,29 6006,25 5 1390 1816 -231,7 -433,5 53684,89 187922,25 6 1764 2430 142,3 180,5 20249,29 32580,25 7 1767 2580 145,3 330,5 21112,09 109230,25 8 1765 2563 143,3 313,5 20534,89 98282,25 9 1671 2276 49,3 26,5 2430,49 702,25 10 1838 2455 216,3 205,5 46785,69 42230,25 Summe: 16217 22495 233556,1 646556,5 Die Standardabweichungen ergeben sich nun wie gewohnt aus: \\[\\begin{aligned} s_{x}&amp;=\\sqrt{\\frac{\\sum\\limits^n_{i=1}(x_i-\\bar{x})^2}{n-1}}\\\\[5pt] &amp;=\\sqrt{\\frac{233556,1}{9}}=\\sqrt{25950,68}\\approx161,09\\\\[6pt] s_{y}&amp;=\\sqrt{\\frac{\\sum\\limits^n_{i=1}(y_i-\\bar{y})^2}{n-1}}\\\\[5pt] &amp;=\\sqrt{\\frac{646556,5}{9}}=\\sqrt{71839,61} \\approx268,03 \\end{aligned}\\] Nun lassen sich die errechneten Werte in (7.2) einsetzen: \\[\\begin{aligned} r&amp;=\\frac{s_{xy}}{s_x\\cdot s_y}\\\\[4pt] &amp;\\approx\\frac{40226,5}{161,09\\cdot268,03}\\approx0,93 \\end{aligned}\\] Wir können bei einem Korrelationskoeffizienten \\(r\\approx0,93\\) von einem deutlichen positiven Zusammenhang zwischen Niederschlag und Ertrag ausgehen. 7.5 Aufgaben 7.5.1 Aufgabe 1 Zeichnen Sie ein Streudiagramm und berechnen Sie die Kovarianz sowie den Korrelationskoeffizenten für die folgenden Messreihen. Messreihe: \\(x_i\\) \\(y_i\\) 14,21 134 10,32 131 13,82 134 15,79 135 14,70 134 17,23 137 14,84 136 14,96 135 Messreihe: \\(x_i\\) \\(y_i\\) -1,17 14,40 -0,10 2,31 -0,15 2,95 0,46 -1,39 0,34 -2,96 -0,44 2,44 2,13 -20,47 0,66 -10,51 -1,37 11,81 0,56 -4,05 7.5.2 Aufgabe 2 Sie erheben für zufällige Wasserhäuschen in Frankfurt die Entfernung zur nächsten Haltestelle der S- oder U-Bahn sowie den durchschnitllichen Tagesumsatz. Die Erhebung ergibt: Entfernung (m) Umsatz (/Tag) 35 394,61 79 468,92 234 385,75 105 376,17 318 283,26 31 342,77 Gibt es einen Zusammenhang zwischen Entfernung und Umsatz? Wenn ja: Wie hängen die Variablen zusammen? Wie stark ist der Zusammenhang? 7.5.3 Aufgabe 3 (weiterführend, nicht klausurrelevant wirklich nur für Leute, die Spaß an Mathematik haben!) Zeigen Sie, dass der Korrelationskoeffizent \\(r\\) ein standardisierter Wert ist, indem Sie ihn in \\(z\\)-Werten ausdrücken. Überprüfen Sie die Formel anhand Aufgabe 1 a). Angenommen, Sie wollen \\(r\\) angeben, ohne die Koviarianz berechnet zu haben. Wie lassen sich die Rechenschritte dann vereinfachen? Überprüfen Sie den Rechenweg anhand Aufgabe 2. 7.6 Tipps zur Vertiefung YouTube-Kanal Kurzes Tutorium Statistik: Streudiagramm und Korrelation YouTube-Kanal Methodenlehre Mainz: Bivariate Daten (Playlist) Kapitel 10 in Bortz und Schuster (2010) Kapitel 6.1, 6.3 und 6.4 in Bahrenberg, Giese und Nipper (2010) Kapitel 16 in Klemm (2002) 7.7 Quellen "],["lineare-regression.html", "Sitzung 8 Lineare Regression 8.1 Lernziele dieser Sitzung 8.2 Regresssionsanalyse 8.3 Bestimmung der Regressionsgeraden 8.4 Residuen 8.5 Determinationskoeffizient 8.6 Aufgaben 8.7 Tipps zur Vertiefung 8.8 Quellen", " Sitzung 8 Lineare Regression 8.1 Lernziele dieser Sitzung Sie können eine Regressionsgerade berechnen. Werte aus der Regressionsgerade ableiten. Residuen errechnen. den Determinationskoeffizienten \\(R^2\\) berechnen und interpretieren. 8.2 Regresssionsanalyse Sind zwei stochastisch abhängige Variablen \\(x\\) und \\(y\\) durch eine Regressionsgleichung miteinander verknüpft, kann die eine Variable zur Vorhersage der anderen eingesetzt werden. (Bortz und Schuster 2010: 183) Es gibt viele Möglichkeiten, Regressionen zu modellieren. Im Rahmen dieser Veranstaltung wird nur die lineare Regression (engl. linear regression) behandelt. Lineare Regressionsmodelle werden immer durch eine lineare Gleichung des Formats \\[ y=a+b\\cdot x \\tag{8.1} \\] ausgedrückt, wobei \\(a\\) der Achsenabschnitt ist und \\(b\\) die Steigung. Ist die Gleichung bekannt, so können wir für jeden Wert \\(x\\) einen entsprechenden Wert \\(y\\) vorhersagen. 8.1 zeigt ein solches lineares Regressionsmodell als Gerade durch ein Streudiagramm. Abbildung 8.1: Regressionslinie durch ein Streudiagramm Der Achsenabschnitt \\(a\\approx2,2\\) bedeutet, dass die Regressionsgerade die \\(y\\)-Achse etwa auf der Höhe 2,2 schneidet (bei \\(x=0\\)). Die Steigung \\(b\\approx1,7\\) heißt, dass für jede zusätzliche Einheit der Variable \\(x\\) ca. 1,7 zusätzliche Einheiten der Variable \\(y\\) erwartet werden können. Wenn die Regressionsgleichung bekannt ist, kann für jedes gültige (grundsätzlich: jedes beliebige) \\(x\\) ein erwarteter Wert \\(\\hat{y}\\) berechnet werden. So könnte uns bei der Beispielregression interessieren, welchen Wert \\(\\hat{y}_i\\) im Modell annimmt, wenn \\(x_i=20\\) beträgt: \\[\\begin{aligned} \\hat{y}_i&amp;=a+b\\cdot x_i\\\\ &amp;\\approx2,2+1,7\\cdot20\\\\ &amp;=36,2 \\end{aligned}\\] Bei solchen Schätzungen außerhalb des bekannten Wertebereichs spricht man auch vom Extrapolieren, sonst  für fehlende Werte innerhalb des bekannten Wertebereich  vom Interpolieren. Umgekehrt könnte die Frage lauten: Wie groß muss ein \\(x_i\\) sein, damit (im Modell) \\(\\hat{y}_i=12\\) beträgt? Dies lässt sich durch eine einfache Umformung der (8.1) berechnen: \\[\\begin{aligned} \\hat{y}_i&amp;=a+b\\cdot x_i\\\\[5pt] x_i&amp;=\\frac{\\hat{y}_i-a}{b}\\\\[5pt] &amp;=\\frac{12-2,2}{1,7}\\\\ &amp;\\approx5,8 \\end{aligned}\\] Bei der Regressionsanalyse wird ein gerichtetes Abhängigkeitsverhältnis der Variablen impliziert: \\(y\\) hängt hier von \\(x\\) ab. Daher wird \\(x\\) auch die Prädiktorvariable und \\(y\\) die Kriteriumsvariable genannt. Es ist also für derartige Fragestellungen nötig, die Gleichung der Regressionsgeraden zu kennen. Im Folgenden wird gezeigt, wie diese anhand einer bivariaten Verteilung bestimmt werden kann. 8.3 Bestimmung der Regressionsgeraden Der Koeffizient \\(b\\) (also die Steigung der Regressionsgeraden) lässt sich berechnen, indem man die Kovarianz \\(s_{xy}\\) durch die Varianz von \\(x\\) dividiert: \\[ b=\\frac{s_{xy}}{s^2_x} \\tag{8.2} \\] Der Koeffizient \\(a\\) (also der Achsenabschnitt) ergibt sich wiederum aus \\(b\\) und den Mittelwerten \\(\\bar{x}\\) und \\(\\bar{y}\\): \\[ a=\\bar{y}-b\\cdot\\bar{x} \\tag{8.3} \\] Die Bestimmung der Regressionsgeraden soll nun mit einem Beispiel illustriert werden. 8.3.1 Beispiel Wir fragen uns, wie die Aufenthaltszeit von Passagieren am Frankfurter Flughafen mit dem Betrag zusammenhängt, den sie in den dortigen Geschäften ausgeben. Eine Zufallserhebung habe die Werte in ?? ergeben. Tabelle 8.1: Messwerte am Frankfurter Flughafen Aufenthaltszeit (min) Ausgaben () \\(x_i\\) \\(y_i\\) 121 17,94 125 23,15 293 44,31 370 42,46 246 35,51 281 28,46 169 18,47 328 56,77 388 40,11 131 12,64 299 24,54 324 46,37 Mit den Methoden aus Sitzung 2 und 7 können wir folgende Werte für die Mittelwerte \\(\\bar{x}\\) und \\(\\bar{y}\\), die Varianz \\(s^2_x\\) sowie die Kovarianz \\(s_{xy}\\) berechnen: \\[\\begin{aligned} \\bar{x}&amp;=256,25\\\\ \\bar{y}&amp;\\approx 32,56\\\\ s^2_{x}&amp;\\approx9340,93\\\\ s_{xy}&amp;\\approx 1062,50 \\end{aligned}\\] Für die Steigung der Regressionsgeraden \\(b\\) setzen wir die entsprechenden Werte in (8.2) ein: \\[\\begin{aligned} b&amp;=\\frac{s_{xy}}{s^2_x}\\\\[5pt] &amp;\\approx\\frac{1062,50}{9340,93}\\\\[4pt] &amp;\\approx0,114 \\end{aligned}\\] Die Steigung von 0,114 bedeutet, dass  im linearen Regressionsmodell  Passagiere in jeder zusätzlichen Minute, die sie am Flughafen verbringen, in etwa 11,4 zusätzliche Cent ausgeben. Der Achsenabschnitt \\(a\\) berechnet sich dann gemäß (8.3): \\[\\begin{aligned} a&amp;=\\bar{y}-b\\cdot\\bar{x}\\\\ &amp;\\approx 32,56-0,114\\cdot256,25\\\\ &amp;\\approx 3,35 \\end{aligned}\\] Dieser Wert ergibt nur einen abstrakt-mathematischen Sinn  es dürfte in der Praxis wohl kaum Passagiere geben, die 0 Minuten am Flughafen verbringen und  3,35 ausgeben. Mit dem Achsenabschnitt \\(a\\) und der Steigung \\(b\\) lässt sich folgende Gleichung für die Regressionsgerade aufstellen (s. (eq:lin)): \\[\\begin{aligned} y&amp;=a+b\\cdot x\\\\ y&amp;\\approx3,35 + 0,114 \\cdot x \\end{aligned}\\] Graphisch ist diese lineare Regression in 8.2 dargestellt. Abbildung 8.2: Regressionslinie durch ein Streudiagramm 8.4 Residuen Residuen (engl. residuals) werden mit \\(e\\) bezeichnet und sind die Differenzen zwischen den tatsächlichen \\(y\\)-Werten und den im Modell erwarteten \\(\\hat{y}\\)-Werten für die jeweiligen \\(x\\)-Werte: \\[ e_i=y_i-\\hat{y}_i \\tag{8.4} \\] Residuen sind also  auch dem Wortstamm nach  das, was nach der Vorhersage durch das Modell übrig bleibt von den tatsächlich beobachteten Werten (also der Teil des Werts, der nicht durch das Regressionsmodell erklärt wird). 8.4.1 Beispiel Graphisch sind die Residuen für unser Beispiel in 8.3 dargestellt (positive Werte in grün, negative Werte in rot), tabellarisch in ??. Abbildung 8.3: Graphische Darstellung der Residuen Tabelle 8.2: Residuen der Beispielwerte Aufenthaltszeit (min) Ausgaben () Erwartete Ausgaben () Residuen () \\(x_i\\) \\(y_i\\) \\(\\hat{y}_i\\approx3,35+0,114\\cdot x_i\\) \\(e_i=y_i-\\hat{y}_i\\) 121 17,94 17,144 0,796 125 23,15 17,600 5,550 293 44,31 36,752 7,558 370 42,46 45,530 -3,070 246 35,51 31,394 4,116 281 28,46 35,384 -6,924 169 18,47 22,616 -4,146 328 56,77 40,742 16,028 388 40,11 47,582 -7,472 131 12,64 18,284 -5,644 299 24,54 37,436 -12,896 324 46,37 40,286 6,084 Residuen spielen in vielen statistischen Verfahren eine Rolle, z.B. in der Residuenanalyse. Diese Verfahren werden im Rahmen dieser Veranstaltung jedoch nicht behandelt. 8.5 Determinationskoeffizient Der Determinationskoeffizient \\(R^2\\) (engl. coefficient of determination) ist formal definiert als das Verhältnis der Varianz der vorhergesagten \\(\\hat{y}\\)-Werte zur Varianz der tatsächlich beobachteten \\(y\\)-Werte (wobei sich der Term \\([n-1]\\) auskürzt): \\[ R^2=\\frac{\\sum\\limits^n_{i=1}(\\hat{y}_i-\\bar{y})^2}{\\sum\\limits^n_{i=1}(y_i-\\bar{y})^2} \\tag{8.5} \\] Da Zähler und Nenner als Quadratsummen stets positiv sind und die Varianz der \\(\\hat{y}\\)-Werte immer kleiner oder gleich der Varianz der \\(y\\)-Werte ist, nimmt der Determinationskoeffizient immer einen Wert zwischen 0 und 1 an. Je größer \\(R^2\\), desto besser erklärt das lineare Regressionsmodell die tatsächlich beobachteten Werte. \\(R^2=1\\) bedeutet, dass das Modell die Werte perfekt erklärt. Für lineare Regressionsmodelle (also für die einzige Regression, die im Rahmen dieser Veranstaltung behandelt wird) lässt sich \\(R^2\\) auch berechnen, indem wir den Korrelationskoeffizienten \\(r\\) quadrieren: \\[ R^2=r^2 \\tag{8.6} \\] 8.5.1 Beispiel Mit den Methoden aus Sitzung 7 können wir den Korrelationskoeffizienten für unser Beispiel errechnen: \\[\\begin{aligned} r&amp;=\\frac{s_{xy}}{s_x\\cdot s_y}\\\\[6pt] &amp;\\approx\\frac{1062,50}{96,65\\cdot13,68}\\\\[4pt] &amp;\\approx0,804 \\end{aligned}\\] Der Determinationskoeffizient ergibt sich dann mit (8.6): \\[\\begin{aligned} R^2&amp;=r^2\\\\ &amp;\\approx 0,804^2\\\\ &amp;\\approx 0,646 \\end{aligned}\\] 8.6 Aufgaben 8.6.1 Aufgabe 1 Sie haben für eine bivariate Verteilung die folgende Regressionsgleichung bestimmt: \\[ y=-1,48-0,975\\cdot x \\] Bestimmen Sie die erwarteten \\(\\hat{y}_i\\)-Werte für diese \\(x_i\\)-Werte: \\[ 0,3\\quad-18,5\\quad-13,5\\quad-17,2\\quad29,8\\quad25,6\\quad-36,4\\quad-26,2 \\] Für welche Werte \\(x_i\\) sagt das Regressionsmodell diese Werte \\(\\hat{y}_i\\) voraus? \\[ -10\\quad15\\quad-50\\quad-10\\quad-60\\quad-55\\quad-20\\quad0 \\] Bestimmen Sie die Residuen für die tatsächlich beobachtete Messreihe: \\(x_i\\) \\(y_i\\) -11,49 6,82 8,22 -8,59 -25,66 25,92 23,81 -26,91 -3,14 4,41 -1,52 -3,39 20,15 -19,89 -10,22 9,30 8.6.2 Aufgabe 2 Eine bivariate Verteilung sei gekennzeichnet durch die folgenden Parameter: \\[\\begin{aligned} \\bar{x}&amp;=157,5\\\\ \\bar{y}&amp;=156,7\\\\ s^2_{x}&amp;=1080,94\\\\ s^2_{y}&amp;=884,46\\\\ s_{xy}&amp;=869,83 \\end{aligned}\\] Bestimmen Sie die Regressionsgleichung im linearen Modell. Bestimmen Sie den Determinationskoeffizienten \\(R^2\\). 8.6.3 Aufgabe 3 Diese Aufgabe erfordert auch Verfahren aus Sitzung 6. Sie fragen sich, wie die erreichte Punktzahl in einer Klausur mit der Vorbereitungszeit der geprüften Studierenden zusammenhängt. Sie erheben die folgende Messreihe: Vorbereitungszeit (min) Erreichte Punktzahl 834 88 17 41 519 75 253 39 739 77 844 100 Welche Punktzahl ist mit einer Vorbereitunszeit von sechs Stunden zu erwarten? Ab welcher Vorbereitungszeit ist im Modell zu erwarten, dass ein Studierende*r die Klausur besteht (\\(\\geq\\) 50 Punkte)? Ab welcher Vorbereitungszeit kann laut Modell mit der vollen Punktzahl (100 Punkte) gerechnet werden? Wie gut erklärt ein lineares Modell die Prüfungsleistungen anhand der Vorbereitungszeit? Welche Limitationen hat das Modell? Denken Sie an extreme Werte. 8.7 Tipps zur Vertiefung Kapitel 11 in Bortz und Schuster (2010) Kapitel 6.2 in Bahrenberg, Giese und Nipper (2010) Kapitel 17 in Klemm (2002) 8.8 Quellen "],["kreuztabellen.html", "Sitzung 9 Kreuztabellen 9.1 Lernziele dieser Sitzung 9.2 Bivariate Verteilungen mit nominalen Variablen 9.3 Kreuztabelle 9.4 Berechnung der erwarteten Werte 9.5 Berechnung des Kontingenzkoeffizenten \\(\\chi^2\\) 9.6 Berechnung des \\(\\phi\\)-Koeffizienten 9.7 Berechnung des Cramér-Index 9.8 Aufgaben 9.9 Tipps zur Vertiefung 9.10 Quellen", " Sitzung 9 Kreuztabellen 9.1 Lernziele dieser Sitzung Sie können eine Kreuztabelle erstellen und interpretieren. den Kontingenzkoeffizienten \\(\\chi^2\\) errechnen. die Maßzahlen \\(\\phi\\) bzw. \\(\\mathit{CI}\\) errechnen und interpretieren. 9.2 Bivariate Verteilungen mit nominalen Variablen In der bivariaten Statistik (Sitzung 7 und 8) ging es bisher um Zusammenhänge zwischen zwei metrischen Variablen. In dieser Sitzung geht es um statistische Verfahren der bivariaten Statistik, bei denen für beide Variablen nur das Nominalskalenniveau vorausgesetzt ist. (Für Skalenniveaus s. Sitzung 1.) Mit den Werten von nominalen Variablen lassen sich die in Sitzung 7 und 8 besprochenen Parameter (z.B. Kovarianz) nicht errechnen, weil wir mit ihnen nicht die notwendigen Rechenoperationen (Addition, Subtraktion) durchführen können. Stattdessen sind die beobachteten Häufigkeiten Ausgangslage für die im Folgenden besprochenen Verfahren. 9.2.1 Beispiel Wir fragen uns, ob es einen Zusammenhang zwischen dem Studienfach von Studierenden an einer Universität und ihrem präferierten Transportmittel für den Pendelweg zum Campus gibt. Insbesondere interessiert uns, ob ein Zusammenhang zwischen dem Studium der Geistes- und Sozialwissenschaften und der Fahrradnutzung besteht. Beide Variablen sind nominalskaliert: die erhobenen Werte können in Kategorien eingeordnet werden (Studienfach: Geographie, Politikwissenschaft, BWL, ; Transportmittel: Bus, Fahrrad, zu Fuß, ). Um die Variablen im Sinne unserer Fragestellung zu vereinfachen, wandeln wir beide Variablen in dichotome Variablen um (die dann nur zwei Werte annehmen können). Wir beschränken uns auf die Erhebung von Fahrrad oder anderes Transportmittel einerseits und Geistes-/Sozialwissenschaft oder anderes Studienfach andererseits. Die (verkürzte) Tabelle der Rohdaten einer Zufallsstichprobe der Größe \\(n=90\\) könnte dann so aussehen wie 9.1. Tabelle 9.1: Ungeordnete Rohdaten der Erhebung Studienfach Transportmittel 1 anderes Studienfach Fahrrad 2 anderes Studienfach Fahrrad 3 Geistes-/Sozialwissenschaft anderes Transportmittel 4 Geistes-/Sozialwissenschaft anderes Transportmittel 5 Geistes-/Sozialwissenschaft anderes Transportmittel 6 Geistes-/Sozialwissenschaft Fahrrad    85 anderes Studienfach anderes Transportmittel 86 anderes Studienfach anderes Transportmittel 87 Geistes-/Sozialwissenschaft anderes Transportmittel 88 anderes Studienfach anderes Transportmittel 89 anderes Studienfach anderes Transportmittel 90 Geistes-/Sozialwissenschaft anderes Transportmittel 9.3 Kreuztabelle Die Kreuztabelle (auch Kontingenztabelle, Kontingenztafel, engl. contingency table) ist eine übersichtliche Zusammenfassung der Rohdaten. Sie spannt die beiden Variablen in Spalten- und Zeilenrichtung auf, so dass in jeder Zelle die Häufigkeit einer bestimmten Wertekombination steht. Bei zwei dichotomen Variablen ergeben sich zwei Spalten und zwei Zeilen, also vier Tabellenfelder. Wir sprechen in diesem Fall auch von einer \\(2\\times2\\)-Tabelle. 9.3.1 Beispiel Die Kreuztabelle für unser Beispiel ist in 9.2 dargestellt. Die Spaltenüberschriften sind die beiden Werte der dichotomen Variable Transportmittel, und die Zeilennamen sind die beiden Werte für Studienfach. In den Zellen stehen die Häufigkeiten. Es lässt sich also z.B. ablesen, dass die Kombination Fahrrad und anderes Studienfach neun mal vorkommt. Tabelle 9.2: Kreuztabelle der Beispieldaten Fahrrad anderes Transportmittel Geistes-/Sozialwissenschaft 11 28 39 anderes Studienfach 9 42 51 20 70 90 Am rechten Rand der Tabelle stehen die Summen für die Zeilen, am unteren Rand die Summen der Spalten. Ganz unten rechts steht die Gesamtsumme (Größe der Stichprobe). 9.3.2 Verallgemeinerung In 9.3 ist das allgemeingültige Format für Kreuztabellen festgehalten. Dabei sind folgende Besonderheiten zu beachten: Das Symbol \\(k\\) steht für die Anzahl der Zeilen, \\(\\ell\\) für die Anzahl der Spalten. Die Häufigkeiten für Merkmalskombinationen in den Tabellenfeldern werden durch \\(n_{ij}\\) symbolisiert, wobei \\(i\\) für die laufende Nummer der Zeile steht, und \\(j\\) für die laufende Nummer der Spalte. Die Teilsummen an den Rändern werden mit Punktnotation bezeichnet. Dabei steht die Zeilensumme \\(n_{i\\cdot}\\) für die Summe aller Felder in Zeile \\(i\\) (Zeilensumme) und \\(n_{\\cdot j}\\) für die Summe aller Felder in Spalte \\(j\\) (Spaltensumme). Die Gesamtsumme unten rechts wird hier mit \\(n\\) gekennzeichnet und steht wie gewohnt für die Gesamtgröße der Stichprobe. Tabelle 9.3: Allgemeine Bezeichnungen in der Kreuztabelle Spalte 1 Spalte 2  Spalte \\(\\ell\\) Zeile 1 \\(n_{11}\\) \\(n_{12}\\)  \\(n_{1\\ell}\\) \\(n_{1\\cdot}\\) Zeile 2 \\(n_{21}\\) \\(n_{22}\\)  \\(n_{2\\ell}\\) \\(n_{2\\cdot}\\)       Zeile \\(k\\) \\(n_{k1}\\) \\(n_{k2}\\)  \\(n_{k\\ell}\\) \\(n_{k\\cdot}\\) \\(n_{\\cdot1}\\) \\(n_{\\cdot2}\\)  \\(n_{\\cdot\\ell}\\) \\(n\\) 9.4 Berechnung der erwarteten Werte Bestünde kein Zusammenhang zwischen den Variablen, dann wäre zu erwarten, dass sich die Kombinationen gleichmäßig auf die Tabellenfelder aufteilen, und zwar ausgehend von den Teilsummen für die Zeilen und Spalten. Der Erwartungswert für ein Tabellenfeld (also der durchschnittliche Wert, wenn es keinen Zusammenhang zwischen den beiden Variablen gibt) berechnet sich durch die Formel: \\[ m_{ij}=\\frac{n_{i\\cdot}\\cdot n_{\\cdot j}}{n} \\tag{9.1} \\] Es wird also das Produkt der Zeilen- und der Spaltensumme geteilt durch die Gesamtsumme. 9.4.1 Beispiel Die beobachtete Häufigkeit für die Kombination Geistes-/Sozialwissenschaft (Zeile 1) und anderes Transportmittel (Spalte 2) ist 28. Aber was wäre der Erwartungswert bei den gegebenen Summen? Wir setzen einfach die entsprechenden Werte in die (9.1) ein: \\[\\begin{aligned} m_{12}&amp;=\\frac{n_{1\\cdot}\\cdot n_{\\cdot 2}}{n}\\\\[5pt] &amp;=\\frac{39\\cdot 70}{90}\\\\[4pt] &amp;\\approx 30,33 \\end{aligned}\\] Diese Rechnung lässt sich für alle Tabellenfelder durchführen. Die Kreuztabelle kann dann um diese erwarteten Werte in Klammern ergänzt werden (s. 9.4). Tabelle 9.4: Kreuztabelle der Beispieldaten Fahrrad anderes Transportmittel Geistes-/Sozialwissenschaft 11(8,67) 28(30,33) 39 anderes Studienfach 9(11,33) 42(39,67) 51 20 70 90 9.5 Berechnung des Kontingenzkoeffizenten \\(\\chi^2\\) Sind für alle Tabellenfelder die Beobachtungs- und Erwartungswerte gegeben, lässt sich für jedes Tabellenfeld ein Wert berechnen, der diese Werte in Relation setzt. Die Summe dieser Werte über die gesamte Tabelle hinweg wird Kontingenzkoeffizient genannt und mit \\(\\chi^2\\) (Chi-Quadrat) abgekürzt. \\[ \\chi^2= \\sum_{i=1}^{k}\\sum_{j=1}^{\\ell}\\frac{(n_{ij}-m_{ij})^{2}}{m_{ij}} \\tag{9.2} \\] Bei der Formel steht \\(k\\) wieder für die Anzahl der Zeilen (und \\(i\\) für ihre laufende Nummer) und \\(\\ell\\) für die Anzahl der Spalten (und \\(j\\) für ihre laufende Nummer). Das doppelte Summenzeichen mag etwas verwirrend sein, bedeutet aber nur, dass die Zeilen spaltenweise summiert werden, und dann die Summe dieser Zeilensumme genommen wird  d.h. dass einfach alle Tabellenfelder aufsummiert werden. Der \\(\\chi^2\\)-Wert kann (ähnlich wie der \\(F\\)-Wert aus Sitzung 6) nur positive Werte annehmen. Er bildet die Grundlage für die im Folgenden besprochenen Kennwerte \\(\\phi\\) und \\(\\mathit{CI}\\) sowie für den in Sitzung 10 zu besprechenden \\(\\chi^2\\)-Test. 9.5.1 Beispiel Ein möglicher Zwischenschritt ist es, diese Teilwerte von \\(\\chi^2\\) für die einzelnen Tabellenfelder auszurechnen und in der Kreuztabelle zu notieren. Die Teilwerte werden dann für jedes Tabellenfeld mit der Formel \\[ \\frac{(n_{ij}-m_{ij})^{2}}{m_{ij}} \\tag{9.3} \\] berechnet und sind in 9.5 in blau dargestellt. Tabelle 9.5: Kreuztabelle der Beispieldaten mit Teilwerten für \\(\\chi^2\\) Fahrrad anderes Transportmittel Geistes-/Sozialwissenschaft 11(8,67)0,626 28(30,33)0,179 39 anderes Studienfach 9(11,33)0,479 42(39,67)0,137 51 20 70 90 Zum Beispiel ergibt sich der Teilwert für \\(\\chi^2\\) für die Kombination anderes Studienfach  Fahrrad durch Einsetzen in (9.3): \\[\\begin{aligned} \\frac{(n_{21}-m_{21})^{2}}{m_{21}} &amp;\\approx \\frac{(9-11,33)^2}{11,33}\\\\ &amp;=\\frac{-2,33^2}{11,33}\\\\ &amp;\\approx\\frac{5,43}{11,33}\\\\ &amp;\\approx0,479 \\end{aligned}\\] Der \\(\\chi^2\\)-Wert lässt sich nun bestimmen, indem diese Teilwerte aufsummiert werden: \\[\\begin{aligned} \\chi^2&amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{\\ell}\\frac{(n_{ij}-m_{ij})^{2}}{m_{ij}}\\\\[4pt] &amp;\\approx 0,626 + 0,179 + 0,479 + 0,137\\\\ &amp; =1,421 \\end{aligned}\\] Mit diesem Wert \\(\\chi^2\\approx1,421\\) können wir noch nicht so viel anfangen  wir wissen aber, dass er ein Maß dafür ist, wie sehr unsere beobachtete Verteilung von einer zu erwarteten Verteilung (vorausgesetzt, es gibt keinen Zusammenhang) abweicht. 9.6 Berechnung des \\(\\phi\\)-Koeffizienten Der \\(\\phi\\)-Koeffizient ist der Korrelationskoeffizient für zwei dichotome Variablen (wobei er in der hier besprochenen Version nur positive Werte annehmen kann). Er ist jedoch nicht ohne weiteres mit dem Korrelationskoeffizienten \\(r\\) (aus Sitzung 7) vergleichbar. Der Wert für \\(\\phi\\) kann aus \\(\\chi^2\\) berechnet werden mit: \\[ \\phi=\\sqrt{\\frac{\\chi^2}{n}} \\tag{9.4} \\] 9.6.1 Beispiel In unserem Beispiel ergibt sich also für \\(\\phi\\) durch Einsetzung in (9.4): \\[\\begin{aligned} \\phi&amp;=\\sqrt{\\frac{\\chi^2}{n}}\\\\[6pt] &amp;\\approx\\sqrt{\\frac{1,421}{90}}\\\\[4pt] &amp;\\approx0,126 \\end{aligned}\\] Es wird ersichtlich, dass es eine leichte Korrelation der Variablen gibt. Aber in welche Richtung? Dafür müssen wir auf die Kreuztabelle blicken: Der beobachtete Wert für die Wertekombination Fahrrad und Geistes-/Sozialwissenschaft beträgt \\(n_{11}=11\\) und liegt über dem Erwartungswert \\(m_{11}=8,67\\). Damit ist klar: Das Studium von Geistes- und Sozialwissenschaften korreliert positiv mit der Fahrradnutzung für den Pendelweg. Ob diese Korrelation auch statistisch relevant ist, kann mit dem \\(\\chi^2\\)-Test (Sitzung 10) überprüft werden. 9.7 Berechnung des Cramér-Index Bisher wurden in dieser Sitzung nur Verteilungen von zwei dichotomen Variablen besprochen. Nun gibt es aber auch nominalskalierte bivariate Verteilungen, in denen die Merkmale mehr als zwei Werte annehmen können (also nicht dichotom sind). In diesem Fall ist der Cramér-Index (auch Cramérs \\(v\\), engl. Cramér index) ein geeigneter Kennwert für die Abhängigkeit der Variablen. Die Formel für den Cramér-Index lautet \\[ \\mathit{CI}=\\sqrt{\\frac{\\chi^2}{n\\cdot (\\mathrm{min}(k, \\ell)-1)}} \\tag{9.5} \\] wobei der Ausdruck \\(\\mathrm{min}(k,\\ell)\\) für den kleineren Wert aus Zeilenanzahl \\(k\\) und Spaltenanzahl \\(\\ell\\) steht. In einer \\(2\\times2\\)-Tabelle ist dieser Wert identisch mit dem \\(\\phi\\)-Koeffizienten. 9.7.1 Beispiel Hätten wir im Beispiel die Erhebung nicht auf dichotome Variablen reduziert, sondern die Wissenschaftsdisziplinen und Verkehrsmittel direkt erhoben, so würde sich die Kreuztabelle vielleicht wie in ?? darstellen. Dabei werden die Erwartungswerte wie gehabt mit (9.1) und die Teilwerte für \\(\\chi^2\\) mit der (9.3) errechnet. Der \\(\\chi^2\\)-Wert ergibt sich wieder aus der Summe (s. (9.2)): \\[\\begin{aligned} \\chi^2&amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{\\ell}\\frac{(n_{ij}-m_{ij})^{2}}{m_{ij}}\\\\[4pt] &amp;\\approx 0,144+1,137+0,742+0,548+0,705+0,111\\\\&amp;\\quad+0,002+0,052+0,082+0,792+3,231+1,574 \\\\ &amp; =9,120 \\end{aligned}\\] Mit diesem Wert kann der Cramér-Index anhand von (9.5) berechnet werden. Die Zeilenanzahl ist \\(k=4\\) und die Spaltenanzahl \\(\\ell=3\\). Der Ausdruck \\(\\mathrm{min}(k,\\ell)\\) ergibt den kleineren dieser Werte, also 3: \\[\\begin{aligned} \\mathit{CI}&amp;=\\sqrt{\\frac{\\chi^2}{n\\cdot (\\mathrm{min}(k, \\ell)-1)}}\\\\[6pt] &amp;\\approx\\sqrt{\\frac{9,122}{90\\cdot(3-1)}}\\\\[4pt] &amp;\\approx0,225 \\end{aligned}\\] Dieser Wert ist größer als der oben berechnete \\(\\phi\\)-Koeffizient. Das ist nicht besonders überraschend: Eine detailliertere Erfassung der Variablen führt zu einem deutlicheren Zusammenhang. 9.8 Aufgaben 9.8.1 Aufgabe 1 Sie fragen sich, wie die Wohnumgebung einer Person (Stadt oder Land) damit zusammenhängt, ob die Person ein eigenes Auto besitzt. Sie erheben die folgende Messreihe: Wohnort Autobesitz Land Ja Land Ja Stadt Nein Stadt Nein Stadt Ja Stadt Nein Land Ja Land Nein Land Ja Land Ja Stadt Nein Land Ja Land Ja Land Ja Stadt Nein Land Ja Stadt Nein Land Nein Stadt Ja Stadt Nein Überführen Sie die Daten in eine Kreuztabelle. Berechnen Sie die Erwartungswerte für jedes Tabellenfeld. Berechnen Sie \\(\\chi^2\\). Berechnen Sie den \\(\\phi\\)-Koeffizienten. Besteht eine Korrelation? In welche Richtung? 9.8.2 Aufgabe 2 Sie interessieren sich dafür, ob zwei Ja/Nein-Fragen auf einem Fragebogen korrelieren. Sie ermitteln folgende Häufigkeiten: Vervollständigen Sie die Kreuztabelle um ihre Summen und die Erwartungswerte. Berechnen Sie \\(\\chi^2\\) und den \\(\\phi\\)-Koeffizienten. Wie würden Sie den Zusammenhang beschreiben? 9.8.3 Aufgabe 3 Sie möchten überprüfen, ob auf dem Arbeitsmarkt anhand von Namen diskriminiert wird, die auf einen Migrationshintergrund schließen lassen. Sie antworten als fiktive Bewerber*innen mit vergleichbaren Qualifikationen auf zufällige Stellenanzeigen und halten fest, ob die jeweilige Bewerbung in einer Einladung zum Vorstellungsgespräch resultiert. Sie erheben diese Daten: Können Sie einen Zusammenhang zwischen Namensherkunft und Erfolg der Bewerbung feststellen? Begründen Sie Ihre Antwort. 9.9 Tipps zur Vertiefung Kapitel 9.1, 10.3.4 und 10.3.7 in Bortz und Schuster (2010) Kapitel 6.7.2 in Bahrenberg, Giese und Nipper (2010) Kapitel 2.3 in Klemm (2002) 9.10 Quellen "],["chi-quadrat-tests.html", "Sitzung 10 Chi-Quadrat-Tests 10.1 Lernziele dieser Sitzung 10.2 Anwendungsbereich 10.3 \\(\\chi^2\\)-Unabhängigkeitstest 10.4 \\(\\chi^2\\)-Anpassungstest 10.5 Aufgaben 10.6 Tipps zur Vertiefung 10.7 Quellen", " Sitzung 10 Chi-Quadrat-Tests 10.1 Lernziele dieser Sitzung Sie können einen \\(\\chi^2\\)-Unabhängigkeitstest durchführen. einen \\(\\chi^2\\)-Anpassungstest durchführen. 10.2 Anwendungsbereich In Sitzung 9 haben wir gelernt, wie für bivariate Verteilungen Korrelationen beschrieben werden können, wenn beide Variablen nominalskaliert sind. Grundlage dafür waren die Häufigkeiten von Wertekombinationen in der Kreuztabelle. Auch für \\(\\chi^2\\)-Tests sind beobachtete Häufigkeiten in einer Kreuztabelle unser Ausgangspunkt. Wir fragen jedoch nicht nach einem Kennwert für die Stärke der Korrelation, sondern wollen wissen, ob es einen statistisch signifikanten Zusammenhang zwischen den beiden Variablen gibt  also einen Zusammenhang, der nur mit einer Wahrscheinlichkeit \\(\\alpha\\) zufällig zustande gekommen ist. Um den Unterschied zu verdeutlichen: Bei sehr großen Fallzahlen kann auch eine leichte Korrelation statistisch signifikant sein, bei kleinen Fallzahlen wird es es selbst für starke Korrelationen schwierig, eine statistische Signifikanz nachzuweisen. Mit dem \\(\\chi^2\\)-Unabhängigkeitstest und dem \\(\\chi^2\\)-Anpassungstest lernen wir im Folgenden zwei leicht unterschiedliche Varianten des \\(\\chi^2\\)-Tests kennen. Beide sollen direkt an Beispielen ausgeführt werden. 10.3 \\(\\chi^2\\)-Unabhängigkeitstest Grundlage sind bivariate Häufigkeiten, die in einer Kreuztabelle dargestellt werden können (s. 10.1). Wie Kreuztabellen erstellt werden, haben wir bereits in Sitzung 9 behandelt. Tabelle 10.1: Kreuztabelle der Beispieldaten Grundwehrdienst Zivildienst Land 18 11 29 Stadt 10 23 33 28 34 62 Unser Beispieldatensatz beschäftigt sich mit Kriegsdienstverweigerern. Zwischen 1956 und 2011 galt in der BRD die Wehrpflicht, d.h. alle vom Staat als männlich erfassten und als tauglich gemusterte jungen Menschen mussten Dienst an der Waffe leisten  es sei denn, sie verweigerten den Kriegsdienst und leisteten stattdessen Zivildienst (z.B. in sozialen Einrichtungen). Zusätzlich zur Frage der Kriegsdienstverweigerung sei in einer Zufallsstichprobe von als tauglich gemusterten erhoben, ob der Wohnort eine Gemeinde mit über oder unter 20000 Einwohner*innen (Stadt oder Land) ist.5 Die Ergebnisse sind in 10.1 zusammengefasst. Wir interessieren uns für den statistischen Zusammenhang dieser beiden Variablen, und zwar möchten wir die Hypothese prüfen, dass Menschen aus der Stadt eher den Kriegsdienst verweigerten als Menschen vom Land. Der Test wird entlang der bekannten sechs Schritte ausgeführt. 10.3.1 Test wählen und Voraussetzungen prüfen Für den \\(\\chi^2\\)-Unabhängigkeitstest müssen folgende Voraussetzungen erfüllt sein: Ziel ist die Überprüfung einer bivariaten Verteilung auf einen statistisch signifikanten Zusammenhang zwischen zwei nominalskalierten Variablen. Grundlage sind beobachtete Häufigkeiten aus einer einfachen, unabhängigen Zufallsstichprobe. Alle Tabellenfelder enthalten beobachtete Häufigkeiten \\((n_{ij}\\geq 5)\\). Für unsere Beispieldaten sind diese Voraussetzungen gegeben. 10.3.2 Hypothesen formulieren Wir haben wieder zwei Möglichkeiten: die gerichtete und die ungerichtete Alternativhypothese. 10.3.2.1 Ungerichtete Alternativhyptothese Wir verzichten an dieser Stelle auf mathematische Notationen und würden bei ungerichteter Alternativhypothese im Klartext schreiben: \\[\\begin{aligned} H_0 &amp;: \\textrm{Es gibt keinen Zusammenhang zwischen Wohnort und Verweigerungsentscheidung.}\\\\ H_1 &amp;: \\textrm{Es gibt einen Zusammenhang zwischen Wohnort und Verweigerungsentscheidung.} \\end{aligned}\\] 10.3.2.2 Gerichtete Alternativhyptothese Im Falle einer gerichteteten Alternativhypothese bleibt die Nullhypothese bestehen, aber die Alternativhypothese gibt eine bestimmte Richtung des Zusammenhangs vor. \\[\\begin{aligned} H_0 &amp;: \\textrm{Es gibt keinen Zusammenhang zwischen Wohnort und Verweigerungsentscheidung.}\\\\ H_1 &amp;: \\textrm{Es gibt einen positiven Zusammenhang zwischen Wohnort in der Stadt} \\\\ &amp;\\quad\\textrm{und Kriegsdienstverweigerung.} \\end{aligned}\\] Gerichtete Alternativhypothesen sind im \\(\\chi^2\\)-Unabhängigkeitstest nur für \\(2\\times2\\)-Tabellen möglich. Im Beispiel entscheiden wir uns für die gerichtete Alternativhypothese, denn wir vermuten einen Zusammenhang in diese bestimmte Richtung. 10.3.3 Signifikanzniveau entscheiden Wie in anderen Tests ist ein Signifikanzniveau von \\(\\alpha=0,05\\) üblich, wofür wir uns auch im Beispiel entscheiden. 10.3.4 Kritischen Wert bestimmen Bei \\(\\chi^2\\)-Tests gibt es immer nur einen kritischen Wert. Zunächst müssen beim \\(\\chi^2\\)-Unabhängigkeitstest die Freiheitsgrade bestimmt werden mit der Formel: \\[\\mathit{df} = (k - 1) \\cdot (\\ell - 1) \\tag{10.1}\\] wobei auch hier wieder \\(k\\) für die Zeilenanzahl und \\(\\ell\\) für die Spaltenanzahl steht. Im Beispiel also: \\[\\begin{aligned} \\mathit{df} &amp;= (k - 1) \\cdot (\\ell - 1)\\\\ &amp;=(2-1)\\cdot (2 - 1) = 1 \\end{aligned}\\] Damit lässt sich der kritische Wert aus der Formelsammlung ablesen, die allerdings für ungerichtete Alternativhypothesen ausgelegt ist. Hätten wir eine ungerichtete Alternativhypothese gewählt, würde der Ablehnungsbereich also definiert durch: \\[\\begin{aligned} \\chi^2 &amp;\\geq \\chi^2_{df;(1-\\alpha)}\\\\ \\chi^2 &amp;\\geq \\chi^2_{1;95\\%}\\\\ \\chi^2 &amp;\\geq 3,841 \\end{aligned}\\] Für unsere gerichtete Alternativhypothese dürfen wir den Ablehnungsbereich jedoch verdoppeln (müssen aber im nächsten Schritt auch prüfen, ob die Richtung auch stimmt): \\[\\begin{aligned} \\chi^2 &amp;\\geq \\chi^2_{df;(1-2\\cdot\\alpha)}\\\\ \\chi^2 &amp;\\geq \\chi^2_{1;90\\%}\\\\ \\chi^2 &amp;\\geq 2,706 \\end{aligned}\\] 10.3.5 Prüfgröße berechnen Wie in Sitzung 9 besprochen, wird die Prüfgröße \\(\\chi^2\\) anhand der Formel \\[ \\chi^2= \\sum_{i=1}^{k}\\sum_{j=1}^{\\ell}\\frac{(n_{ij}-m_{ij})^{2}}{m_{ij}} \\tag{9.2} \\] errechnet. Dabei ist die Ermittlung der Erwartungswerte \\(m_{ij}\\) ein notwendiger Schritt, und auch die Teilwerte für \\(\\chi^2\\) können wieder direkt in die Kreuztabelle eingetragen werden. Tabelle 10.2: Kreuztabelle mit Erwartungswerten und Teilwerten für \\(\\chi^2\\) Grundwehrdienst Zivildienst Land 18(13,10)1,833 11(15,90)1,510 29 Stadt 10(14,90)1,611 23(18,10)1,327 33 28 34 62 Für unser Beispiel erfolgt die Berechnung anhand 10.2. Zunächst muss dabei geprüft werden, ob die Richtung unserer Alternativhypothese stimmt. Die beobachtete Häufigkeit der Zivildienstleistenden in der Stadt \\(n_{22}=23\\) ist größer als der Erwartungswert \\(m_{22}=18,1\\). Wenn eine Signifikanz nachgewiesen werden kann, dann also für den positiven Zusammenhang zwischen Wohnort in der Stadt und Kriegsdienstverweigerung (wie in unserer Alternativhypothese spezifiziert). Für \\(\\chi^2\\) ergibt sich im Beispiel: \\[\\begin{aligned} \\chi^2 &amp;= \\sum_{i=1}^{k}\\sum_{j=1}^{\\ell}\\frac{(n_{ij}-m_{ij})^{2}}{m_{ij}}\\\\[4pt] &amp;=1,833+1,51+1,611+1,327\\\\ &amp;=6,281 \\end{aligned}\\] 10.3.6 Ergebnis interpretieren Der Wert der Prüfgröße \\(\\chi^2=6,281\\) liegt deutlich im Ablehnungsbereich \\(\\chi^2\\geq 2,706\\). Die Nullhypothese kann abgelehnt werden. Es wurde ein statistisch signifikanter positiver Zusammenhang zwischen Wohnort in Gemeinden mit über 20000 Einwohner*innen und Kriegsdienstverweigerung festgestellt (\\(\\alpha=0,05\\)). 10.4 \\(\\chi^2\\)-Anpassungstest Beim \\(\\chi^2\\)-Anpassungsest geht es um die Häufigkeiten eines nominalskalierten Merkmals  er ist deshalb der univariaten Teststatistik zuzuordnen. Der Test überprüft, ob das Merkmal entlang einer vorgegebenen Verteilung (im Normalfall gleichmäßig) verteilt ist, oder ob es signifikante Abweichungen von dieser erwarteten Verteilung gibt. Ein Beispiel: Für größere Verspätungen (\\(\\geq\\) 10 Minuten) beim ÖPNV einer Großstadt wird festgehalten, an welchen Wochentagen sie auftreten. Wir ignorieren Wochenden und Feiertage und fragen uns, ob sich die Verzögerungen gleichmäßig auf Werktage verteilen, oder ob es signifikante Abweichungen in Bezug auf den Wochentag gibt. Die Werte in 10.3 seien über drei Monate hinweg erhoben worden. Tabelle 10.3: Häufigkeiten größerer Verspätungen im ÖPNV Wochentag Häufigkeit Montag 459 Dienstag 409 Mittwoch 414 Donnerstag 387 Freitag 437 Wir befolgen wieder die sechs Schritte für statistische Testverfahren. 10.4.1 Test wählen und Voraussetzungen prüfen Für den \\(\\chi^2\\)-Anpassungstest müssen folgende Voraussetzungen erfüllt sein: Ziel ist die Überprüfung einer nominalskalierten Variable auf eine statistisch signifikante Abweichung von einer vorgegebenen Verteilung. Grundlage sind beobachtete Häufigkeiten aus einer einfachen, unabhängigen Zufallsstichprobe. Alle Tabellenfelder enthalten beobachtete Häufigkeiten \\((n_{i}\\geq 5)\\). In unserem Beispiel sind diese Voraussetzungen gegeben. 10.4.2 Hypothesen formulieren \\[\\begin{aligned} H_0 &amp;: \\textrm{Starke Verspätungen sind an allen Werktagen gleich wahrscheinlich.}\\\\ H_1 &amp;: \\textrm{Starke Verspätungen sind an manchen Wertkagen wahrscheinlicher als an anderen.} \\end{aligned}\\] Gerichtete Hypothesen dürfen hier nur bei dichotomen Variablen formuliert werden (also bei zwei Tabellenfeldern). 10.4.3 Signifikanzniveau entscheiden Üblich: \\(\\alpha=0,05\\) 10.4.4 Kritischen Wert bestimmen Die Freiheitsgrade bestimmen sich aus \\[\\mathit{df}=k-1 \\tag{10.2}\\] wobei \\(k\\) hier einfach die Anzahl der Katorien ist. In unserem Beispiel (bei fünf Werktagen) also: \\[\\begin{aligned} \\mathit{df}&amp;=k-1\\\\ &amp;=5-1=4 \\end{aligned}\\] Der kritische Wert für den Ablehnungsbereich ist der Formelsammlung zu entnehmen. \\[\\begin{aligned} \\chi^2 &amp;\\geq \\chi^2_{\\mathit{df};(1-\\alpha)}\\\\ \\chi^2 &amp;\\geq \\chi^2_{4;95\\%}\\\\ \\chi^2 &amp;\\geq 9,488 \\end{aligned}\\] Auch hier wäre bei einer gerichteten Hypothese der kritische Wert \\(\\chi^2_{\\mathit{df};(1-2\\cdot \\alpha)}\\) anzuwenden  dies ist allerdings wie bereits erwähnt nur für dichotome Variablen möglich. 10.4.5 Prüfgröße berechnen Die Prüfgröße \\(\\chi^2\\) berechnet sich analog zu vorherigen Beispielen. Einzige Besonderheit: Die Erwartungswerte werden direkt anhand der zu erwartenden (im Regelfall: gleichmäßigen) Verteilung bestimmt. Im Beispiel ergibt sich in den fünf Kategorien jeweils ein Erwartungswert von \\[\\frac{n}{k}=\\frac{2106}{5}=421,2\\] Tabelle 10.4: Tabelle für den \\(\\chi^2\\)-Anpassungstest Montag Dienstag Mittwoch Donnerstag Freitag 459 409 414 387 437 2106 (421,2) (421,2) (421,2) (421,2) (421,2) 3,392 0,353 0,123 2,777 0,593 Dann nehmen wir wieder eine Tebelle zu Hilfe um die Prüfgröße \\(\\chi^2\\) zu berechnen (s. 10.4). Wie gehabt werden einfach die Teilwerte zusammengezählt: \\[\\begin{aligned} \\chi^2 &amp;= \\sum_{i=1}^{k}\\frac{(n_{i}-m_{i})^{2}}{m_{i}}\\\\[4pt] &amp;=3,392 + 0,353 + 0,123 + 2,777 + 0,593\\\\ &amp;=7,238 \\end{aligned}\\] 10.4.6 Ergebnis interpretieren Der Ablehnungsbereich \\(\\chi^2 \\geq 9,488\\) wurde nicht erreicht. Die Nullhypothese muss beibehalten werden. Eine statistisch signifikante Abweichung von einer gleichmäßigen Verteilung konnte nicht nachgewiesen werden (\\(\\alpha=0,05\\)). 10.4.7 Andere Verteilungen Die theoretische Verteilung, von der eine signifikante Abweichung festgestellt werden soll, ist im obigen Beispiel uniform, d.h. gleichmäßig. Allerdings kann beim Anpassungstest auch von anderen Verteilungen ausgegangen werden  so könnte eine (begründete) Nullhypothese auch lauten, dass Kategorie A doppelt so viele Fallzahlen aufweist wie Kategorie B und C. In der Praxis wird der \\(\\chi^2\\)-Anpassungstest auch oft verwendet, um nachzuweisen, dass keine signifikante Abweichung von der Normalverteilung zu beobachten ist  nur dann dürfen nämlich viele statistische Verfahren durchgeführt werden. 10.5 Aufgaben 10.5.1 Aufgabe 1 Sie interessieren sich dafür, ob in einem Unternehmen der Tätigkeitsbereich mit dem Geschlecht der Angestellten zusammenhängt. In den Personalakten sind Angestellte als männlich oder weiblich erfasst und ihre Tätigkeitsfelder in Leitende Tätigkeit, Administration und Fertigung unterteilt. Folgende Häufigkeiten sind erfasst: Welchen Test führen Sie durch? Formulieren Sie die Hypothesen. Das Thema wird in der Unternehmensleitung bereits kontrovers diskutiert, weshalb Sie einen Fehler 1. Art zu 99% ausschließen möchten. Wie lautet das Signifikanzniveau? Bestimmen Sie die Freiheitsgrade und den kritischen Wert. Berechnen Sie die Prüfgröße. Wie interpretieren Sie das Ergebnis? 10.5.2 Aufgabe 2 Eine Ihner Bekannten behauptet, dass beim Elfmeterschießen  statistisch gesehen  in 60% der Fälle das Team gewinnt, das zuerst den Strafstoß ausführt. Sie möchten das empirisch überprüfen und schauen sich in Archiven siebzig Partien bei Fußballturnieren an, die durch Elfmeterschießen entschieden wurden. Tatsächlich stellen Sie fest, dass in genau 60% der Fälle das zuerst ausführende Team gewann. Prüfen Sie, ob diese Beobachtung auch statistisch relevant ist. Wählen Sie 5% als Signifikanzniveau. 10.6 Tipps zur Vertiefung Kapitel 9 in Bortz und Schuster (2010) Kapitel 5.3.4 in Bahrenberg, Giese und Nipper (2010) Kapitel 13 in Klemm (2002) 10.7 Quellen Bahrenberg, Gerhard, Ernst Giese und Josef Nipper. 2010. Statistische Methoden in der Geographie. Bd. 1. Univariate und bivariate Statistik. Stuttgart: Bornträger. Benninghaus, Hans. 2007. Deskriptive Statistik. Eine Einführung für Sozialwissenschaftler. Wiesbaden: VS Verlag. Bortz, Jürgen und Christof Schuster. 2010. Statistik für Human- und Sozialwissenschaftler. Berlin: Springer. Haseloff, Otto W., Hans-Joachim Hoffmann, John H Maindonald und W John Braun. 1968. Kleines Lehrbuch der Statistik DAAG. Data Analysis and Graphics Data and Functions. Berlin: de Gruyter. Klemm, Elmar. 2002. Einführung in die Statistik. Für die Sozialwissenschaften. Wiesbaden: Westdeutscher Verlag. R Core Team. 2018. R: A Language and Environment for Statistical Computing. Wien: R Foundation for Statistical Computing. https://www.R-project.org/ (zugegriffen: ). Hier wird also eine verhältnisskalierte Variable (Bevölkerungszahl der Gemeinde) in eine nominalskalierte Variable transformiert. In Fällen wie diesen, wo die Variable nach der Transformation nur zwei Werte annehmen kann, sprechen wir auch von der Dichotomisierung einer Variable. "]]
