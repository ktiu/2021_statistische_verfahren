---
title: Statistische Verfahren in der Geographie
subtitle: Skript für den Theorieteil
author:
  - name: Till Straube
    url: https://user.uni-frankfurt.de/~tstraube
    email: straube@geo.uni-frankfurt.de
    affiliation: |
      | Institut für Humangeographie
      | Goethe-Universität Frankfurt
date: Sommersemester 2023
site: bookdown::bookdown_site
lang: de
documentclass: report
tables: true
bibliography: ["statistik.bib"]
csl: /home/till/.csl/chicago-author-date-de.csl
link-citations: yes

papersize: a4
fontsize: 11pt
geometry: margin=2.5cm,top=3.5cm,bottom=3cm
fontfamily: sourcesanspro
fontfamilyoptions: default
csquotes: true
---

```{r setup, include=F}

library(dplyr)
library(purrr)
library(tibble)
library(ggplot2)
library(magrittr)
library(lectuR)

options(OutDec = ",")

knitr::opts_chunk$set(
  fig.align  = "center",
  fig.width  = 5,
  fig.height = 3,
  fig.pos    = "!h",
  echo       = FALSE,
  warning    = FALSE,
  message    = FALSE,
  cache      = T,
  comment    = NA
)

target <- knitr::opts_knit$get("rmarkdown.pandoc.to")

if (!is.null(target)) {
  if (target == "html") {
    knitr::opts_chunk$set(
      dev        = "svglite",
      out.width  = "450px"
    )
  } else if (target == "latex") {
    knitr::opts_chunk$set(
      dev        = "pdf",
      out.width  = ".6\\linewidth"
    )
  }
}

rtip <- function(text) {
  if ((! is.null(target)) && target == "latex") {
    c("\\begin{rtip}",
      "%s",
      "\\end{rtip}") -> lines
    text %>%
      stringr::str_replace_all("`([^`]*)`", "\\\\verb|\\1|") -> text
  } else {
    c("<div class='rtip'>Softwarehinweis</div>",
      "<div class='rtip_content'>%s</div>") -> lines
  }
  lines %>%
    paste(collapse = "\n") %>%
    sprintf(text) %>%
    knitr::asis_output()
}

goethe_blue    <- "#00618F"
light_gray     <- "#f8f6f5"
sand_gray      <- "#e4e3dd"
dark_gray      <- "#4d4b46"
purple         <- "#860047"
emo_red        <- "#b3062c"
mustard_yellow <- "#e3ba0f"
green          <- "#737c45"
magenta        <- "#ad3b76"
orange         <- "#c96215"
sun_yellow     <- "#f7d926"
light_green    <- "#a5ab52"
light_blue     <- "#48a9da"

th_css <- "background-color: var(--sand_gray);
           color: var(--goethe_blue);
           font-weight: 600"

dcat <- function(xs) {
  xs %>%
    cat(sep = "  ", fill = T)
}

library(extrafont)

theme_goethe <- function() {
  target <- knitr::opts_knit$get("rmarkdown.pandoc.to")
  text <- ggplot2::element_text(size = 10)
  if ((! is.null(target)) && target != "latex") {
    text <- ggplot2::element_text(family = "Source Sans Pro", size = 10)
  }
  theme_classic() %+replace%
    theme(
      text = text,
      legend.text.align = 0,
      legend.position = c(0.9, 0.8)
    )
}

nummeriere <- function(typ = c("aufgabe", "lösung"), sitzung, aufgabe) {
  sprintf(list(aufgabe = c("### Aufgabe&nbsp;%s-%s {#aufgabe-%s-%s}",
                           "[zur&nbsp;Lösung](#loesung-%s-%s)"),
               lösung  = c("### Lösung&nbsp;%s-%s {#loesung-%s-%s}",
                           "[zur Aufgabenstellung](#aufgabe-%s-%s)"))[[typ]] %>%
            paste(collapse = "\n\n"),
          sitzung, aufgabe, sitzung, aufgabe, sitzung, aufgabe)
}

naechste <- function(typ = c("aufgabe", "lösung"), naechste_sitzung = F) {
  if (naechste_sitzung) {
    counter$sitzung <<- counter$sitzung + 1
    counter$aufgabe <<- 1
  } else counter$aufgabe <<- counter$aufgabe + 1
  nummeriere(typ, counter$sitzung, counter$aufgabe)
}

counter <- list(sitzung = 0, aufgabe = 0)
```

# Terminüberblick {-}

*Alle Sitzungen finden von 14 bis 16h c. t. statt, die Klausuren s. t.*

Datum                 | Sitzung | Inhalt                                                                   | Ort
--------------------: | -----:  | :-----------------------------------                                     | :-----
11. April 2023        |         | [Vorbesprechung]                                                         | HZ10
18. April 2023        | 1       | [Datenerhebung und Häufigkeiten]                                         | HZ10
25. April 2023        | 2       | [Maßzahlen]                                                              | HZ10
2. Mai 2023           | 3       | [$z$-Werte und Normalverteilung](#z-werte-und-normalverteilung)          | HZ10
9. Mai 2023           | 4       | [Schätzstatistik]                                                        | HZ10
16. Mai 2023          | 5       | [Grundlagen der Teststatistik]                                           | HZ10
23. Mai 2023          | 6       | [Testverfahren mit zwei Stichproben]                                     | HZ10
30. Mai 2023          | 7       | [Korrelation]                                                            | HZ10
6. Juni 2023          | 8       | [Lineare Regression]                                                     | HZ10
13. Juni 2023         | 9       | [Kreuztabellen]                                                          | HZ10
20. Juni 2023         | 10      | [$\chi^2$-Tests]<!--(#chi-quadrat-tests)-->                              | HZ10
27. Juni 2023         |         | Klausurvorbereitung                                                      | HZ10
4. Juli 2023          |         | Klausur (14h s. t.)                                                      | H IV
10. Oktober 2023      |         | Nachklausur (14h s. t.)                                                  | TBA

<!--chapter:end:index.Rmd-->

# Vorbesprechung {-}

### Lernziele der Veranstaltung {-}

Sie können...

- Grundbegriffe der Statistik sinnvoll verwenden.
- die wichtigsten statistischen Kennzahlen berechnen.
- gängige Diagramme interpretieren.
- einfache statistische Schätz- und Prüfverfahren anwenden.
- passende Verfahren für verschiedene Aufgaben wählen.

### Konzept der Veranstaltung {-}

- Die gesamte Veranstaltung dient als Klausurvorbereitung
- Die selbständige Anwendung der Verfahren steht im Vordergrund
- Veranstaltung folgt dem [Flipped-Classroom-Konzept](https://de.wikipedia.org/wiki/Umgedrehter_Unterricht)

### Sitzungsvorbereitung {-}

- Materialien werden zur eigenständigen Vorbereitung bereit gestellt
- Dieses Online-Skript mit den Kerninhalten
- Darin: Videos (aus 2020) mit Beispielen und Übungen
- Darin: Verweise auf weiterführende Literatur, YouTube-Videos, etc.
- Fehler und Unklarheiten bitte per E-Mail melden!

### Sitzungsablauf {-}

- Dienstags, 14 h c. t. in HZ10
- Übungsaufgaben (und Lösungen) werden online bereit gestellt
- Teilnehmer\*innen bearbeiten die Aufgaben in Kleingruppen
- Bei Problemen fragen Sie sich erst mal gegenseitig
- Sonst bin ich immer ansprechbar

### Empfehlungen {-}

- Lassen Sie sich auf den wöchentlichen Rhythmus ein
- Bereiten Sie die Sitzungen vor und nach
- Bilden Sie Lerngruppen
- Gleichen Sie in Lerngruppen Ihre Ziele ab
- Machen Sie sich mit Ihrem Taschenrechner vertraut

### Literaturempfehlungen {-}

- Ganz besonders:
  - @bortz (als E-Book bei der UB erhältlich; dieselben Notationskonventionen wie in der Veranstaltung)
- Ergänzend:
  - @delange (geographiebezogen)
  - @bahrenberg (geographiebezogen)
  - @benninghaus (als E-Book bei der UB erhältlich)
- Bedingt:
  - @zimmermann-janschitz2014a (geographiebezogen; als E-Book bei der UB erhältlich)
- Englisch:
  - @burt

### Taschenrechner {-}

- Zulassungsregeln für Klausur wie für Mathe-Abi (Hessen)
- Also kein "programmierbarer" Taschenrechner
- Erlaubt ist z. B. CASIO FX-991DE Plus
- "Wissenschaftlicher" Taschenrechner kann von großem Vorteil sein... aber den statistischen Funktionen nicht blind vertrauen!

<!--chapter:end:Vorbesprechung.Rmd-->

# Datenerhebung und Häufigkeiten

### Lernziele dieser Sitzung {-}

Sie können...

- einige Grundbegriffe der Statistik definieren.
- Typen von Stichproben unterscheiden.
- Skalenniveaus von Variablen bestimmen.
- Häufigkeitsverteilungen beschreiben.

### Lehrvideos (Sommersemester 2020) {-}

- [1a) Grundbegriffe](https://video01.uni-frankfurt.de/Mediasite/Play/36dca452df154bd3b7be2e069174e8991d)
- [1b) Skalenniveaus](https://video01.uni-frankfurt.de/Mediasite/Play/5a397035f7a6468fa2cecf802ca8d52a1d)
- [1c) Grundbegriffe](https://video01.uni-frankfurt.de/Mediasite/Play/5fce0458009b4da283b14fdc30e3a0ea1d)

## Statistische Praxis

Was ist Statistik? Je nach Perspektive kann Statistik vieles sein: ein Teilgebiet der Mathematik, ein Untersuchungsobjekt kritischer Forschung oder ein unbeliebtes Studienfach.

Im Rahmen dieser Veranstaltung soll Statistik als eine Zusammenstellung von Praktiken in der quantitativen Forschung verstanden werden, wobei ihre Anwendung stets im Mittelpunkt steht. Eine hilfreiche Definition findet sich bei @haseloff:

> "Allgemein kann gesagt werden: Die Statistik hat es mit Zahlen zu tun, die entweder aus Abzählvorgängen oder aus Messungen gewonnen wurden. Ihre Aufgabe ist es, ein solches Zahlenmaterial in eine optimal übersichtliche und informationsreiche Form zu bringen, aus ihnen methodische Schlußfolgerungen zu ziehen und gegebenfalls auch die Ursachen der analysierten Zahlenverhältnisse mit sachlichen Methoden aufzudecken." [@haseloff: 27]

### Grundbegriffe der Statistik
\nopagebreak

#### Untersuchungselement

Untersuchungselemente (auch Untersuchungseinheiten, Merkmalsträger, bei Personen: Proband\*innen, engl. *sampling unit*) sind die individuellen Gegenstände empirischer Untersuchungen. Bei einer Hochrechnung zur Bundestagswahl ist dies z. B. eine befragte Wählerin.

#### Stichprobe

Eine Stichprobe (engl. *sample*) ist die Menge aller Untersuchungselemente, deren Daten direkt erhoben werden. Die Anzahl der Untersuchungselemente in der Stichprobe wird in Formeln mit $n$ bezeichnet. Bei einer Hochrechnung z.B. bilden alle tatsächlich befragten Wähler\*innen die Stichprobe.

#### Grundgesamtheit

Die Grundgesamtheit (auch Population, engl. *population*) ist die Menge aller potentiell untersuchbaren Elemente, über die Aussagen getroffen werden sollen. Die Stichprobe ist eine Teilmenge der Grundgesamtheit. Die Anzahl der Elemente in der Grundgesamtheit wird in Formeln mit $N$ bezeichnet. Bei einer Hochrechnung zur Bundestagswahl sind dies z.B. alle Wähler\*innen (bzw. alle Wahlberechtigten, wenn Wahlbeteiligung von Interesse ist).

#### Variable

Variablen (auch Merkmale, engl. *variable*) sind Informationen über die Untersuchungselemente, die in einer Untersuchung von Interesse sind. Typischerweise unterscheiden sie sich von Untersuchungselement zu Untersuchungseelement, sind also variabel. Bei einer Hochrechnung ist dies die Antwort auf die Frage: "Welche Partei haben Sie gerade gewählt?"

#### Wert

Ein Wert (auch Merkmalsausprägung, engl. *observation*) ist die erfasste Ausprägung einer Variable bei einem Untersuchungselement. In Formeln werden Werte mit $x_1, x_2, x_3, ..., x_n$ durchnummeriert. Bei einer Hochrechnung kann die Variable "gewählte Partei" für ein Untersuchungselement z.B. den Wert "CDU" annehmen.

#### Kennwert

Kennwerte (auch Maßzahlen, Kennzahlen, engl. *summary statistics*) sind Zahlen, die aus den beobachteten Werten errechnet werden. Sie können beispielsweise Aufschluss über Mittelwerte und Verteilung einer Variable oder den Zusammenhang mehrerer Variablen geben. Bei einer Hochrechnung sind z.B. die relativen Häufigkeiten (in Prozent) der Variable "gewählte Partei" von besonderem Interesse.

### Taxonomien statistischer Verfahren

Statistische Verfahren werden in mehrerlei Hinsicht unterschieden, wie im Folgenden beschrieben. Dabei schließen sich verschiedene Kategorien nicht unbedingt aus, es gibt also durchaus statistische Verfahren, die z.B. als univariat *und* deskriptiv bezeichnet werden.

#### Uni-, bi- und multivariate Statistik

Bei diesen Bezeichnungen ist entscheidend, wie viele Variablen bei den jeweiligen Verfahren zum Einsatz kommen. Im Allgemeinen spricht man bei einer Variable von univariater Statistik, bei zwei Variablen von bivariater Statistik und bei mehr als zwei Variablen von multivariater Statistik. (Manchmal werden allerdings auch Verfahren mit nur zwei Variablen als multivariat bezeichnet.)

In dieser Veranstaltung beschäftigen wir uns zunächst mit univariaten, dann mit bivariaten Verfahren. Verfahren mit mehr als zwei Variablen werden nicht behandelt.

#### Deskriptive und schließende Statistik

Unabhängig von der Anzahl der Variablen unterscheidet man auch nach der Art und Weise des Vorgehens:

##### Deskriptive Statistik

Die deskriptive Statistik (auch: beschreibende Statistik) dient der Beschreibung der Verteilung von Merkmalen, indem sie z. B. Durchschnittswerte bildet, Häufigkeiten bestimmt oder etwas über die Streuung eines Merkmals aussagt. Sie kann so große Datenmengen übersichtlicher machen, indem sie diese ordnet, gruppiert oder verdichtet. Sie erleichtert es also, das Charakteristische, Wichtige zu erkennen.

##### Schließende Statistik

Die schließende Statistik (auch: analytische, operative Statistik, Inferenzstatistik, Prüfstatistik) verhilft dazu, von Eigenschaften einer Stichprobe auf Eigenschaften der Grundgesamtheit verallgemeinern bzw. schließen zu können (deshalb eben auch: schließende Statistik) und diese Einschätzung überprüfen zu können.

Die schließende Statistik wird weiter unterteilt in Schätz- und Teststatistik:

###### Schätzende Statistik

Die Schätzstatistik schätzt Kennwerte der Grundgesamtheit aus den Kennwerten einer Stichprobe.

###### Testende Statistik

Die Teststatistik überprüft, als wie wahrscheinlich oder unwahrscheinlich gemachte Schätzungen bzw. Hypothesen gelten können.

### Ablauf einer statistischen Untersuchung

Eine typische Anwendung statistischer Verfahren in der Forschung folgt diesem Schema:

#### Datenerhebung

- Eigene Erhebung z.B. durch Zählen, Messen, Befragung (primärstatistische Daten)
  - Auswahl von Untersuchungseinheiten
  - Wahl der Datenniveaus
- Rückgriff auf vorhandenes Datenmaterial (sekundärstatistische Daten)

#### Datenaufbereitung

- Verdichtung des gewonnenen Datenmaterials und Digitalisierung in Form einer Datenmatrix
- Verschneidung von mehreren Datensätzen
- Vereinheitlichung und Säuberung der Daten
- Überblick verschaffen durch einfache Beschreibung von Häufigkeiten und Maßzahlen (deskriptive Statistik)

#### Datenauswertung

- Verdichtete Beschreibung von Verteilungsmustern einer Variable (univariate deskriptive Statistik)
- Verdichtete Beschreibung der Beziehung zwischen zwei Variablen (bivariate deskriptive Statistik)
- Schluss von Stichprobe auf Grundgesamtheit (Schätzstatistik)
- Testen von Hypothesen über die Grundgesamtheit (Teststatistik)


## Grundlagen der Datenerhebung

\nopagebreak

### Typen von Stichproben

\nopagebreak

#### Reine Zufallsstichprobe

Bei endlichen Grundgesamtheiten können Lotterieverfahren angewendet werden. Dabei wird allen Elementen der Grundgesamtheit eine Zahl zwischen 1 und $N$ zugeordnet. Anschließend werden Zufallszahlen ausgewählt und die entsprechenden Elemente in die Stichprobe übernommen.

#### Systematische Zufallsstichprobe

Die Elemente einer endlichen Grundgesamtheit werden in eine Rangordnung gebracht (Nummerierung 1 bis $N$). Anschließend wählt man jedes $(N/n)$-te Element aus. So entsteht eine Stichprobe der Größe $n$.

#### Geschichtete Zufallsstichprobe

Die Elemente einer endlichen Grundgesamtheit werden in Schichten (Klassen) zusammengefasst. Anschließend zieht man eine Zufallsstichprobe aus jeder Schicht. Geschichtete Stichproben setzen die Kenntnis einiger Parameter der Grundgesamtheit voraus. Zur Aufteilung des Stichprobenumfangs auf die einzelnen Schichten wird in der Regel die proportionale Aufteilung gewählt.

#### Klumpenstichprobe

Hier ist die Grundgesamtheit schon in "natürliche" Gruppen aufgeteilt (z.B. Schulklassen) und es werden mehrere dieser Gruppen (Klumpen, engl. *cluster*) nach einem Zufallsverfahren als Stichprobe gewählt.

> "Man beachte, dass ein einzelner Klumpen (...) keine Klumpenstichprobe darstellt, sondern eine Ad-hoc-Stichprobe, bei der zufällige Auswahlkriterien praktisch keine Rolle spielen. Die Bezeichnung „Klumpenstichprobe“ ist nur zu rechtfertigen, wenn mehrere zufällig ausgewählte Klumpen vollständig untersucht werden." [@bortz: 81]

### Variablentypen

\nopagebreak

#### Qualitative Variablen

Qualitative Variablen können nicht der Größe nach, sondern nur im Hinblick auf ihre Eigenschaft/Art ("Qualität") unterschieden werden (z.B. Parteizugehörigkeit, Telefonnummer, Automarke).

Qualitative Variablen, die nur zwei mögliche Werte annehmen können, nennt man "dichotome" Variablen (etwa Antworten auf Ja-Nein-Fragen).

#### Quantitative Variablen

Quantitative Variablen können der Größe nach unterschieden werden (Bsp. Geburtenzahl, Arbeitslosenzahl).

Quantitative Variablen können diskret oder stetig sein:

##### Diskrete Variablen

Diskrete Variablen (auch diskontinuierliche Variablen) können nur endlich viele, ganzzahlige Werte annehmen. Zwischen zwei Ausprägungen befindet sich eine abzählbare Menge anderer Ausprägungen (z.B. Anzahl eigener Kinder, Haushaltsgröße in Personen).

##### Stetige Variablen

Stetige Variablen (auch: kontinuierliche Variablen) können in einem bestimmten Bereich jede beliebige Ausprägung annehmen. Der Ausdehnungsbereich kennt keine Lücken, sondern ist als ein fortlaufendes Kontinuum vorstellbar: Bei stetigen Variablen können zwischen zwei Werten oder Ausprägungen unendlich viele weitere Ausprägungen oder Werte liegen (z.B. Körpergröße, Längengrad in Dezimalform).

### Skalenniveaus

Eine Variable lässt sich aufgrund ihrer Eigenschaften einem Skalenniveau (auch Skalentyp, Messniveau, Datenniveau, engl. *level of measurement*) zuordnen. Bestimmte Rechenoperationen und statistische Verfahren setzen bestimmte Skalenniveaus voraus. Deshalb ist es wichtig zu wissen, welchem Skalenniveau eine Variable zuzuordnen ist.

Variablen lassen sich immer auch einem niedrigeren Skalenniveau zuordnen. Dies geht allerdings mit Informationsverlust einher.

Die im Folgenden beschriebenen Skalenniveaus sind nicht deckungsgleich mit den o.g. Variablentypen. Intervall- und Verhältnisskalen können z.B. jeweils diskret oder stetig sein.

In Tabelle \@ref(tab:skalen) sind die wichtigsten Skalenniveaus im Überblick aufgeführt. "Gültige Lagemaße" sind dabei als Zusatzinformation aufgelistet und werden erst in der [nächsten Sitzung](#lagemaße) behandelt.

```{r skalen}
tribble(
  ~Skalenart, ~Beispiel, ~`mögliche Aussagen`, ~`gültige Lagemaße`,
  "Nominalskala", "Postleitzahl", "Gleichheit, Verschiedenheit", "Modus",
  "Ordinalskala", "Militärischer Rang", "$+$ Größer-kleiner-Relationen", "$+$ Median",
  "Intervallskala", "Temperatur in °C", "$+$ Gleichheit von Differenzen", "$+$ arithmetisches Mittel",
  "Verhältnisskala", "Körpergröße", "$+$ Gleichheit von Verhältnissen", "$+$ geometrisches Mittel") %>%
  tabelle(escape=F, caption="Die vier wichtigsten Skalenniveaus")
```

#### Nominalskala

Die Merkmalsausprägungen einer Variable stehen je 'für sich'; sie lassen sich nicht sinnvoll in eine Rangordnung bringen oder gar miteinander verrechnen.

Die einzige Aussage, die sich über zwei Werte in einer Nominalskala treffen lässt, ist dass sie gleich oder nicht gleich sind.

Beispiele: Postleitzahlen, Telefonnummern, Staatsangehörigkeit, Krankheitsklassifikationen

#### Ordinalskala

Die Merkmalsausprägungen einer Variablen lassen sich sinnvoll in eine Rangordnung bringen, die Abstände zwischen den Merkmalsausprägungen aber lassen sich nicht sinnvoll quantifizieren.

Über zwei Werte in einer Ordinalskala lässt sich nicht nur sagen, ob sie gleich oder verschieden sind (wie in der Nominalskala), sondern darüber hinaus, welcher Wert bei Verschiedenheit größer ist.

Beispiele: Militärische Ränge, Windstärken, pauschale Häufigkeitsangaben (sehr oft ... nie), Zufriedenheitsangaben (sehr zufrieden ... unzufrieden)

#### Metrische Skalen (oder Kardinalskalen)

Abstände zwischen den Merkmalsausprägungen lassen sich exakt angeben.

Zusätzlich zu den Möglichkeiten der Ordinalskala können auf einer metrischen Skala Rechenoperationen auch sinnvoll auf die Differenzen zwischen den Merkmalsausprägungen angewendet werden.

Metrische Skalen werden unterteilt in Intervall- und Verhältnisskalen: 

##### Intervallskala

Maßeinheit und Wahl des Nullpunktes sind willkürlich gewählt.

Beispiele: Grad Celsius, Geburtsjahr als Jahreszahl ("1961"), in der Praxis häufig: subjektive Bewertung auf einer Skala von 1 bis 10.

##### Verhältnisskala (auch Ratioskala)

Es gibt einen invarianten (absoluten, natürlichen) Nullpunkt.

In einer Verhältnisskala lassen sich über alle o.a. Möglichkeiten hinaus auch Aussagen über Verhältnisse zwischen Werten treffen (z.B. "$x_1$ ist doppelt so groß wie $x_2$").

Beispiele: Lebensalter in Jahren, Haushaltsgröße, Köpergröße,
Körpergewicht


## Häufigkeitsverteilungen

\nopagebreak

### Urliste

Die Urliste ist eine ungeordnete Liste aller erfassten Werte.

Für die statistische Erhebung "Anfangsbuchstaben der Vornamen von Teilnehmenden an einer Statistikvorlesung" könnte die Urliste z.B. so aussehen:

```{r, comment=NA, results='asis'}
df <- read.csv("img/1_letters.csv")
xs <- as.character(df$letter)
cat('`', xs, '`')
```

### Geordnete Liste

Die geordnete Liste bringt die Werte der Urliste in eine geeignete Reihenfolge, so dass die unterschiedlichen Werte leicht gezählt werden können:

```{r, comment=NA, results='asis'}
cat('`', sort(xs), '`')
```

### Häufigkeiten

Die absoluten Häufigkeiten erhält man durch einfaches Abzählen der jeweiligen Werte. Für die relativen Häufigkeiten teilt man diese Zahl durch $n$. Kumulierte Häufigkeiten zählen die bisherigen Summen bzw. Anteile zusammen (s. Tabelle \@ref(tab:haeufkum)).

```{r}
rtip("In R lässt sich mit dem Befehl `table()` eine einfache Häufigkeitstabelle aus Rohdaten erstellen.")
```

```{r haeufkum}
df <- data.frame(table(xs))
df$kum <- cumsum(df$Freq)
df$rel <- (df$Freq)/(sum(df$Freq))
df$kumrel <- cumsum(df$rel)
df$rel <- paste0(round(df$rel*100, 1), "\\%")
df$kumrel <- paste0(round(df$kumrel*100, 1), "\\%")
colnames(df) <- c("Buchstabe", "Absolute Häufigkeit $f$", "$f_{kum}$", "Relative Häufigkeit", "$\\%_{kum}$")
tabelle(df, caption="Tabelle mit kumulierten Häufigkeiten", escape=F, align = "lrrrr")
```

### Stabdiagramme

Die so ermittelten Häufigkeiten lassen sich als Stabdiagramm (auch Säulen-, Streifen-, Balkendiagramm, engl. *bar chart*) darstellen (s. Abbildung \@ref(fig:stabdiagramm)).

```{r}
rtip("In R lautet der Standardbefehl zur Erstellung eines Stabdiagramms `barplot()`.")
```

```{r stabdiagramm, fig.cap="Stabdiagramm"}
bar <- data.frame(xs)
bar$xs <- as.factor(xs)
ggplot(bar, aes(x=xs)) +
  geom_bar(fill=goethe_blue) +
  xlab("Anfangsbuchstabe") +
  ylab("Häufigkeit") +
  theme_goethe()
```


### Quantitative Variablen

Das oben beschriebene Verfahren funktioniert gut für qualitative Variablen (und diskrete Variablen mit wenigen unterschiedlichen Werten). Für quantitative Variablen wird ein anderes Verfahren empfohlen.

Zur Veranschaulichung soll diese geordnete Liste von Messwerten des Stammdurchmessers von Schwarzkirschen [Beispieldatensatz `trees` aus @r] dienen:

```{r, comment=NA, results='asis'}
cat('`', format(sort(trees$Girth), decimal.mark = ","), '`')
```

Für solche Verteilungen müssen zuerst Klassen (engl. *bins*) gebildet werden, in denen die Werte dann zusammengefasst werden (s. Tabelle \@ref(tab:haeufklass)).

```{r haeufklass}
df <- data.frame(table(cut(trees$Girth, seq(8,22,2))))
df$kum <- cumsum(df$Freq)
df$rel <- (df$Freq)/(sum(df$Freq))
df$kumrel <- cumsum(df$rel)
df$rel <- paste0(round(df$rel*100, 1), "\\%")
df$kumrel <- paste0(round(df$kumrel*100, 1), "\\%")
df$Var1 <- gsub("\\((\\d+),(\\d+)\\]", "über \\1 bis \\2 Zoll", df$Var1)
colnames(df) <- c("Durchmesser", "Absolute Häufigkeit $f$", "$f_{kum}$", "Relative Häufigkeit", "$\\%_{kum}$")
tabelle(df, escape=F, align = "lrrrr", caption="Häufigkeitstabelle mit klassierten Werten")
```

Für die Wahl der Klassengrenzen gibt es zwei feste Regeln:

- Alle Werte müssen abgedeckt sein.
- Die Klassen dürfen sich nicht überlappen.

Zusätzlich sollten die folgenden Konventionen nach Möglichkeit befolgt werden:

- Klassen sollten gleich große Wertebereiche abdecken.
- Alle Klassen sollten besetzt sein.
- Klassengrenzen sollten möglichst glatte Zahlen sein.
- Aus Gründen der Übersichtlichkeit sollten nicht mehr als 20 Klassen gewählt werden.
- Klassengrenzen sollten "Klumpen" mit ähnlichen Werten nicht trennen.

Die Darstellung erfolgt in so genannten Histogrammen (engl. *histogram*). Abbildung \@ref(fig:histogramm) enthält ein Beispiel für ein Histogramm.

```{r}
rtip("In R können Histogramme mit `hist()` erstellt werden.")
```

```{r histogramm, fig.cap="Histogramm"}
ggplot(data=trees, aes(x=Girth)) +
  geom_histogram(breaks=seq(8,22,2), closed='right', fill=goethe_blue) +
  scale_x_continuous(breaks = seq(8,22,2)) +
  scale_y_continuous(breaks = seq(0,12,3)) +
  xlab("Stammdurchmesser in Zoll") +
  ylab("Häufigkeit") +
  theme_goethe()
```

### Polygone

Statt ausgefüllten Flächen wie im Histogramm lassen sich für die Häufigkeiten auch Punkte setzen, die dann mit Linien verbunden werden. So entsteht ein Häufigkeitspolygon (s. Abbildung \@ref(fig:poly)).

```{r poly, fig.cap="Polygonzug"}
ggplot(data=trees, aes(x=Girth)) +
  geom_freqpoly(breaks=seq(8,22,2), closed='right', color=goethe_blue) +
  scale_x_continuous(breaks = seq(8,22,2)) +
  scale_y_continuous(breaks = seq(0,12,3)) +
  xlab("Stammdurchmesser in Zoll") +
  ylab("Häufigkeit") +
  theme_goethe()
```

### Eigenschaften von Häufigkeitsverteilungen

Polygone von Häufigkeitsverteilungen (insbesondere in geglätteter Form) ergeben Annäherungen an so gennannte Dichtefunktionen (engl. *density functions*). Diese lassen sich mit Attributen (uni-/bimodal, schmal-/breitgipflig, etc.) beschreiben, wie in Abbildung \@ref(fig:shapes) veranschaulicht.

```{r shapes, fig.cap="Merkmale von Verteilungen [aus: @bortz: 42]"}
knitr::include_graphics("img/shapes.png")
```

## Tipps zur Vertiefung {-}

### Grundbegriffe

- YouTube-Kanal "Kurzes Tutorium Statistik": [Statistische Grundbegriffe](https://www.youtube.com/watch?v=bJsBcLjke3Q)
- Kapitel 1.1 in @bortz
- Kapitel 1.1 in @benninghaus
- Kapitel 2.1 in @bahrenberg
- *Englisch:* Kapitel 1 in @burt

### Stichproben

- Kapitel 6.1 in @bortz
- Kapitel 2.5 in @delange
- Kapitel 2.3 in @bahrenberg
- *Englisch:* Kapitel 1 in @burt

### Skalenniveaus

- Kapitel 1.2 in @bortz
- Kapitel 2.5 in @delange
- Kapitel 2.1 in @benninghaus
- Kapitel 2.2 in @bahrenberg
- YouTube-Kanal "Kurzes Tutorium Statistik": [Skalenniveaus](https://www.youtube.com/watch?v=TV4tTtW4UBU)
- *Englisch:* Kapitel 1.3 in @burt

### Häufigkeiten und Diagramme

- YouTube-Kanal "Kurzes Tutorium Statistik": [Stabdiagramme und Histogramme](https://www.youtube.com/watch?v=LkOBRWXnTRQ)
- Kapitel 3.1 und 3.2 in @bortz
- Kapitel 2.5 in @delange
- Kapitel 1.2 in @benninghaus
- Kapitel 4.1 in @bahrenberg
- *Englisch:* Kapitel 2.1 in @burt

<!--chapter:end:01_Datenerhebung_und_Haeufigkeiten.Rmd-->

## Übungsaufgaben {-}

`r naechste("aufgabe", T)`

Teilen Sie in Ihrer Kleingruppe folgende Begriffe untereinander auf:

- Variable
- Kennwert
- Wert
- Grundgesamtheit
- Stichprobe
- Untersuchungselement

Gehen Sie nun für jeden Begriff wie folgt vor:

1. Erklären Sie der Reihe nach "Ihren" Begriff den anderen Gruppenmitgliedern, gerne auch mit Beispielen.
2. Die anderen Gruppenmitglieder nehmen die Rolle von unwissenden Dritten ein und stellen bei Bedarf Nachfragen.
2. Die anderen Gruppenmitglieder geben direkt danach Feedback auf die Erklärung: 
   - Was fanden Sie gut erklärt?
   - Was fanden Sie unverständlich?
   - Was hat Ihnen gefehlt?


`r naechste("aufgabe")`

Finden Sie als Gruppe jeweils zwei Beispiele für:

- systematische Zufallsstichproben
- geschichtete Zufallsstichproben
- Klumpenstichproben

`r naechste("aufgabe")`

Bestimmen Sie das Skalenniveau der folgenden Variablen. Kennzeichnen Sie darüber hinaus, ob die Variable qualitativ, diskret oder stetig ist.

a) Lebensalter in Jahren
a) Regenmenge in mm
a) Güteklasse
a) Passagieraufkommen
a) Baujahr
a) Geschwindigkeit in km/h
a) Sozialstatus (Unter-, Mittel und Oberschicht)
a) Temperatur in °F
a) Fläche eines Bundeslands in km²
a) Temperatur in K
a) Einwohnerzahl
a) Pegelstand
a) Staatsangehörigkeit
a) Interesse an Statistik (gering bis hoch)
a) Klausurnote
a) Bodentyp
a) Entfernung zum Stadtzentrum in km
a) Körpergröße
a) Kleidergröße (S bis XXL)
a) Monatliches Nettoeinkommen

`r naechste("aufgabe")`

Folgende Werte seien erfasst über die Lebensdauer von Klimaanlagen in Stunden [Beispieldatensatz `aircondit7` aus @r]:  

```
14 23 15 139 13 39 188 22 50 3 36 46 30 5 102 5 88 22 197 72 210 97 79 44
```

a) Erstellen Sie eine Häufigkeitstabelle. Welche Klassen wählen Sie und warum?
a) Zeichnen Sie ein Histogramm.
a) Beschreiben Sie die Verteilung.

`r naechste("aufgabe")`

Sind die folgenden Aussagen wahr oder unwahr?

a) Die Auswahl z. B. jedes 100. Merkmalsträgers nennt man „systematische Stichprobe“.
a) Eine Stichprobe kann eine Grundgesamtheit niemals völlig richtig repräsentieren, es gibt immer einen Zufallsfehler.
a) Die Größe der Stichprobe wird auch mit $N$ bezeichnet.
a) Klassengrenzen müssen so gewählt werden, dass alle Werte abgedeckt sind.
a) Je stärker die Werte der Variablen streuen, desto kleiner sollte die Stichprobe sein.
a) Variablen auf der Verhältnisskala sind immer metrisch und stetig.
a) Verhältnisskala und Intervallskala unterscheiden sich durch den natürlichen Nullpunkt.
a) Intervallskalierte Daten können immer auf die Nominalskala transformiert werden.
a) Ordinalskalierte Daten können immer auf die Intervallskala transformiert werden.
a) Eine stetige Variable ist nicht zwingend auch metrisch.
a) Im Gegensatz zu nominalskalierten Variablen lassen sich Werte von ordinalskalierten Variablen in eine sinnvolle Reihenfolge bringen.
a) Die relative Häufigkeit eines Werts ist nie größer als 100%.
a) Verfahren der deskriptiven Statistik sind immer auch univariat.
a) Klassengrenzen dürfen sich in Ausnahmefällen überlappen.
a) $x_3$ ist immer kleiner als $x_4$.
a) Variablen auf der Verhältnisskala haben einen natürlichen Nullpunkt.
a) Die absolute Häufigkeit eines Werts ist immer eine positive ganze Zahl.
a) Wenn man die Urliste ordnet, erhält man die geordnete Liste.

<!--chapter:end:01_Aufgaben.Rmd-->

# Maßzahlen

### Lernziele dieser Sitzung {-}

Sie können...

- die wichtigsten Lagemaße von Stichproben bestimmen.
- die wichtigsten Streumaße von Stichproben bestimmen.
- Boxplots interpretieren.

### Lehrvideos (Sommersemester 2020) {-}

- [2a) Lagemaße](https://video01.uni-frankfurt.de/Mediasite/Play/bbb30f8025cf48e99a48700b0600e1e11d)
- [2b) Streumaße](https://video01.uni-frankfurt.de/Mediasite/Play/cfdb254c058f44228e7b026f36986cc31d)
- [2c) Klassierte Verteilungen](https://video01.uni-frankfurt.de/Mediasite/Play/d115769da4ee4e25a9062a9b2e2e11c41d)
  - In diesem Video ist mir ein Fehler unterlaufen: Bei Minute 6:30 muss das arithmetische Mittel $\bar{x}\approx4{,}59$ betragen. Daraus ergibt sich ein Folgefehler: Die Varianz müsste den Wert $s^2\approx14{,}56$ haben.

## Einleitende Bemerkungen

Die im Folgenden besprochenen Maßzahlen (oder Kennzahlen, Parameter) verdichten (oder aggregieren) Häufigkeitsverteilungen einer Variable. Durch diese Parameter kann das Charakteristische einer Verteilung schnell erfasst und vergleichbar gemacht werden. Die Verdichtung auf Maßzahlen geht jedoch immer auch mit Informationsverlust einher.

Die Möglichkeit der Angabe statistischer Maßzahlen ist abhängig vom Skalenniveau der Daten, wie der Überblick in Tabelle \@ref(tab:mass) zeigt.

```{r mass}
th <- c(
  "Parameter", "Typ", "Mindestes Skalenniveau", "Formel"
)
td <- c(
  "Modalwert", "Lagemaß", "nominal", "\\medskip$\\mathit{Mo}$",
  "Median", "Lagemaß", "ordinal", "\\medskip$\\def\\arraystretch{1.2} \\mathit{Md} = \\Bigg\\{\\begin{array}{@{}c@{}}\\frac{x_{(\\frac{n}{2})}+x_{(\\frac{n}{2}+1)}}{2} \\quad \\textrm{falls }n \\textrm{ gerade}\\\\[6pt] x_{(\\frac{n+1}{2})}\\quad \\textrm{falls }n \\textrm{ ungerade}\\end{array}$",
  "Arithmetisches Mittel", "Lagemaß", "metrisch", "\\medskip$\\bar{x}=\\frac{\\sum\\limits_{i=1}^{n}x _{i}}{n}$",
  "Spannweite", "Streumaß", "ordinal", "\\medskip$R=x_{(n)}-x_{(1)}$",
  "Quartilsabstand", "Streumaß", "ordinal", "\\medskip$\\mathit{IQR}=Q_3-Q_1$",
  "Varianz", "Streumaß", "metrisch", "\\medskip$s^2=\\frac{\\sum\\limits_{i=1}^{n}(x_{i}-\\bar{x})^2}{n-1}$",
  "Standardabweichung", "Streumaß", "metrisch", "\\medskip$s=\\sqrt{s^2}$"
)
table <- data.frame(t(matrix(td, nrow=length(th))))
colnames(table) <- th
tabelle(table, escape=F, caption="Die wichtigsten Maßzahlen")
```

### Beispielverteilung

Alle Berechnungen von Maßzahlen werden am folgenden Beispiel illustriert: Für die 14 Gemeinden im Landkreis Rothenberge wurde die jeweilige Anzahl an Gaststätten erhoben. Die Zählung ergab die Wertereihe in Tabelle \@ref(tab:werte).

```{r werte}
xs <- c(4, 1, 4, 1, 5, 5, 0, 1, 8, 5, 1, 25, 3, 3)

matrix(xs, nrow = 1, dimnames = list(c(), sprintf("$x_{%s}$", 1:14)))%>% as_tibble %>%
  tabelle(escape=F, caption="Beispielverteilung")
```


## Lagemaße

Lagemaße (auch Maße der Zentraltendenz, Lokalisationsparameter, Mittelwerte, engl. *measures of central tendency*) bezeichnen alle statistischen Maßzahlen, die eine Verteilung repräsentieren, indem sie die Lage der mittleren oder häufigsten Variablenwerte angeben.

Im Falle einer unimodalen, perfekt symmetrischen Verteilung (z.&nbsp;B. Glockenform) haben alle drei Lageparameter den gleichen Wert. Je weiter Verteilungen von dieser Form abweichen -- durch Mehrgipfligkeit oder Asymmetrie -- desto unpräziser ist die Beschreibung der Verteilung durch einen einzigen Parameter.

### Median

Der Median (engl. *median*) einer Verteilung ist der Wert, der größer als genau 50% aller Werte ist.

Da dies eine Größer-kleiner-Relation der Werte voraussetzt, kann der Median nur für ordinale und metrische Skalenniveaus angegeben werden.

Im Folgenden wird die (einfachere) Bestimmung des Medians nach @bortz verwendet. @benninghaus beschreibt ein anderes Verfahren, welches zu anderen Ergebnissen kommen kann.

Um den Median zu bestimmen, wird zunächst eine geordnete Liste angefertigt, indem die Werte aufsteigend sortiert werden. Diese sortierten Werte werden mit $x_{(1)}, x_{(2)}, x_{(3)}, ..., x_{(n)}$ bezeichnet (also mit Klammern). Für unsere Beispielverteilung ergibt sich Tabelle \@ref(tab:sort).

```{r sort}
matrix(sort(xs), nrow = 1, dimnames = list(c(), sprintf("$x_{(%s)}$", 1:14)))%>% as_tibble %>%
  tabelle(escape=F, caption="Sortierte Wertereihe")
```

Bei einer ungeraden Stichprobengröße $n$ teilt der $(\frac{n+1}{2})$-te Wert (also der Wert genau in der Mitte) die Stichprobe in zwei Hälften, weshalb gilt:

\[
  \mathit{Md} = x_{(\frac{n+1}{2})} \quad \text{falls }n\text{ ungerade.}
  (\#eq:med1)
\]

Bei geradem $n$ entstehen zwei gleich große Hälften der Stichprobe: $x_{(1)}$ bis $x_{(\frac{n}{2})}$ einerseits, und $x_{(\frac{n}{2}+1)}$ bis $x_{(n)}$ andererseits. Der Durchschnitt zwischen $x_{(\frac{n}{2})}$ und $x_{(\frac{n}{2}+1)}$ teilt die Stichprobe in zwei Hälften. Es gilt:

\[
  \mathit{Md} = \frac{x_{(\frac{n}{2})} + x_{(\frac{n}{2}+1)}}{2} \quad \text{falls } n \text{ gerade.}
  (\#eq:med2)
\]

In unserem Beispiel ist $n=14$ und damit gerade. Der Median errechnet also nach Formel \@ref(eq:med2) wie folgt:

\[
  \begin{aligned}
    \mathit{Md} & = \frac{x_{(7)} + x_{(8)}}{2} \\[4pt]
                & = \frac{3 + 4}{2} \\[4pt]
                & = 3{,}5
  \end{aligned}
\]

```{r}
rtip("In R gibt die Funktion `median()` den Median einer Verteilung aus.")
```

### Modalwert

Der Modalwert $\mathit{Mo}$ (auch Modus, engl. *mode*) gibt den häufigsten Wert oder die häufigsten Werte einer Verteilung an.

Der Modalwert kann so auch (als einziger Mittelwert) für nominalskalierte Variablen angegeben werden.

Bei ordinalen und metrischen Skalenniveaus sind folgende Besonderheiten zu beachten:

- Wird der Modus einer Verteilung durch unmittelbar benachbarte Werte gebildet, wird er als Kombination (bei metrischen Variablen als arithmetisches Mittel) dieser Werte angegeben.
- Bei bimodalen (multimodalen) Verteilungen werden beide (alle) Modalwerte angegeben.

Hierzu müssen die Häufigkeiten der Werte bekannt sein, bzw. bestimmt werden (s. Tabelle \@ref(tab:mod)).

```{r mod}
df <- as.data.frame(table(xs))
colnames(df) <- c("Wert $x_i$", "Häufigkeit $f_i$")
tabelle(df, escape=F, align="r", caption = "Häufigkeiten der Beispielverteilung", full_width=F)
```

Der Modalwert der Beispielverteilung beträgt 1, da der Wert 1 am häufigsten (viermal) vorkommt.

### Arithmetisches Mittel

Das arithmetische Mittel (auch Mittelwert, Durchschnitt, engl. *mean*) ist das gebräuchlichste Lagemaß und Grundlage für viele statistische Verfahren.

Das arithmetische Mittel setzt ein metrisches Skalenniveau voraus.

Die Berechnung des arithmetischen Mittels einer Stichprobe erfolgt durch die Formel:

\[
 \bar{x}=\frac{\sum\limits _{i=1}^{n}x_{i}}{n}
 (\#eq:am)
\]

Für unsere Beispielverteilung ergibt sich durch einsetzen in Formel \@ref(eq:am):
\[
  \begin{aligned}
     \bar{x}&=\frac{\sum\limits _{i=1}^{14}x_{i}}{14} \\[4pt]
            &=\frac{4+1+4+1+5+5+0+1+8+5+1+25+3+3}{14} \\[4pt]
            &=\frac{63}{14}\\[4pt]
            &\approx 4{,}71
  \end{aligned}
\]

```{r}
rtip("Der Befehl für die Ermittlung des arithmetischen Mittels in R lautet `mean()`.")
```

## Streumaße

Streumaße (auch Streuungs-, Variabilitäts-, Dispersionswerte, engl. *measures of variability*) geben Auskunft darüber, wie heterogen die Werte einer Verteilung sind, d.&nbsp;h. wie breit sie gestreut sind. Während Lagemaße den typischen Wert einer Verteilung ermitteln, zeigen Streumaße, wie gut (oder eigentlich: wie schlecht) dieser typische Wert die Verteilung repräsentiert.

### Spannweite

Die Spannweite (engl. *range*) gibt Auskunft darüber, wie groß der Wertebereich ist, der von einer Verteilung abgedeckt wird. Sie wird (für metrische Skalen) als die Differenz vom größten zum kleinsten Wert (also vom letzten zum ersten Wert einer geordneten Werteliste) angegeben:

\[
 R=x_{(n)} - x_{(1)}
 (\#eq:range)
\]

Für unsere Beispielstichprobe ergibt sich (mit Blick auf Tabelle \@ref(tab:sort)):

\nopagebreak

\[
  \begin{aligned}
     R&=x_{(14)} - x_{(1)} \\[4pt]
     &=25-0 \\[4pt]
     &=25
  \end{aligned}
\]

```{r}
rtip("In R gibt die Funktion `range()` die Werte für $x_{(1)}$ und $x_{(n)}$ aus.")
```

### Quartilsabstand

Der Quartilsabstand (auch Interquartilsabstand, engl. *interquartile range, IQR*) gibt die Größe des Wertebereichs der mittleren 50% einer Verteilung an.

Genau so wie der Median eine Messwertreihe in zwei gleich große Hälften "schneidet", schneiden die Quartile die Werte in Viertel. Dabei liegt der so genannte untere Angelpunkt $Q_1$ genau über 25% der Werte, $Q_2$ ist identisch mit dem Median und der obere Angelpunkt $Q_3$ liegt genau über 75% der Werte.

Der Angelpunkt $Q_1$ wird ermittelt, indem der Median für die unteren 50% ($Q_3$: die oberen 50%) der Werte bestimmt wird -- also jener Werte, die theoretisch unterhalb des Medians der Gesamtverteilung liegen.

Dabei folgen wir @bortz und nehmen im Fall eines ungeraden $n$ den Median auf beiden Seiten hinzu.

Die Formel für den Quartilsabstand lautet:

\[
  \begin{aligned}
    \mathit{IQR}=Q_3-Q_1
  \end{aligned}
  (\#eq:iqr)
\]

Der Quartilsabstand ist Ausreißern gegenüber stabiler als die Spannweite, da extreme hohe oder niedrige Wert nicht in die Berechnung einfließen.

In unserem Beispiel (mit $n=14$) ist die untere Hälfte der Verteilung:

```{r lower}
matrix(sort(xs)[1:7], nrow = 1, dimnames = list(c(), sprintf("$x_{(%s)}$", 1:7)))%>% as_tibble %>%
  tabelle(escape=F, full_width=F)
```

$Q_1$ ist der Median dieser Werte, also $x_{(4)}=1$.

Die oberen 7 Werte lauten:

```{r upper}
matrix(sort(xs)[8:14], nrow = 1, dimnames = list(c(), sprintf("$x_{(%s)}$", 8:14)))%>% as_tibble %>%
  tabelle(escape=F, full_width=F)
```

$Q_3$ ist also $x_{(11)} = 5$.

Für den Quartilsabstand ergibt sich durch einsetzen in Formel \@ref(eq:iqr):

\[
  \begin{aligned}
    \mathit{IQR}&=5-1 \\[4pt]
       &=4 \\[4pt]
  \end{aligned}
\]

```{r}
rtip("In R werden die Quartile üblicherweise mit `quantile()` und der Quartilsabstand mit `IQR()` bestimmt.")
```

**Achtung:** Genau wie für den Median gibt es auch für die Ermittlung der Quartile bzw. des Quartilsabstands unterschiedliche Verfahren. Die Ergebnisse dieser R-Funktionen weichen hier deshalb meist leicht vom hier besprochenen Verfahren ab!

### Varianz

Die Varianz einer Messwertreihe (engl. *variance*) kann verstanden werden als der durchschnittliche quadrierte Abstand der Werte zum arithmetischen Mittel.

Die Formel lautet:

\[
  s^2=\frac{\sum\limits_{i=1}^{n}(x_{i}-\bar{x})^2}{n-1}
  (\#eq:var)
\]

Die Quadrierung der Differenz hat dabei einen doppelten Effekt: Zum einen bekommen auch negative Differenzen ein positives Vorzeichen, so dass sich positive und negative Differenzen nicht neutralisieren. Zum anderen werden hierdurch besonders große Abweichungen zum arithmetischen Mittel stärker gewichtet als dies ohne Quadrierung der Fall wäre.

Zudem fällt auf, dass im Gegensatz zur Formel für das arithmetische Mittel im Nenner $n-1$ steht und nicht etwa $n$. Dies hat mit so genannten Freiheitsgraden zu tun, die wir allerdings erst in [Sitzung 5](#freiheitsgrade) genauer kennenlernen.

Für unsere Beispielstichprobe wird die Berechnung für alle einzelnen $(x_i-\bar{x})^2$ schnell aufwendig und unübersichtlich. Deshalb berechnen wir ihre Summe hier mit Hilfe einer Häufigkeitstabelle (s. Tabelle \@ref(tab:freq)). Dabei werden alle distinkten Werte einzeln transformiert und in der letzten Spalte mit ihrer Häufigkeit multipliziert.

```{r freq, results='asis'}
df <- as.data.frame(table(xs))
df$xs <- as.numeric(levels(df$xs))[df$xs]
df$`Abweichung vom arithmetischen Mittel` <- df$xs - round(mean(xs),2)
df$`Quadrat der Abweichung` <- round(df$`Abweichung vom arithmetischen Mittel`^2,2)
df$`Produkt mit Häufigkeit` <- df$Freq*df$`Quadrat der Abweichung`
mem<- df$`Produkt mit Häufigkeit`
colnames(df)<-c("Werte $x_i$", "Häufigk. $f_i$", "$(x_i- \\bar{x})$", "$(x_i- \\bar{x})^2$", "$f_i\\cdot(x_i -\\bar{x})^2$")
tabelle(df, escape = F, caption="Häufigkeitstabelle zur Berechnung der Varianz")
```

Schließlich werden die Werte in Formel \@ref(eq:var) eingesetzt:

\nopagebreak

\[\begin{aligned}
    s^2&=\frac{\sum\limits_{i=1}^{14}(x_{i}-\bar{x})^2}{14-1} \\[4pt]
       &\approx\frac{22{,}18+55{,}04+5{,}84+1+0{,}24+10{,}82+411{,}68}{13} \\[4pt]
       &=\frac{506{,}80}{13}\\[4pt]
       &\approx 38{,}98
\end{aligned}\]

Eine solche Tabelle lässt sich analog auch für die Berechnung von Summen größerer Messwertreihen für das arithmetische Mittel verwenden.

Zudem lässt dieses Verfahren sich auf klassierte Daten anwenden, wenn für $x_i$ der Mittelwert der Klassen eingesetzt wird (womit allerdings Informations- und Präzisionsverlust einhergeht).

```{r}
rtip("In R lautet der Befehl für die Errechnung der Varianz `var()`.")
```

### Standardabweichung

Die Standardabweichung (engl. *standard deviation*) ist das gebräuchlichste Streumaß und spielt eine herausragende Rolle in den allermeisten statistischen Verfahren.

Die Standardabweichung einer Messwertreihe ist definiert als die Quadratwurzel ihrer Varianz:

\[
  \begin{aligned}
    s=\sqrt{s^2}
  \end{aligned}
  (\#eq:sd)
\]

Indem hier die Wurzel gezogen wird, wird in gewisser Weise die Quadrierung der Differenzen für die Varianz wieder "korrigiert". Insbesondere wird die Quadrierung der Maßeinheit wieder aufgehoben -- die Standardabweichung hat also die gleiche Einheit wie die Messreihe selbst.

In unserem Beispiel beträgt die Standardabweichung also:

\[
  \begin{aligned}
    s&\approx\sqrt{38{,}98}
      \approx6{,}24
  \end{aligned}
\]

```{r}
rtip("Die Standardabweichung wird in R mit der Funktion `sd()` berechnet.")
```

## Boxplot

Der Boxplot (auch Box-and-whisker-plot) kombiniert einige der gebräuchlichsten Maßzahlen in einer übersichtlichen Grafik (s. Abbildung \@ref(fig:box)).

```{r box, fig.height=5, fig.width=3, out.width='35%', fig.cap="Boxplot der Beispielverteilung"}
ggplot(data.frame(xs), aes(y=xs)) +
  stat_boxplot(geom = 'errorbar', width=0.5) +
  geom_boxplot(fill = mustard_yellow) +
  scale_x_continuous(limits = c(-0.6,0.4), breaks = NULL) +
  scale_y_continuous(NULL) +
  theme_goethe() +
  theme(axis.line = element_blank(),
        panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))
```

Die Höhe der "Box" definiert sich durch den Quartilsabstand, der mittlere Strich markiert den Median und die "Whisker" markieren den Wertebereich insgesamt -- wobei Ausreißer, deren Abstand zur Box mehr als das 1,5-Fache des Quartilsabstands beträgt, üblicherweise gar nicht oder (wie hier) gesondert mit Punkten markiert werden.

```{r rtip-boxplot}
rtip("In R lässt sich ein Boxplot mit dem Befehl `boxplot()` ausgeben.")
```

## Tipps zur Vertiefung {-}

### Lagemaße

- Kapitel 2.1 in @bortz
- Kapitel 3.3.2 in @delange
- Kapitel 3.3.1 in @benninghaus
- Kapitel 4.2.1 in @bahrenberg
- YouTube-Kanal "Kurzes Tutorium Statistik": [Arithmetisches, harmonisches und geometrisches Mittel](https://www.youtube.com/watch?v=Kx9aHOMVPEg)
- YouTube-Kanal "Kurzes Tutorium Statistik": [Boxplots, Median, Quartile](https://www.youtube.com/watch?v=HsDeAoBOyS4)
- *Englisch:* Kapitel 2.2 in @burt

### Streumaße

- Kapitel 2.2 in @bortz
- Kapitel 3.3.3 in @delange
- Kapitel 3.1.2 in @benninghaus
- Kapitel 4.2.2 in @bahrenberg
- YouTube-Kanal "Kurzes Tutorium Statistik": [Streumaße - Varianz, Standardabweichung, Variationskoeffizient und mehr!](https://www.youtube.com/watch?v=3oZrS3ZWVcA)
- *Englisch:* Kapitel 2.3 in @burt

### Boxplot

- Kapitel 3.4 in @bortz
- Kapitel 5.3.1 in @delange
- YouTube-Kanal "Kurzes Tutorium Statistik": [Boxplots, Median, Quartile](https://www.youtube.com/watch?v=HsDeAoBOyS4)
- *Englisch:* Kapitel 16.3 in @burt

<!--chapter:end:02_Maßzahlen.Rmd-->

## Übungsaufgaben {-}

`r naechste("aufgabe", T)`

Berechnen Sie das arithmetische Mittel für die folgenden Verteilungen:

#### a) 

```{r}
set.seed(4525)
runif(6, 10, 80) %>%
  round() %>%
  cat()
```

#### b)

```{r}
set.seed(4525)
runif(8, -1, 1) %>%
  round(3) %>%
  cat(sep="  ")
```

#### c)

```{r}
set.seed(4525)
runif(10, 600, 1000) %>%
  round(2) %>%
  cat(sep="  ")
```

Tauschen Sie sich danach in der Lerngruppe darüber aus ...

- Was schreiben Sie wann auf?
- Wie geben Sie die Zahlen und Rechenschritte in den Taschenrechner ein?
- Wie überprüfen Sie ggf. Ihr Ergebnis mit Hilfe des Taschenrechners?

`r naechste("aufgabe")`

Wiederholen Sie Aufgabe 1, aber berechnen Sie statt des arithmetischen Mittels die Standardabweichung (und tauschen sich darüber aus).

`r naechste("aufgabe")`

Bei einer Befragung jedes 500. Studierenden im Matrikel einer privaten Hochschule wurden folgende Angaben zur Haushaltsgröße gemacht:

```
1 4 4 2 3 2 3 5 2 7 2 1 1
```

a) Welches Skalenniveau liegt vor? ([Sitzung 1](#skalenniveaus))
b) Berechnen Sie Modalwert,
c) Median und
d) arithmetisches Mittel der Stichprobe.
e) Berechnen Sie außerdem die Spannweite,
f) den Quartilsabstand,
g) die Varianz und
h) die Standardabweichung der Stichprobe.
i) Zeichnen Sie einen Boxplot der Stichprobenverteilung.

`r naechste("aufgabe")`

Eine Messreihe der Körperlänge weiblicher Beutelratten hat folgende Werte in cm erfasst [Beispieldatensatz `fossum` aus @daag]:

```{r}
lectuR::klassieren(DAAG::fossum$totlngth,
                   "cm",
                   seq(75, 97.5, 2.5)) %>%
    select(x, k, f, fkum, prod) %>%
    tabelle(escape=F, col.names = c("$x$", "$k_i$", "$f_i$", "$f_{kum}$", "$f_i \\cdot k_i$"))
```

a) Wie groß ist der Quartilsabstand?
b) Bestimmen Sie das arithmetische Mittel der Reihe.
b) Berechnen Sie auch die Varianz und
d) die Standardabweichung.

`r naechste("aufgabe")`

In Wiesbaum soll ein Kulturzentrum entstehen. Zwei leerstehende Industriegebäude -- eine Ziegelei und ein Möbellager -- kommen für eine Umnutzung in Frage. Bei der Entscheidung, welches Gebäude umfunktioniert werden soll, spielt auch eine Rolle, welcher Ort ohnehin schon mehr Fußverkehr aufweist. Für beide Gebäude wurden daher jeweils die Anzahl der Passant\*innen an sechs zufälligen Tagen erfasst:

\[\begin{aligned}
```{r}
set.seed(1616)
ziegelei <- round(rnorm(6,80,10))
moebellager <- round(rnorm(6,70,18))
knitr::asis_output(
  sprintf(
    "\\textrm{Ziegelei}: \\quad & %s\\\\
\\textrm{Möbellager}: \\quad & %s\\\\",
    paste(ziegelei, collapse="\\quad"),
    paste(moebellager, collapse="\\quad")
  )
)
```
\end{aligned}\]

a) Welches Gebäude weist im Durchschnitt die höhere Passant\*innenzahl auf?

b) Vergleichen Sie außerdem die Quartilsabstände der beiden Messreihen.

`r naechste("aufgabe")`

In Australien betrug die durchschnittliche Niederschlagsmenge in den 1970er- und 80er-Jahren ^[Auszug aus dem Datensatz `bomsoi` in @haseloff]:
\nopagebreak

```{r}
tribble(
  ~Jahr, ~`Niederschlag (mm)`,
  1970,	384.52,
  1971,	493.65,
  1972,	364.65,
  1973,	661.32,
  1974,	785.27,
  1975,	603.45,
  1976,	527.75,
  1977,	471.81,
  1978,	525.65,
  1979,	455.64,
  1980,	433.01,
  1981,	535.12,
  1982,	421.36,
  1983,	499.29,
  1984,	555.21,
  1985,	398.88,
  1986,	391.96,
  1987,	453.41,
  1988,	459.84,
  1989,	483.78
) %>%
  tabelle(full_width = F)
```

a) Welches Skalenniveau liegt vor?  ([Sitzung&nbsp;1](#skalenniveaus))
b) Legen Sie eine klassierte Häufigkeitstabelle an. Begründen Sie die Wahl der Klassen. ([Sitzung&nbsp;1](#quantitative-variablen-1))
c) Was ist der Modalwert der klassierten Verteilung?
d) Wie groß ist der Quartilsabstand?
e) Bestimmen Sie das arithmetische Mittel der klassierten Verteilung.
f) Berechnen Sie die Standardabweichung.
g) Zeichnen Sie einen Boxplot für die Verteilung.

<!--chapter:end:02_Aufgaben.Rmd-->

# `r symbol_header("z")`-Werte und Normalverteilung {#z-werte-und-normalverteilung}

### Lernziele dieser Sitzung {-}

Sie können...

- $z$-Werte ermitteln.
- Merkmale der Normalverteilung wiedergeben.
- anhand einer normalverteilten Dichtefunktion...
  - Wahrscheinlichkeiten errechnen.
  - Perzentile errechnen.

### Lehrvideos (Sommersemster 2020) {-}

- [3a) $z$-Transformation](https://video01.uni-frankfurt.de/Mediasite/Play/8c755eed883b4ea0924481da818b742f1d) 
- [3b) Normalverteilung](https://video01.uni-frankfurt.de/Mediasite/Play/26e839cc0d8d43d2a74c2c03b76aa6421d) 
- [3c) Quantile der Normalverteilung](https://video01.uni-frankfurt.de/Mediasite/Play/902e68deb21045a79473a249303558d11d)


## Variationskoeffizient

Die Berechnung von Maßzahlen ([Sitzung&nbsp;2](#maßzahlen)) vereinfacht es uns, auch große Verteilungen miteinander zu vergleichen. Voraussetzung dafür ist jedoch, dass die Kennwerte (wie arithmetisches Mittel, Standardabweichung) in derselben Maßeinheit (kg, cm, °C, etc.) vorliegen und einen vergleichbaren Maßstab haben.

Eine Möglichkeit, unabhängig hiervon eine Aussage über die *relative* Streuung zu treffen, ist der Variationskoeffizient (engl. *coefficient of variation*) $v$. Er ist definiert als das (prozentuale) Verhältnis von Standardabweichung zu Mittelwert:

\[\begin{aligned}
v=\frac{s}{|\bar{x}|}\cdot 100\%
\end{aligned}
(\#eq:cv)
\]

Zur Illustration: An zufälligen Tagen hat die Wetterstation auf dem Feldberg folgende Luftdruckwerte gemessen (in&nbsp;hPa):

```{r}
xs <- c(1007.1, 1003.4, 990.7, 994.2, 1000.9, 993, 1016, 983.9, 1007.4, 
997.8, 997.9, 1000.2)
cat(format(xs, nsmall=1), sep="  ", fill=T)
```

Mit den bekannten Methoden ([Sitzung&nbsp;2](#maßzahlen)) können wir das arithmetische Mittel $\bar{x}\approx 999,37$ und die Standardabweichung $s\approx8,56$ der Stichprobe bestimmen. Durch einsetzen dieser Werte in Formel \@ref(eq:cv) ergibt sich:

\[\begin{aligned}
v&\approx\frac{8{,}56}{999{,}37}\cdot 100\%\\[4pt]
 &\approx0{,}86\%
\end{aligned}
\]

Da die Standardabweichung im Vergleich zu den absoluten Werten sehr klein ist, ist der Variationskoeffizient hier sehr klein.

Ein Problem ergibt sich, wenn der Mittelwert einer Verteilung nahe Null liegt (z.&nbsp;B. wenn die Reihe auch negative Messwerte enthält). Der Variationskoeffizient wird in diesem Fall sehr groß und verliert stark an Aussagekraft.

## `r symbol_header("z")`-Transformation {#z-transformation}

Ein weiterer Ansatz, Verteilungsmuster vergleichbar zu machen, ist die $z$-Transformation (auch Standardisierung, engl. *standardization*).

Für jeden der Messwerte lässt sich ein entsprechender $z$-Wert mit dieser Formel errechnen:

\[
z=\frac{x-\bar{x}}{s}
(\#eq:z)
\]

Der $z$-Wert eines Werts $x$ ist also der Abstand des Werts zum arithmetischen Mittel $\bar{x}$ der Verteilung, ausgedrückt im Verhältnis zu ihrer Standardabweichung $s$.

Die einzelnen $z$-Werte für die Luftdruckmessungen ergeben sich wie in Tabelle \@ref(tab:trans) dargestellt.

```{r trans, cache=T}
df <- data.frame(xs)
df$b <- paste0("$z_{", row(df), "}=\\frac{", df$xs ,"-999,37}{8,56}$\\medskip")
df$z <- format(round((df$xs-999.37)/8.56,2), nsmall=2)
df$xs <- format(xs, nsmall=1)
colnames(df) <- c("$x_i$", "Berechnung", "$z_i$")
tabelle(df, full_width = F, escape = F, align = "rcr", caption = "$z$-Transformation")
```

Eine so $z$-transformierte Verteilung hat *immer* automatisch das arithmetische Mittel $\bar{z}=0$ und die Standardabweichung $s_z=1$. Außerdem haben $z$-Werte keine Maßeinheit. So kann jede Verteilung "standardisiert" und systematisch vergleichbar gemacht werden.

```{r}
rtip("In R kann eine empirische Verteilung mit dem Behfehl `scale()` $z$-transformiert werden.")
```

Andersherum lassen sich $z$-Werte folgendermaßen wieder umwandeln in $x$-Werte:

\[
  x=s\cdot z+\bar{x}
  (\#eq:zrev)
\]

## Normalverteilung

```{r norms, fig.pos="b", cache=T, fig.cap="Dichtefunktionen verschiedener Normalverteilungen"}

mode <- optimize(function(x){dnorm(x, mean=12,sd=2)}, c(-7,22), maximum = T)
ggplot(data = data.frame(x = c(-7,22)), aes(x)) +
    stat_function(fun = function(x){dnorm(x, mean=0,sd=3)},
                  n = 250,
                  color = light_green) +
    stat_function(fun = function(x){dnorm(x, mean=6,sd=2)},
                  n = 250,
                  color = goethe_blue) +
    stat_function(fun = function(x){dnorm(x, mean=10,sd=8)},
                  n = 250,
                  color = magenta) +
    scale_y_continuous( expand=c(0,0), limits = c(0,mode$objective*1.05)) +
    scale_x_continuous(expand=c(0,0)) +
    annotate(geom="blank", x=-4, y=mode$objective*1.05) +
    annotate(geom="text", x=-2, y=0.15, label="a ~ N(0,9)", color = light_green) +
    annotate(geom="text", x=11, y=0.15, label="b ~ N(6,4)", color = goethe_blue) +
    annotate(geom="text", x=17, y=0.06, label="c ~ N(10,64)", color = magenta) +
    xlab(NULL) +
    ylab(NULL) +
    theme_goethe()
```

Die Normalverteilung (auch: Gaußverteilung, engl. *normal distribution*) ist unimodal und symmetrisch. Die Normalverteilung ist eine theoretische Verteilung, für die bekannt ist, mit welcher Wahrscheinlichkeit bestimmte Werte unter- und überschritten werden bzw. mit welcher Wahrscheinlichkeit Werte in einem bestimmten Intervall liegen.

Die Dichtefunktion einer Normalverteilung hat eine markante Glockenform (s. Abbildungen \@ref(fig:norms) und \@ref(fig:stdnorm)). Die beiden Wendepunkte einer Normalverteilung (also dort, wo die Steigung zwischen zu- und abnehmend wechselt; oder mathematisch: wo die Ableitung der Dichtefunktion einen Extremwert annimmt) sind je eine Standardabweichung vom Mittelwert entfernt.

Die Dichtefunktion nimmt nie den Wert Null an -- Extremwerte sind also sehr selten bzw. unwahrscheinlich, aber nie unmöglich. Perfekte Normalverteilungen kommen in empirischen Beobachtungen nicht vor, sondern nur Annäherungen.

Da es sich um eine *theoretische* Verteilung handelt, ist die Normalverteilung zunächst insbesondere in Bezug auf die Grundgesamtheit interessant. Im Kontext der Grundgesamtheit wird das arithmetische Mittel mit $\mu$ ("Mü") und die Standardabweichung mit $\sigma$ ("Sigma") bezeichnet (s. Tabelle \@ref(tab:param)).

```{r param, cache=T}
read.table(sep="|", header=T, text = "
Parameter             | Stichprobe | Grundgesamtheit
Anzahl Elemente       | $n$        | $N$
Arithmetisches Mittel | $\\bar{x}$  | $\\mu$
Varianz               | $s^2$      | $\\sigma^2$
Standardabweichung    | $s$        | $\\sigma$
") %>% 
  tabelle(escape = F, full_width = F, caption="Bezeichnung von Parametern in Stichprobe und Grundgesamtheit")
```

Jede Normalverteilung lässt sich anhand von zwei Parametern beschreiben: ihr arithmetisches Mittel und ihre Standardabweichung. Normalverteilte Grundgesamtheiten werden so notiert:

\nopagebreak
\[\begin{aligned}
x \sim N(\mu,\enspace\sigma^2)
\end{aligned}
(\#eq:norm)\]

Der Mittelwert $\mu$ bestimmt die Lage der Kurve auf der x-Achse, die Varianz $\sigma^2$ bestimmt die "Stauchung" der Kurve (je größer desto flacher). Es gibt also unendlich viele verschiedene Normalverteilungen (s. Abbildung \@ref(fig:norms)).

## Standardnormalverteilung

Die Standardnormalverteilung (engl. *standard normal distribution*) ist sozusagen das Grundmuster aller Normalverteilungen. Sie hat den Mittelwert $\mu=0$ und die Standardabweichung $\sigma=1$ (s. Abbildung \@ref(fig:stdnorm)).

Alle Normalverteilungen lassen sich durch die $z$-Transformation auf die Standardnormalverteilung standardisieren.

```{r stdnorm, cache=T, fig.cap="Dichtefunktion der Standardnormalverteilung"}
ggplot(data = data.frame(x = c(-3,3)), aes(x)) +
    stat_function(fun = dnorm,
                  n = 250,
                  color = goethe_blue) +
    scale_y_continuous(breaks = seq(0,0.4,0.1), limits=c(0, dnorm(0)*1.05), expand=c(0,0)) +
    scale_x_continuous(expand=c(0,0)) +
    annotate(geom="blank", x=0, y=dnorm(0)*1.05) +
    xlab("x") +
  ylab(NULL) +
    theme_goethe()
```

## Crash-Kurs Wahrscheinlichkeitsrechnung

Ein Zufallsexperiment ist ein beliebig oft wiederholbarer, nach bestimmten Vorschriften ausgeführter Versuch, dessen Ergebnis zufallsbedingt ist (d. h. nicht eindeutig voraussagbar ist).

Jedem zufälligen Ereignis $A$ ist eine bestimmte "Wahrscheinlichkeit des Auftretens" (engl. *probability*) $P(A)$ zugeordnet, die der Ungleichung $0 \leq P(A) \leq 1$ genügt (d. h. zwischen 0 und 1 liegt).

Die Wahrscheinlichkeit eines sicheren Ergebnisses A ist $P(A) = 1$. Hingegen würde $P(B) = 0$ bedeuten, dass das Ereignis B nicht eintreten kann. Die Summe der Wahrscheinlichkeiten aller möglichen Ereignisse beträgt 1.

Der *Additionssatz* besagt: Die Wahrscheinlichkeit, dass eins von verschiedenen zufälligen, sich gegenseitig ausschließenden Ereignissen eintritt, ist die Summe ihrer Wahrscheinlichkeiten.

Der *Multiplikationssatz* besagt: Die Wahrscheinlichkeit für das Eintreten zweier voneinander unabhängiger Ereignisse ist gleich dem Produkt der Einzelwahrscheinlichkeiten.

## Wahrscheinlichkeitsdichtefunktionen

Die Fläche unter einer Wahrscheinlichkeitsdichtefunktion (engl. *probability density function*) beträgt genau 1.

Das Perzentil $x_p$ (engl. *percentile*) ist definiert als der Wert, unter dem der Anteil $p$ der Verteilung liegt. In [Sitzung&nbsp;2](#Maßzahlen) haben wir also bereits den Median $x_{50\%}$ sowie die Angelpunkte $Q_1=x_{25\%}$ und $Q_3=x_{75\%}$ kennengelernt.

Die Fläche unter einer Wahrscheinlichkeitsdichtefunktion innerhalb der Limits $-\infty$ und $x_p$ beträgt $p$. Für einen zufälligen Wert $x$ ist die Wahrscheinlichkeit $P(x < x_p) = p$, dass er kleiner als $x_p$ ausfällt.
Für die Standardnormalverteilung finden sich die $p$-Werte für positive $z$ in der [Wertetabelle in der Formelsammlung](#tabelle-z).^[Manchmal wird die Funktion $z_p \rightarrow P(z < z_p)$ für normalverteilte Werte auch mit $\Phi(z)$ bezeichnet [z.&nbsp;B. in @bahrenberg].]

## Wahrscheinlichkeitsrechnung mit Standardnormalverteilung

Für die im Rest dieser Sitzung vorgestellten Verfahren müssen folgende Voraussetzungen gegeben sein:

- Die Grundgesamtheit ist (annähernd) normalverteilt.
- Arithmetisches Mittel $\mu$ und Standardabweichung $\sigma$ der Grundgesamtheit sind bekannt.

Die Verfahren sollen anhand eines Beispiels illustriert werden: Es sei bekannt, dass der Luftdruck auf dem Feldberg annähernd normalverteilt ist, und zwar mit dem arithmetischen Mittel $\mu=1003$ und Varianz $\sigma^2=73$. Graphisch stellt sich die Wahrscheinlichkeitsdichtefunktion wie in Abbildung \@ref(fig:dens) dar.

```{r dens, cache=T, fig.pos='t', fig.cap="Theoretische Wahrscheinlichkeitsdichtefunktion des Luftdrucks"}
ggplot(data.frame(x=c(1003-3*sqrt(73),1003+3*sqrt(73))), aes(x)) +
  stat_function(fun=function(x){dnorm(x,1003,sqrt(73))}, color = goethe_blue) +
  scale_y_continuous(limits=c(0, dnorm(1003,1003,sqrt(73))*1.05), expand=c(0,0)) +
  scale_x_continuous(expand=c(0,0)) +
  xlab("x (Luftdruck in hPa)") +
  ylab(NULL) +
  theme_goethe()
```

Wir können auch (analog zu Formel \@ref(eq:norm)) schreiben:

\[
x \sim N(1003,\enspace73)
\]

Daraus ergibt sich für die Standardabweichung $\sigma$:
\nopagebreak

$$\begin{aligned}
\sigma&=\sqrt{\sigma^2}\\
&=\sqrt{73}\\
&\approx8{,}54
\end{aligned}$$

### Unterschreitungswahrscheinlichkeit{#unter}

Die einfachste Art der Fragestellung ist nun, mit welcher Wahrscheinlichkeit ein bestimmter Wert $x_p$ unterschritten wird.

Nehmen wir an, es sei gefragt, mit welcher Wahrscheinlichkeit zu einem beliebigen Zeitpunkt der Luftdruck weniger als 1015&nbsp;hPa beträgt. Anders gesagt interessiert uns der Anteil der Fläche unter der Verteilung, der zwischen $-\infty$ und $x_p=1015$ liegt (s. Abbildung \@ref(fig:unter)).

```{r unter, fig.pos='H', cache=T, fig.cap="Unterschreitung eines Messwerts"}
mu = 1003
sigma = sqrt(73)
xl = mu-3*sigma
xr = mu+3*sigma
f = function(x){dnorm(x,mu,sigma)}
xp=1015

ggplot(data.frame(x=c(xl, xr)), aes(x)) +
  stat_function(fun=f, xlim=c(xl, xp), geom = "area", fill= light_blue) +
  stat_function(fun=f, color = goethe_blue) +
  geom_vline(xintercept=xp, color= goethe_blue, linetype="dashed") +
  scale_y_continuous(expand=c(0,0), limits=c(0,f(mu)*1.05)) +
  scale_x_continuous(expand=c(0,0)) +
  xlab("x (Luftdruck in hPa)") +
  ylab(NULL) +
  theme_goethe()
```

Um den entsprechenden Wert für $P(x < x_p)$ (also die Wahrscheinlichkeit, dass ein zufälliges $x$ unser Perzentil $x_p$ unterschreitet) in Erfahrung zu bringen, müssen wir die Verteilung zunächst standardisieren. Der Wert $z_p$ ergibt sich aus der Formel für die $z$-Transformation, diesmal jedoch mit $\mu$ statt $\bar{x}$ und $\sigma$ statt $s$, da es sich um die Grundgesamtheit handelt:

\[\begin{aligned}
    z_p &= \frac{x_p-\mu}{\sigma} \\[4pt]
        &\approx \frac{1015-1003}{8{,}54}\\[4pt]
        &\approx 1{,}41
  \end{aligned}
\]

Graphisch ist das standardisierte Perzentil in Abbildung \@ref(fig:z) dargestellt.

```{r z, cache=T, fig.pos='H', fig.cap="Standardnormalverteilung des Luftdrucks"}
ggplot(data.frame(x=c(-3,3)), aes(x)) +
      stat_function(fun = dnorm,
                  xlim =  c(-3,1.41),
                  geom = "area",
                  fill = light_blue) +
    geom_vline(xintercept = 1.41,
               color = goethe_blue,
               linetype = "dashed") +
  stat_function(fun=dnorm, color = goethe_blue) +
  scale_y_continuous(NULL, expand=c(0,0), limits = c(0,dnorm(0)*1.05)) +
  scale_x_continuous("z", expand=c(0,0), breaks=c(-3,-2,-1,0,1.41,3), labels=c(-3,-2,-1,0,1.41,3)) +
  theme_goethe()
```

Die [Wertetabelle für die Standardnormalverteilung](#tabelle-z) gibt für $z$-Werte die Wahrscheinlichkeit ihrer Unterschreitung in ener Normalverteilung an. Diese Wahrscheinlichkeit kann notiert werden als $P(z < z_p)$.

Der Wertetabelle können wir den Wert $P(z < 1{,}41) \approx 0{,}9207$ entnehmen. Die Wahrscheinlichkeit, dass der Luftdruck zu einem zufälligen Zeitpunkt weniger als 1015 hPA beträgt, ist somit 92,07%.

```{r}
rtip("In R lässt sich die Unterschreitungswahrscheinlichkeit eines $z$-Werts mit dem Befehl `pnorm()` ermitteln.")
```

#### Überschreitungswahrscheinlichkeit

Wird nach der Wahrscheinlichkeit der Überschreitung eines Werts gefragt, ist in anderen Worten die Fläche unter der Wahrscheinlichkeitsdichtefunktion zwischen $x_p$ und $\infty$ gemeint. Wir bleiben bei unserem Beispiel $x_p=1015$ (s. Abbildung \@ref(fig:ueber)).


```{r ueber, cache=T, fig.cap="Überschreitung eines Messwerts"}
ggplot(data.frame(x=c(xl, xr)), aes(x)) +
  stat_function(fun=f, xlim=c(xp, xr), geom = "area", fill= light_blue) +
  stat_function(fun=f, color = goethe_blue) +
  geom_vline(xintercept=xp, color= goethe_blue, linetype="dashed") +
  scale_y_continuous(expand=c(0,0), limits=c(0,f(mu)*1.05)) +
  scale_x_continuous(expand=c(0,0)) +
  xlab("x (Luftdruck in hPa)") +
  ylab(NULL) +
  theme_goethe()
```

Hier können wir genauso wie bei der Unterschreitung $z_p=1{,}41$ errechnen.

Jetzt stehen wir zunächst vor dem Problem, dass die $p$-Werte in der Tabelle immer die Wahrscheinlichkeit der Unterschreitung darstellen. Wir wissen jedoch: Die gesamte Fläche unter der Verteilung ist 1, und die Wahrscheinlichkeiten der Unter- und Überschreitung sind komplementär, d.&nbsp;H. einer von beiden Fällen tritt sicher (mit einer Wahrscheinlichkeit von 100%) ein. (Den Sonderfall $x=x_p$ können wir bei stetigen Variablen vernachlässigen.)

Hieraus ergibt sich ganz allgemein:

\[
  \begin{aligned}
    P(x \geq x_p) = 1-P(x<x_p)
  \end{aligned}
  (\#eq:ueber)
\]

Und für unser Beispiel:

\[
  \begin{aligned}
    P(x \geq 1015) &= 1-P(x < 1015) \\
    &\approx1-P(z < 1,41)\\
    &\approx1-0{,}9207\\
    &= 0{,}0793
  \end{aligned}
\]

In 7,93% der Fälle beträgt der Luftdruck also über 1015&nbsp;hPA.

#### Negativer $z$-Wert

Wenn nach der Unterschreitungswahrscheinlichkeit eines unterdurchschnittlichen Werts gefragt ist (z. B. 990 hPA), dann ergibt sich ein negativer Wert für $z_p$:

\begin{equation}
  \begin{aligned}
    z_p &= \frac{x_p-\mu}{\sigma} \\[4pt]
        &= \frac{990-1003}{8{,}54} \\[4pt]
        &\approx -1{,}52
  \end{aligned}
\end{equation}

Die [Wertetabelle](#tabell-z) enthält keine $p$ für negative $z_p$. Da die Standardnormalverteilung jedoch um $z=0$ symmetrisch ist, gilt ganz allgemein:

\[
  \begin{aligned}
    P(z < -z_p) = 1 - P(z < z_p)
  \end{aligned}
  (\#eq:neg)
\]

Für unser Beispiel ergibt sich (mit dem Wert $P(z < 1,52) = 0{,}9357$ aus der Tabelle):

\[
  \begin{aligned}
    P(z < -1,52) &= 1 - P(z < 1,52) \\
    &\approx 1-0{,}9357 \\
    &=0{,}0643
  \end{aligned}
\]

Ein Luftdruck von 990&nbsp;hPa wird also nur in ca. 6,43% der Fälle unterschritten.

```{r}
rtip("Der Befehl `pnorm()` funktioniert auch mit negativen $z$-Werten.")
```

#### Wert in einem Intervall

Nun wollen wir wissen, mit welcher Wahrscheinlichkeit ein zufälliger Meßwert zwischen 1005 und 1015&nbsp;hPa liegt. Graphisch ist dies in Abbildung \@ref(fig:intervall) aufbereitet.

```{r intervall, cache=T, fig.cap="Messwertintervall"}
xu=1005
xo=1015
ggplot(data.frame(x=c(xl, xr)), aes(x)) +
  stat_function(fun=f, xlim=c(xu,xo), geom = "area", fill=light_blue) +
  stat_function(fun=f, color = goethe_blue) +
  geom_vline(xintercept=xu, color=goethe_blue, linetype="dashed") +
  geom_vline(xintercept=xo, color=goethe_blue, linetype="dashed") +
  scale_y_continuous(expand=c(0,0), limits=c(0,f(mu)*1.05)) +
  scale_x_continuous(expand=c(0,0)) +
  xlab("x (Luftdruck in hPa)") +
  ylab(NULL) +
  theme_goethe()
```

Rechnerisch müssen wir also von den (günstigen) Fällen, in denen 1015 hPA unterschritten werden, noch jene (ungünstige) Fälle abziehen, in denen die 1005 hPA *ebenfalls* unterschritten werden.

Ganz allgemein heißt das für die Untergrenze $x_u$ und die Obergrenze $x_o$:

\[\begin{aligned}
    P(x_{u} \leq x < x_{o}) = P(x < x_{o}) - P(x < x_{u})
  \end{aligned}
  (\#eq:intervall)
\]

Für unseren Fall ist $x_u=1005$ und $x_o=1015$. In den [vorherigen Aufgaben](#unter) haben wir $z_o\approx1,41$ bereits ermittelt. Wir müssen aber noch $z_u$ ermitteln:

\[\begin{aligned}
    z_u &= \frac{x_u-\mu}{\sigma} \\[4pt]
        &= \frac{1005-1003}{8{,}54}  \\[4pt]
        &\approx 0{,}23
\end{aligned}\]

Dann können wir die entsprechende Wahrscheinlichkeit berechnen, indem wir wieder die Werte aus der [Wertetabelle](#tabelle-z) einsetzen:

$$
  \begin{aligned}
    P(1005 \leq x < 1015) &= P(x < 1015) - P(x < 1005) \\
    &\approx P(z < 1{,}41) - P(z < 0{,}23) \\
    &\approx 0{,}9207- 0{,}5910  \\
    &= 0{,}3297
  \end{aligned}
  $$

Der Luftdruck liegt also mit einer Wahrscheinlichkeit von 32,97% zwischen 1005 und 1015&nbsp;hPa.

#### Gesuchter Wert bei gegebener Wahrscheinlichkeit

Die Fragerichtung lässt sich umdrehen: Welche Marke wird beim Messen des Luftdrucks nur in 5% der Fälle überschritten?

5% Überschreitungswahrscheinlichkeit entsprechen einer Unterschreitungswahrscheinlichkeit von 95%. Welcher Wert wird also mit 95% Wahrscheinlichkeit unterschritten?

Der Tabelle entnehmen wir, dass einer Unterschreitungswahrscheinlichkeit von 0,95 ein $z$-Wert zwischen 1,64 und 1,65 entspricht. Da es bei dieser Fragestellungen oft darum geht, einen "kritischen" Wert zu nennen, der nur in Ausnahmefällen überschritten wird, nehmen wir hier üblicherweise den extremeren Wert, also $z_{95\%}\approx 1,65$.

Mit der umgekehrten $z$-Transformation erhalten wir:

\[
  \begin{aligned}
    x_{95\%}&=z_{95\%}\cdot \sigma + \mu \\
       &\approx 1{,}65\cdot 8{,}54 + 1003\\
       &\approx 1017{,}10
  \end{aligned}
\]

Die Marke von 1017,10&nbsp;hPa wird also nur in 5% der Fälle überschritten.

```{r}
rtip("Das Perzentil für eine gegebene Unterschreitungswahrscheinlichkeit lässt sich in R mit `qnorm()` bestimmen.")
```

#### Gesuchte Grenzwerte eines Intervalls

Eine übliche Art der Fragestellung ist auch: Zwischen welchen beiden Werten liegen die mittleren 85% der Fälle (s. Abbiddung \@ref(fig:mitte))?

```{r mitte, cache = T, fig.cap="Die mittleren 85\\% der Normalverteilung"}
xu <- qnorm(.925, mu, sigma)
xo <- qnorm(.075, mu, sigma)
ggplot(data.frame(x = c(xl, xr)), aes(x)) +
  stat_function(fun = f, xlim = c(xu,xo), geom = "area", fill = light_blue) +
  stat_function(fun = f, color = goethe_blue) +
  geom_vline(xintercept = xu, color = goethe_blue, linetype = "dashed") +
  geom_vline(xintercept = xo, color = goethe_blue, linetype = "dashed") +
  scale_y_continuous(expand = c(0,0), limits = c(0,f(mu)*1.05)) +
  scale_x_continuous(expand = c(0,0)) +
  xlab("x (Luftdruck in hPa)") +
  ylab(NULL) +
  theme_goethe()
```

Da die Verteilung symmetrisch ist, teilen sich die ungünstigen 15% der Fälle gleichmäßig an den oberen und unteren Rand der Verteilung auf. Die Obergrenze $x_o$ ist also der Wert, der zu 7,5% über- und damit zu 92,5% unterschritten wird.

Der Tabelle entnehmen wir den Wert $z_o=z_{92,5\%}\approx1{,}44$.

Die Untergrenze ist entsprechend der Wert, der in 7,5% der Fälle unterschritten wird.

Der Wert für $z_u=z_{7{,}5\%}$ ist in der Tabelle nicht enthalten. Weil die Verteilung aber symmetrisch ist, wissen wir uns zu helfen:

$$
  \begin{aligned}
    z_u=z_{7{,}5\%}=-z_{92{,}5\%}\approx-1{,}44
  \end{aligned}
  $$

Die absoluten Werte ergeben sich schließlich aus:

$$
  \begin{aligned}
    x_u&=z_u\cdot \sigma + \mu \\
    &\approx-1{,}44 \cdot 8{,}54 + 1003\\
    &\approx990{,}70
  \end{aligned}
$$

Und:

$$
  \begin{aligned}
    x_o&=z_o\cdot \sigma + \mu  \\
    &\approx1{,}44 \cdot 8{,}54 + 1003\\
    & \approx 1015{,}30
  \end{aligned}
$$

Die mittleren 85% der Messwerte liegen also zwischen 990,7 und 1015,3&nbsp;hPa.

## Tipps zur Vertiefung {-}

### Variationskoeffizient

- Kapitel 3.3.4 in @delange
- Kapitel 4.2.2 in @bahrenberg
- YouTube-Kanal "Kurzes Tutorium Statistik": [Streumaße - Varianz, Standardabweichung, Variationskoeffizient und mehr!](https://www.youtube.com/watch?v=3oZrS3ZWVcA)
- *Englisch:* Kapitel 2.3 in @burt

### $z$-Transformation

- Kapitel 2.4 in @bortz
- Kapitel 3.5.2 in @delange
- Kapitel 4.2.2 in @bahrenberg
- Kapitel 3.3.3 in @benninghaus
- YouTube-Kanal "Methodenlehre Mainz": [WT.012.09 Äpfel mit Birnen vergleichen: Die z-Standardisierung](https://www.youtube.com/watch?v=AiucvUlIP8k)
- *Englisch:* Kapitel 6.3 in @burt

### Normalverteilung

- Kapitel 5.4 in @bortz
- Kapitel 7.3.2.2 und 7.3.2.3 in @delange
- Kapitel 5.2.2 in @bahrenberg
- YouTube-Kanal "Mathe by Daniel Jung": [Was ist die Normalverteilung, Gauß-Verteilung, Schaubilder, Übersicht](https://www.youtube.com/watch?v=_f1vgWUiavY)
- *Englisch:* Kapitel 6.3 in @burt

### Wahrscheinlichkeitsdichtefunktion

- Kapitel 5.3 in @bortz
- Kapitel 7.3.2.1 in @delange
- Kapitel 5.2.2 in @bahrenberg
- YouTube-Kanal "Kurzes Tutorium Statistik": [Zufallsvariable, Massenfunktion, Dichtefunktion und Verteilungsfunktion](https://www.youtube.com/watch?v=DoHTsDrzAQk)
- *Englisch:* Kapitel 6.1 in @burt

<!--chapter:end:03_z-Werte_und_Normalverteilung.Rmd-->

## Übungsaufgaben {-}

`r naechste("aufgabe", T) # ex1`

a) Führen Sie eine $z$-Transformation der folgenden Verteilung durch:

    ```{r}
    set.seed(2220)
      rnorm(9, -20, 8) %>%
      round(2) -> ex_3_1_a
      dcat(ex_3_1_a)
    ```

b) Sie kennen das arithmetische Mittel (221,54) und die Varianz (13,02) einer Verteilung. Welche $x$-Werte entsprechen diesen $z$-Werten?

    ```{r}
    set.seed(2220)
    runif(12, -3, 3) %>%
      rlist::list.filter(~ abs(.) <= 3) %>%
      round(2) -> ex_3_1_b
      dcat(ex_3_1_b)
    ```

`r naechste("aufgabe") # ex2`

Gegeben sei eine Normalverteilung beschrieben durch:

\[x \sim N(32{,}2,\enspace19{,}36)\]

a) Mit welcher Wahrscheinlichkeit werden die folgenden Werte unterschritten?

    ```{r}
    set.seed(9444)
    runif(6, 32.2-3*4.4, 32.2+3*4.4) %>%
      round(2) -> ex_3_2_a
      dcat(ex_3_2_a)
    ```

b) Welche Werte werden jeweils mit der folgenden Wahrscheinlichkeit über(!)schritten?

    ```{r}
    c(1.5, 2.5, 5, 13, 50,  90, 99, 99.5) %>%
      `/`(100) -> ex_3_2_b

    ex_3_2_b %>%
      map(~ format(.x * 100)) %>%
      sprintf("%s%%", .) %>%
      dcat()
    ```

c) In welchem Bereich liegen die mittleren 95% der Werte?

d) Wie wahrscheinlich ist es, dass ein Wert zwischen 30 und 40 liegt?

`r naechste("aufgabe") # 3`

Deiche werden durch Wasserdruck bei Hochwasser belastet und dadurch beschädigt. Bei einem 12&nbsp;m hohen Deich gilt als kritische Marke ein Wasserstand von 10&nbsp;m. Die jährlichen Höchstwasserstände des Flusses sind normalverteilt mit einem Mittelwert von 9,01&nbsp;m und einer Standardabweichung von 2,23&nbsp;m.

In den folgenden Teilaufgaben beantworten wir Schritt für Schritt die Frage, wie wahrscheinlich es (für ein beliebiges Jahr) ist, dass der Deich das jährliche Hochwasser ohne Beschädigung übersteht, d.&nbsp;h. dass ein Höchstwasserstand von 10&nbsp;m oder weniger eintritt.

a) Zeichnen Sie die Wahrscheinlichkeitsdichtefunktion (ganz grob, ohne $y$-Achse).
a) Markieren Sie den kritischen Wert 10&nbsp;m.
a) Welchem $z$-Wert entspricht die kritische Marke von 10&nbsp;?
b) Mit welcher Wahrscheinlichkeit bleibt der Deich in einem gegebenen Jahr unbeschädigt (Höchstwasserstand unter der kritischen Marke von 10&nbsp;m)?

`r naechste("aufgabe") # 4`

Wir bleiben beim Deich aus Aufgabe 3.

a) Mit welcher Wahrscheinlichkeit wird der Deich beschädigt (Wasserstand über 10&nbsp;m)?
a) Mit welcher Wahrscheinlichkeit wird der Deich nicht nur beschädigt, sondern läuft über (Wasserstand über 12&nbsp;m)?
a) Mit welcher Wahrscheinlichkeit wird der Deich beschädigt, läuft aber nicht über (Wasserstand zwischen 10 und 12&nbsp;m)?
a) In welchen Grenzen liegen die mittleren 80% der Hochwasserstände?

`r naechste("aufgabe") # 5`

Es ist ein neuer Deich zu bauen, der so sicher sein soll, dass er nur alle 200 Jahre vom Hochwasser übertreten wird. 

a) Welcher Wahrscheinlichkeitswert $p=P(x < x_p)$ ist anzuwenden, d.&nbsp;h. wie wahrscheinlich ist die *Unterschreitung* eines "zweihundertjährigen Hochwassers"?
b) Mit welchem $z$-Wert korrespondiert der gesuchte Wert $x_p$?
c) Wie hoch muss dieser Deich sein? (Welcher Wert $x_p$ entspricht diesem $z_p$?)

`r naechste("aufgabe") # 6`

Die jährlichen Niederschlagsmengen in Mittelstedt betragen im Durchschnitt 400 mm bei annähernder Normalverteilung und einer Standardabweichung von 100 mm. 

a) Wie groß ist die Wahrscheinlichkeit, dass mehr als 500 mm Niederschlag fallen?
b) Wie oft pro hundert Jahre kann mit weniger als 200 mm Niederschlag gerechnet werden?
c) Mit welcher Wahrscheinlichkeit fallen zwischen 200 und 550 mm Niederschlag?
d) Welche Niederschlagsmenge wird wahrscheinlich in nur 2 von 100 Jahren übertroffen?
e) In welchen Grenzen liegen die mittleren 75% der jährlichen Niederschlagsmenge?

`r naechste("aufgabe") # 7`

Errechnen Sie für die Verteilungen in [Aufgabe 5 aus Sitzung 2](#aufgabe-2-5) jeweils den Variationskoeffizienten.

<!--chapter:end:03_Aufgaben.Rmd-->

# Schätzstatistik

### Lernziele dieser Sitzung {-}

Sie können...

- eine Punktschätzung für $\mu$ und $\sigma$ durchführen.
- den Standardfehler der Stichprobenverteilung von $\bar{x}$ bestimmen.
- eine Intervallschätzung für $\mu$ durchführen.

### Lehrvideos (Sommersester 2020) {-}

- [4a) Alphafehler](https://video01.uni-frankfurt.de/Mediasite/Play/7f5b3002871a4b18859db90d937e5f8a1d)
  - In diesem Video gibt es einen Fehler: In Schritt c) der Übungsaufgabe setze ich den falschen Wert für $\mu$ ein. Die Werte müssten stattdessen $x_{(1-\alpha/2)}=27{,}84$ und $x_{\alpha/2}=20{,}16$ betragen.
- [4b) Stichprobenverteilung](https://video01.uni-frankfurt.de/Mediasite/Play/393be1f574c643f9a045a6b4cc60a4511d)
- [4c) Schätzungen](https://video01.uni-frankfurt.de/Mediasite/Play/ace60129a0c94894a66349f56e0b24a31d)

## Stichprobenverteilung

> Die Stichprobenverteilung ist eine theoretische Verteilung, welche die möglichen Ausprägungen eines statistischen Kennwertes (z.&nbsp;B. $\bar{x}$) sowie deren Auftretenswahrscheinlichkeit beim Ziehen von Zufallsstichproben des Umfanges $n$ beschreibt. [@bortz: 83]

Hier ist zunächst die theoretische Verteilung des Mittelwerts einer Stichprobe relevant. Insbesondere interessiert uns, wie sich die theoretische Verteilung des Mittelwerts abhängig von der Stichprobengröße verhält.

### Szenario 1: Normalverteilte Grundgesamtheit

Die Grundgesamtheit (Population) einer Variable $x$ sei normalverteilt mit $\mu=50$ und $\sigma^2=25$. Wir können also schreiben:

\nopagebreak

\[ x \sim N(50, \enspace 25) \]

Die Standardabweichung der Population beträgt entsprechend: 

\nopagebreak

\[\begin{aligned}
\sigma&=\sqrt{\sigma^2}\\[4pt]
&=\sqrt{25}=5\end{aligned}\]

Graphisch ist die Dichtefunktion der Verteilung in Abbildung \@ref(fig:pop) veranschaulicht.

```{r pop, fig.cap="Dichtefunktion der Grundgesamtheit", cache=T}
mu = 50
sigma = 5
fun <- function(x) {
  dnorm(x, mu, sigma)
}
ggplot(data.frame(x=c(mu-(2*sigma),mu+(2*sigma))), aes(x))+
  stat_function(fun=fun, color=goethe_blue) +
  scale_y_continuous(expand = c(0,0), limits = c(0,dnorm(mu,mu,sigma/sqrt(6))*1.05), name=NULL) +
  theme_goethe()
```

Wenn eine einzelne Stichprobe der Größe $n=3$ aus dieser Verteilung gezogen würde, hätte sie drei konkrete Werte ($x_1$, $x_2$ und $x_3$) sowie ein konkretes arithmetisches Mittel ($\bar{x}$).

Es lässt sich jedoch auch eine Wahrscheinlichkeitsdichtefunktion der Mittelwerte *aller theoretisch möglichen Stichproben* der Größe $n=3$ (und zusätzlich der Größe $n=6$) zeichnen (s. Abbildung \@ref(fig:stich)).

```{r stich, cache=T, fig.cap="Dichtefunktionen der Stichprobenverteilungen"}
mu=50
sigma=5
fun<-function(x){dnorm(x,mu,sigma)}
ggplot(data.frame(x=c(mu-(2*sigma),mu+(2*sigma))), aes(x))+
  stat_function(n=250,fun=fun, aes(color="blue")) +
  stat_function(n=250,fun=function(x){dnorm(x,mu,sigma/sqrt(3))}, aes(color="green")) +
  stat_function(n=250,fun=function(x){dnorm(x,mu,sigma/sqrt(6))}, aes(color="orange")) +
  scale_colour_manual(NULL, values = c("blue"=goethe_blue, "green"=green, "orange"= orange), breaks=c("blue", "green", "orange"), labels = expression(x, bar(x)~für~n==3, bar(x)~für~n==6)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,dnorm(mu,mu,sigma/sqrt(6))*1.05), name=NULL) +
  xlab(NULL) +
  theme_goethe()
```

#### Erwartungswert

Es fällt auf, dass die Stichprobenverteilungen für $\bar{x}$ normalverteilt sind und um das arithmetische Mittel der Grundgesamtheit ($\mu$) symmetrisch sind.

Das arithmetische Mittel der Stichprobenverteilung $\mu_{\bar{x}}$ wird auch als **Erwartungswert** (engl. *expected value*) von $\bar{x}$ bezeichnet. Es gilt:

\nopagebreak

$$
\mu_{\bar{x}} = \mu
(\#eq:mean)
$$

Wir können auch sagen: $\bar{x}$ ist ein "erwartungstreuer" Schätzparameter für $\mu$; nicht weil er in der Empirie zwangsläufig identisch mit $\mu$ wäre, sondern weil er mit zunehmender Stichprobengröße immer stärker zu $\mu$ tendiert.

#### Standardfehler

Zusätzlich fällt in Abbildung \@ref(fig:stich) auf: Je größer die Stichprobe, desto gestauchter die Dichtekurve der Stichprobenverteilung: Die theoretische Verteilung von $\bar{x}$ bei $n=6$ weist eine kleinere Varianz auf als bei $n=3$. Das ist einigermaßen intuitiv, denn wir können uns vorstellen, dass das arithmetische Mittel $\bar{x}$ bei steigender Stichprobengröße ein immer präziserer Schätzwert für $\mu$ wird.

Die Varianz der Stichprobenverteilung für $\bar{x}$ bezeichnen wir mit $\sigma^2_{\bar{x}}$. Sie hängt von der Varianz der Population ab und ist invers proportional zur Stichprobengröße. Es gilt:

\nopagebreak

$$
\sigma^2_{\bar{x}} = \frac{\sigma^2}{n}
(\#eq:4var)
$$

Die Standardabweichung der Stichprobenverteilung ($\sigma_{\bar{x}}$) wird auch Standardfehler (engl. *standard error*) genannt. Durch Wurzelziehen ergibt sich:

\nopagebreak

$$
\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}} (\#eq:4sd)
$$

Zusammenfassend lässt sich sagen:

\nopagebreak

$$
\begin{aligned}
\bar{x} \sim N(\mu, {\textstyle \frac{\sigma^2}{n}}) \quad \textrm{für} \quad x\sim N(\mu, \sigma^2)
\end{aligned}
(\#eq:4norm)
$$

### Szenario 2: Nicht normalverteilte Grundgesamtheit

Die Gleichungen \@ref(eq:mean), \@ref(eq:4var) und \@ref(eq:4sd) gelten uneingeschränkt auch für die Stichprobenverteilungen von nicht normalverteilten Populationen. Nur die Normalverteilung der Stichprobenverteilung (Gleichung \@ref(eq:4norm)) ist bei nicht normalverteilten Grundgesamtheiten nicht automatisch gegeben.

Das zentrale Grenzwerttheorem (engl. *central limit theorem*) besagt jedoch:

> Die Verteilung von Mittelwerten aus Stichproben des Umfangs $n$, die derselben Grundgesamtheit entnommen wurden, geht mit wachsendem Stichprobenumfang in eine Normalverteilung über. [@bortz: 86]

Abbildung \@ref(fig:beta) veranschaulicht diesen Effekt für eine nicht normalverteilte Grundgesamtheit.

```{r beta, fig.cap="Stichprobenverteilung bei nicht normalverteilter Population", cache=T}
fun <- function(x){dbeta(x,1,3)}
m = 50000
ggplot(data.frame(x=c(0,0.75)), aes(x)) +
  stat_function(fun=fun, aes(color="blue")) +
  stat_density(data=data.frame(x=replicate(m, rbeta(3, 1, 3) %>% mean)), adjust=3, aes(color="green"), geom="line") +
  stat_density(data=data.frame(x=replicate(m, rbeta(10, 1, 3) %>% mean)), adjust=3, aes(color="orange"), geom="line") +
  stat_density(data=data.frame(x=replicate(m, rbeta(30, 1, 3) %>% mean)), adjust=3, aes(color="purple"), geom="line") + 
  scale_colour_manual(NULL, values = c("blue"=goethe_blue, "green"=green, "orange"=orange, "purple"=purple), breaks=c("blue", "green", "orange", "purple"), labels = expression(x, bar(x)~für~n==3, bar(x)~für~n==10, bar(x)~für~n==30)) +
  scale_x_continuous(expand = c(0,0), name=NULL) +
  scale_y_continuous(expand = c(0,0), limits=c(0, 11), name=NULL) +
  theme_goethe()
```

In der Praxis gilt die Faustregel: Ab einer Stichprobengröße von $n=30$ können wir statistische Verfahren anwenden, die von einer theoretischen Normalverteilung von $\bar{x}$ ausgehen -- und zwar *unabhängig* von der Verteilung der Grundgesamtheit.

## Punktschätzung

Bei statistischen Untersuchungen geht es oft darum, ausgehend von der empirischen Verteilung einer Stichprobe auf Parameter der Grundgesamtheit zu schließen.

Die Punktschätzung (engl. *point estimation*) ist dabei eine vergleichsweise einfache und intuitive Vorgehensweise.

### Punktschätzung des arithmetischen Mittels

Wenn eine Stichprobe vorliegt, dann ist ihr arithmetisches Mittel ($\bar{x}$) als erwartungstreuer Punktschätzer der wahrscheinlichste Wert für das arithmetische Mittel der Grundgesamtheit ($\mu$). Es gilt

$$
\hat{\mu} = \bar{x}
(\#eq:muhat)
$$

wobei das "Dach" auf dem $\mu$ dafür steht, dass es sich nur um eine Schätzung handelt.

Beispiel:

- Zehn Studierende der Humangeographie werden zufällig ausgewählt, um ihre Pendelzeit zum IG-Farben-Campus zu erfassen.
- Die Angaben in Minuten lauten:
```{r, comment=NA, results='asis'}
xs <- c(22, 26, 12, 23, 48, 31, 15, 71, 17, 35) 
cat("`", paste(xs, collapse = " "), "`")
```
- Das arithmetische Mittel der Messreihe lässt sich -- wie in [Sitzung&nbsp;2](#arithmetisches-mittel) ausführlich besprochen -- berechnen: $\bar{x}=30$
- Da es sich um eine erwartungstreue Schätzgröße (und eine valide Zufallsstichprobe) handelt, kann die durchschnittliche Pendelzeit *aller* Studierenden der Humangeographie gemäß Gleichung \@ref(eq:muhat) auf $\hat{\mu}=\bar{x}=30$ Minuten geschätzt werden.

Gleichzeitig wissen wir jedoch, dass diese Punktschätzung des arithmetischen Mittels vermutlich nicht ganz präzise ist, sondern einem Standardfehler ($\sigma_{\bar{x}}$) unterliegt. Woher wissen wir, wie groß dieser Standardfehler ist (und wie unpräzise damit unsere Schätzung)?

### Punktschätzung der Varianz und der Standardabweichung

Bei der Varianz einer Stichprobe $s^2$ handelt es sich ebenfalls um einen erwartungstreuen Punktschätzer für die Varianz der Grundgesamtheit $\sigma^2$.

Es gilt also

$$
\hat{\sigma^2} = s^2 (\#eq:varhat)
$$

und damit natürlich auch

$$
\hat{\sigma} = s (\#eq:sigmahat)
$$

### Schätzung des Standardfehlers

Wir führen das obige Beispiel fort:

- Die Varianz der Stichprobe können wir berechnen: $s^2\approx319{,}78$ (s.[Sitzung&nbsp;2](#varianz)).
- Die Varianz der Grundgesamtheit kann also mit Gleichung \@ref(eq:muhat) auch auf $\hat{\sigma^2}=s^2\approx319{,}78$ geschätzt werden.
- Analog können wir die Standardabweichung der Population auf $\hat{\sigma}=s\approx17{,}88$ schätzen.
- Den Standardfehler können wir mit diesem Schätzwert anhand Gleichung \@ref(eq:4sd) berechnen. Allerdings benutzen wir statt $\sigma_{\bar{x}}$ das Symbol $s_{\bar{x}}$, da es sich um einen Schätzwert handelt:

\nopagebreak

$$
\begin{aligned}
s_{\bar{x}} &= \frac{s}{\sqrt{n}}\\[4pt]
&\approx \frac{17{,}88}{\sqrt{10}}\approx5{,}65
\end{aligned}
$$

Je größer die Stichprobe, desto genauer lassen sich also Parameter der Population schätzen. Die statistische Antwort auf die Frage, wie groß die Stichprobe denn sein müsse, lautet demnach zunächst immer: Möglichst groß!

Bemerkenswert ist jedoch, dass dabei die Größe der Grundgesamtheit ($N$, im Beispiel die Anzahl aller Studierenden der Humangeographie) bei diesen Überlegungen überhaupt keine Rolle spielt.

## Intervallschätzung

Um eine Intervallschätzung durchführen zu können, muss:

- die Standardabweichung der Grundgesamtheit $\sigma$ bekannt und
- die theoretische Verteilung von $\bar{x}$ normalverteilt sein. Das bedeutet:
  - *Entweder* es ist bekannt, dass die Grundgesamtheit normalverteilt ist
  - *Und/oder* die Stichprobengröße ist $n\geq30$

Für das obige Beispiel der Pendelzeiten wissen wir nicht, wie die Verteilung der Grundgesamtheit aussieht, und die Stichprobengröße ($n=10$) ist kleiner als 30. Eine Intervallschätzung können wir hier also nicht durchführen!

Auch bei der Intervallschätzung (engl. *interval estimation*) geht es darum, das arithmetische Mittel der Population ($\mu$) zu schätzen. Allerdings geben wir nicht einfach nur den wahrscheinlichsten Wert an, sondern einen Bereich (ein *Intervall*), in dem $\mu$ mit einer bestimmten Wahrscheinlichkeit liegt.

Die Grundüberlegung ist dabei folgende:

- Wir haben eine *empirische* Stichprobe vorliegen (und können ihren Mittelwert $\bar{x}$ und ihre Standardabweichung $s$ berechnen).
- Wir wissen dass die *theoretische* Verteilung aller möglichen Stichproben normalverteilt ist, und um den gesuchten Wert $\mu$ symmetrisch ist.
- Den Mittelwert unserer empirischen Stichprobe $\bar{x}$ können wir uns als zufälligen Wert der theoretischen Stichprobenverteilung von $\bar{x}$ vorstellen.
- Wo genau in dieser theoretischen Verteilung wir mit unserem empirischen Wert "gelandet" sind, wissen wir nicht.
- Wenn wir den Wert $\mu$ kennen würden, könnten wir (mit den Methoden aus [Sitzung&nbsp;3](#wahrscheinlichkeitsrechnung-mit-standardnormalverteilung)) die Wahrscheinlichkeit für einen beliebeigen Bereich angeben, in den ein zufälliges $\bar{x}$ fällt.
- Der entscheidende Trick: Weil die Normalverteilung symmetrisch ist, sind diese Wahrscheinlichkeiten analog anzuwenden auf die Bereiche einer konstruierten Verteilung mit gleichem $\sigma_{\bar{x}}$ um unser $\bar{x}$, in die der wirkliche Wert $\mu$ fällt. (s. Abbildung \@ref(fig:double)).

```{r double, cache=T, fig.cap="Konstruierte Verteilung um $\\bar{x}$"}
mu=50
sigma=50/sqrt(6)
fun<-function(x){dnorm(x,mu,sigma)}
ggplot(data.frame(x=c(25,80)), aes(x))+
  stat_function(n=250,fun=function(x){dnorm(x,mu,sigma/sqrt(6))}, aes(color="blue")) +
  stat_function(n=250,fun=function(x){dnorm(x,55,sigma/sqrt(6))}, aes(color="orange")) +
  geom_vline(xintercept=50, linetype="dashed", color=orange) +
  geom_vline(xintercept=55, linetype="dashed", color=goethe_blue) +
  scale_colour_manual(NULL, values = c("blue"= goethe_blue, "orange"=orange), breaks=c("blue", "orange"), labels = expression(bar(x), mu)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,dnorm(mu,mu,sigma/sqrt(6))*1.05), breaks=NULL, name=NULL) +
  scale_x_continuous(breaks=c(50,55), expand=c(0,0), labels = expression(mu, bar(x))) +
  xlab(NULL) +
  theme_goethe()
```

Dabei heißt der Bereich Konfidenzintervall (engl. *confidence interval*), und seine Breite wird mit $\textrm{KIB}$ abgekürzt. Die Wahrscheinlichkeit, dass wir mit unserer Schätzung *außerhalb* des Konfidenzintervalls liegen wird mit $\alpha$ gekennzeichnet. Ein 95%-Konfidenzintervall hat also ein $\alpha$ von 0,05 (s. Abbildung \@ref(fig:konf)).

```{r konf, fig.cap="Konfidenzintervall"}
ggplot(data.frame(x=c(-3,3)), aes(x)) +
  stat_function(geom="area", fun=dnorm, fill=light_blue, xlim=c(-1,1)) +
  stat_function(fun=dnorm, color=goethe_blue) +
  annotate(geom = "text", x = -1.5, y = 0.05, label = "alpha/2", parse = T)+
  annotate(geom = "text", x = 1.5, y = 0.05, label = "alpha/2", parse = T)+
  annotate(geom = "text", x = 0, y = 0.05, label = "1-alpha", parse = T)+
  annotate(geom = "text", x = 0, y = dnorm(1), label = "KIB\n")+
  geom_segment(aes(x = -1, xend = 1, y = dnorm(-1), yend = dnorm(1)), arrow = arrow(ends = "both", type = "closed", angle = 10), color = goethe_blue) +
  scale_x_continuous(breaks=c(-1,0,1), labels = c("Untergrenze", bquote(bar(x)), "Obergrenze"), name=NULL, expand = c(0,0)) +
  scale_y_continuous(breaks = NULL, name=NULL, expand=c(0,0), limits = c(0,dnorm(0)*1.05)) +
  theme_goethe()
```


```{r tab}
tibble(Jahr = 2011:2017,
       `Niederschlag (l/m²)` = c(855.3, 839.5, 850.6,
                                 873.1, 858.3, 857.1, 861.4)) %>%
tabelle(full_width = F, caption = "Jahresniederschlag in Hessen")
```

Ein Beispiel soll dies verdeutlichen: Wir wissen, dass die jährliche Niederschlagsmenge in Hessen normalverteilt ist mit $\sigma=10{,}23$. Wir haben die Messwerte in Tabelle 1 erhoben und möchten den Mittelwert ($\mu$) per Intervallschätzung angeben.

Zunächst errechnen wir den Mittelwert unserer empirischen Stichprobe:

\nopagebreak

$$
\begin{aligned}
  \bar{x}&\approx856{,}47
\end{aligned}
$$

Dann errechnen wir anhand Gleichung \@ref(eq:4sd) den Standardfehler der theoretischen Verteilung von $\bar{x}$:

\nopagebreak

$$\begin{aligned}
\sigma_{\bar{x}}&=\frac{\sigma}{\sqrt{n}}\\[4pt]
           &\approx\frac{10{,}23}{\sqrt{7}}\approx3,86
\end{aligned}$$

### Gesuchtes $\alpha$

Nun könnte eine Fragerichtung lauten: Wie groß ist die Wahrscheinlichkeit, dass der Mittelwert der Population $\mu$ in einem Korridor von ± 5 l/m² um $\bar{x}$ liegt? ^[Genau genommen ist das nicht ganz korrekt, "denn tatsächlich kann der Parameter nur innerhalb oder außerhalb des gefundenen Bereichs liegen. Die Wahrscheinlichkeit, dass ein Parameter in einen bestimmten Bereich fällt, ist damit entweder 0 oder 1." [@bortz: 93]. Mathematisch korrekt müsste es heißen: "Die Wahrscheinlichkeit, dass $\bar{x}$ zu einer Population gehört, deren Parameter $\mu$ in diesem Bereich liegt..."]

Gesucht ist bei einer Konfidenzintervallbreite von $\textit{KIB}=10$ also die Wahrscheinlichkeit:

\nopagebreak

\[1-\alpha\approx P(851{,}47 < \mu < 861{,}47)\]

Generalisierend lässt sich schreiben:

\nopagebreak

$$
1-\alpha=P(x_{\alpha/2} < \mu < x_{(1-\alpha/2)})
$$

\nopagebreak

...wobei $x_{\alpha/2}$ die Untergrenze darstellt und $x_{(1-\alpha/2)}$ die Obergrenze.

In $z$-Werten ausgedrückt:

\nopagebreak

$$
1-\alpha=P(z_{\alpha/2} < z_{\mu} < z_{(1-\alpha/2)})
(\#eq:konf)
$$

In [Sitzung&nbsp;3](#wahrscheinlichkeitsrechnung-mit-standardnormalverteilung) haben wir bereits gelernt, wie diese Wahrscheinlichkeit berechnet werden kann. Im Folgenden wird der Rechenweg noch einmal am Beispiel dargelegt. 

#### Die umständliche Variante

Zunächst müssen wir die Intervallgrenzen in$z$-Werte umwandeln, um die Unter- bzw. Überschreitungswahrscheinlichkeiten ermitteln zu können. Die $z$-Transformation muss hier jedoch anhand des Standardfehlers $\sigma_{\bar{x}}$ geschehen, da wir ja an der Stichprobenverteilung interessiert sind. Durch $z$-Transformation mit $\bar{x}$ und dem Standardfehler $\sigma_{\bar{x}}$ erhalten wir die standardisierten Intervallgrenzen.

Untergrenze:

\nopagebreak

$$\begin{aligned}
z_{\alpha/2} &= \frac{x_{\alpha/2}-\bar{x}}{\sigma_{\bar{x}}}\\[4pt]
&\approx\frac{851{,}47-856,47}{3,86}\approx-1,30
\end{aligned}$$

Obergrenze:

\nopagebreak

$$\begin{aligned}
z_{(1-\alpha/2)} &= \frac{x_{(1-\alpha/2)}-\bar{x}}{\sigma_{\bar{x}}}\\[4pt]
&\approx\frac{861{,}47-856,47}{3,86}\approx1,30
\end{aligned}$$

Es ist wenig überraschend, dass die $z$-transformierten Werte symmetrisch sind. Wir setzen in Gleichung \@ref(eq:konf) ein:

\nopagebreak

$$1-\alpha\approx P(-1{,}30 <z_{\mu} < 1{,}30)$$

Dies lässt sich umformen in:

\nopagebreak

$$
1-\alpha\approx P(z_{\mu}<1{,}30) - P(z_{\mu}<-1{,}30) 
$$

Die jeweiligen Wahrscheinlichkeiten lassen sich in der [Tabelle für $p$-Werte der Normalverteilung](#tabelle-z) nachschauen (bzw. für den negativen $z$-Wert errechnen):

\nopagebreak

$$
\begin{aligned}
1-\alpha&\approx 0,9032 - 0,0968\\
&=0,8064
\end{aligned}
$$

Die Wahrscheinlichkeit, dass $\mu$ im Konfidenzintervall 856,47 ± 5 l/m² liegt, beträgt also 80,64%.

#### Die schnelle Variante

Wir können den $z$-Wert für die Obergrenze des Konfidenzintervalls ganz einfach ausrechnen, weil wir wissen, dass die Obergrenze um 5 größer ist als $\bar{x}$ und dass $z_{\bar{x}}=0$:

\nopagebreak

$$\begin{aligned}
z_{(1-\alpha/2)}&=\frac{5}{\sigma_{\bar{x}}}\\
&\approx\frac{5}{3,86}\\
&\approx1{,}30
\end{aligned}$$

Oberhalb dieses Werts liegt bekanntermaßen der Anteil $\frac{\alpha}{2}$, woraus sich mit Blick auf die Tabelle ergibt:

\nopagebreak

\[\begin{aligned}
\frac{\alpha}{2}&=1-0,9032\\[4pt]
\alpha&=0,1936
\end{aligned}\]

### Gesuchtes Konfidenzintervall

Eine weitere Möglichkeit der Fragestellung lautet: In welchem Bereich liegt das arithmetische Mittel $\mu$ mit einer Wahscheinlichkeit von 90%?

Vorgegeben ist also $\alpha=0{,}1$, und gesucht sind die Unter- und die Obergrenze des Konfidenzintervalls.

Wir setzen ein:

\nopagebreak

\[\begin{aligned}
1-\alpha&=P(z_{\alpha/2} < z_{\mu} < z_{(1-\alpha/2)})\\[4pt]
0{,}9 &= P(z_{5\%} < z_{\mu} < z_{95\%})
\end{aligned}\]

Die entsprechenden $z$-Werte der Intervallgrenzen lassen sich (in umgekehrter Suchrichtung) aus der Tabelle ablesen:

\nopagebreak

\[\begin{aligned}
z_{5\%}&\approx-1{,}64\\[4pt]
z_{95\%}&\approx 1{,}64
\end{aligned}\]

Durch umgekehrte z-Transformation -- auch hier weider mit $\bar{x}$ und $\sigma_{\bar{x}}$ -- ergeben sich die Intervallgrenzen.

Untergrenze:

\nopagebreak

$$\begin{aligned}
x_{5\%} &= z_{5\%} \cdot \sigma_{\bar{x}} + \bar{x}\\[4pt]
&\approx -1{,}64 \cdot 3,86 + 856{,}47\\[4pt]
&\approx 850,14\\[6pt]
\end{aligned}$$

Obergrenze:

\nopagebreak

$$
\begin{aligned}
x_{95\%}&= z_{95\%} \cdot \sigma_{\bar{x}} + \bar{x}\\[4pt]
&\approx 1{,}64 \cdot 3,86 + 856{,}47\\[4pt]
&\approx 862,80
\end{aligned}$$

Auch hier gibt es wieder eine kleine Abkürzung: Aufgrund der Symmetrie unserer theoretischen Verteilung gilt für die Konfidenzintervallbreite generell:

\nopagebreak

$$
\frac{\mathit{KIB}}{2} = z_{(1-\alpha/2)} \cdot \sigma_{\bar{x}}
(\#eq:kib)
$$

Wir setzen einfach unsere Werte ein:

\nopagebreak

\[\begin{aligned}
\frac{\mathit{KIB}}{2} &= z_{95\%} \cdot s_{\bar{x}}\\[4pt]
&\approx1{,}64 \cdot 3,86\\[4pt]
&\approx 6,33
\end{aligned}\]

Die Intervallgrenzen ergeben sich dann trivial aus $\bar{x} \pm \frac{\mathit{KIB}}{2}$.

### Gesuchtes $n$

Eine letzte Fragerichtung lautet: Wie viele Messwerte müssten vorliegen, um den durchschnittlichen Niederschlag mit einem Konfidenzniveau von 99% und einer Genauigkeit von ± 5 l/m² schätzen zu können?

Gegeben sind also das Konfidenzintervall und $\alpha=0{,}01$, gesucht wird $n$. Wir wissen, dass die Stichprobengröße $n$ den Standardfehler $\sigma_{\bar{x}}$ bestimmt. Also benutzen wir zunächst Gleichung \@ref(eq:kib) und formen um:

\nopagebreak

\[\begin{aligned}
\frac{\mathit{KIB}}{2} &= z_{(1-\alpha/2)} \cdot \sigma_{\bar{x}}\\[4pt]
\sigma_{\bar{x}} &= \frac{\mathit{KIB}}{2\cdot z_{(1-\alpha/2)}} 
\end{aligned}\]

Durch Einsetzen und mit Blick auf die Tabelle erhalten wir:

\nopagebreak

\[\begin{aligned}
\sigma_{\bar{x}} &= \frac{10}{2\cdot z_{99{,}5\%}}\\[4pt]
 &\approx \frac{10}{2\cdot 2{,}58}\\[4pt]
 &\approx 1{,}94
\end{aligned}\]

Dieser Standardfehler $\sigma_{\bar{x}}\approx1{,}94$ würde unseren Anforderungen genügen. Welches $n$ ist nötig, um diesen Standardfehler zu erreichen? Wir formen Gleichung \@ref(eq:4sd) um...

\nopagebreak

\[\begin{aligned}
\sigma_{\bar{x}} &= \frac{\sigma}{\sqrt{n}}\\[4pt]
               n &= \Big(\frac{\sigma}{\sigma_{\bar{x}}}\Big)^2
\end{aligned}\]

...und setzen den angestrebten Standardfehler sowie die Standardabweichung der Population ($\sigma=10{,}23$) ein:

\nopagebreak

$$
\begin{aligned}
n&=\Big(\frac{\sigma}{\sigma_{\bar{x}}}\Big)^2\\[4pt]
n&\approx\bigg(\frac{10{,}23}{1{,}94}\bigg)^2\\[4pt]
&\approx27{,}80
\end{aligned}
$$

Wir müssten also 28 Stichproben vorliegen haben.

## Tipps zur Vertiefung {-}

- YouTube-Kanal "Kurzes Tutorium Statistik": [Intervallschätzungen - Konfidenzintervalle](https://www.youtube.com/watch?v=DdwTa28W4Os)
- Kapitel 6.2--6.4 in @bortz
- Kapitel 8.1.1 -- 8.1.4 in @delange
- Kapitel 8 in @klemm
- Kapitel 5.3.1 in @bahrenberg
- *English:* Kapitel 8 in @burt

<!--chapter:end:04_Schaetzstatistik.Rmd-->

## Übungsaufgaben {-}

Die folgenden Aufgaben sind zur eigenständigen Überprüfung Ihrer Lernleistung gedacht (als Vor- oder Nachbereitung der Vorlesung, oder als Klausurübung) und nicht etwa als Hausaufgabe.

`r naechste("aufgabe", T)`

Eine Messreihe habe die Werte:

```{r}
c(165, 173, 155, 179, 158, 142) %>%
  dcat()
```

a) Führen Sie eine Punktschätzung für $\mu$ und $\sigma$ der Grundgesamtheit durch.
b) Welcher Standardfehler für $\bar{x}$ ist zu erwarten?

`r naechste("aufgabe")`

Die Sonnenstunden auf einer Ferieninsel (pro Tag, im Jahresdurschnitt) sind annähernd normalverteilt mit einer Standardabweichung von vier Minuten. Der Mittelwert $\mu$ ist unbekannt, es liegen neun Messwerte vor.

a) Welcher Standardfehler für $\bar{x}$ ist zu erwarten?
c) Welche Konfidenzintervallbreite korrespondiert mit einem Konfidenzniveau von 95%?
b) Mit welchem Konfidenzniveau lässt sich $\mu$ "auf die Minute genau" (± 30 Sekunden) schätzen?
d) Welche Stichprobengröße ist nötig um den Mittelwert mit einer Konfidenzintervallbreite von zwei Minuten und -niveau von 90% zu schätzen?

`r naechste("aufgabe")`

Sie intressieren sich für das Durchschnittseinkommen (in EUR) der Haushalte eines Stadtteils. Die Varianz ist mit $\sigma^2=4096$ bekannt. Eine Zufallsstichprobe von 40 befragten Haushalten weist einen Mittelwert von $\bar{x}=2650$ auf.

a) Wie lautet das 90%-Konfidenzintervall?
b) Mit welcher Wahrscheinlichkeit liegt das Durchschnittseinkommen zwischen 2640 und 2660 EUR?

`r naechste("aufgabe")`

Es sei bekannt, dass die Lieferzeit eines Bauteils aus Übersee annähernd normalverteilt ist mit einer Standardabweichung von 11,5 Tagen.

Bei sieben Bestellvorgängen werden folgende Lieferzeiten festgestellt (in Tagen):

$$116{,}5\quad 94{,}5\quad101{,}5\quad109{,}0\quad125{,}0\quad112{,}5\quad100{,}5$$

Sie interessieren sich für die tatsächliche durchschnittliche Lieferzeit, von der Sie auch in Zukunft ausgehen können.

a) Berechnen Sie das arithmetische Mittel der beobachteten Werte für die Lieferzeit.
b) Was ist der Standardfehler für die Stichprobenverteilung von $\bar{x}$?
c) Zwischen welchen Werten liegt die tatsächliche durchschnittliche Lieferzeit mit 95% Wahrscheinlichkeit?
d) Wie viele zusätzliche Messungen müssten Sie vornehmen, um den tatsächlichen Mittelwert im selben Wertebereich zu 99% verorten zu können?

<!--chapter:end:04_Aufgaben.Rmd-->

# Grundlagen der Teststatistik

### Lernziele dieser Sitzung {-}

Sie können...

- Hypothesen formulieren.
- einen $z$-Test durchführen.
- einen 1-Stichproben-$t$-Test durchführen.

### Lernvideos (Sommersemester 2020) {-}

- [5a) $z$-Test](https://video01.uni-frankfurt.de/Mediasite/Play/696f09c79d0b4186b66e040e4377b7601d)
- [5b) 1-Stichproben-$t$-Test](https://video01.uni-frankfurt.de/Mediasite/Play/c78e80fbd9fb4073a7f932d3862245da1d)

## Statistische Tests

Gemeinsam mit der Schätzstatistik bildet die Test- bzw. Prüfstatistik jenen Teil statistischer Verfahren, die ausgehend von einer Stichprobenverteilung Rückschlüsse auf die Beschaffenheit von Grundgesamtheiten anstreben (schließende Statistik).

Dabei haben Schätz- und Teststatistik jedoch grundlegend verschiedene Vorgehensweisen. Wie in [Sitzung 4](#Schätzstatistik) besprochen ermöglicht die Schätzstatistik die Angabe statistischer Parameter einer Grundgesamtheit anhand von Stichprobenwerten, und unter Angabe von Wahrscheinlichkeiten.

Ziel statistischer Tests hingegen ist es, mit Hilfe von Stichproben Hypothesen (also Vermutungen) über die Grundgesamtheit zu prüfen. Geprüft wird dabei ein empirischer Sachverhalt gegen die Zufälligkeit seiner Realisierung. Ein statistischer Test fragt, ab welcher Größenordnung ein Stichprobenergebnis nicht mehr als zufällig, sondern als *signifikant* anzusehen ist.

Dabei folgt die grundsätzliche Vorgehensweise von (hier behandelten) statistischen Tests immer diesem Schema:

1. Test wählen und Voraussetzungen prüfen
2. Hypothesen formulieren
3. Signifikanzniveau entscheiden
4. Ablehnungsbereich bestimmen
5. Prüfgröße berechnen
6. Ergebnis interpretieren

Die einzelnen Schritte werden im Folgenden direkt anhand des $z$-Tests besprochen.

## `r symbol_header("z")`-Test {#z-test}

Die mathematischen Grundlagen des $z$-Tests leiten sich direkt aus der in [Sitzung 4](#stichprobenverteilung) besprochenen Stichprobenverteilung für $\bar{x}$ ab.

Ein illustrierendes Beispiel: Wir wissen, dass die Anzahl der täglichen Besucher\*innen einer Eissporthalle annähernd normalverteilt ist, und zwar mit dem arithmetischen Mittel $\mu=94{,}2$ und der Standardabweichung $\sigma=11{,}8$. Wir vermuten, dass die Anzahl der Besucher\*innen an bewölkten Tagen größer ist, weil an sonnigen Tagen andere Freizeitbeschäftigungen attraktiver sind.

An fünf zufälligen bewölkten Tagen zählen wir die Besucher\*innen und kommen auf einen Mittelwert der Stichprobe von $\bar{x} = 103{,}0$.

Dieser Wert ist höher als das arithmetische Mittel der Grundgesamtheit ($\mu$). Aber heißt das auch, dass unsere Vermutung stimmt? Wir wissen aus [Sitzung 4](#stichprobenverteilung), dass die Stichprobenverteilung einem Standardfehler ($\sigma_{\bar{x}}$) unterliegt (s. Abbildung \@ref(fig:eis)).

Ist das Ergebnis also nur zufällig zustande gekommen, oder liegt ein *statistisch signifikantes* Ergebnis vor? Mit anderen Worten: Ist die Stichprobe überhaupt der Verteilung $x_0$ um $\mu_0$ entnommen, oder gibt es eine *andere* Verteilung ($x$ um ein anderes $\mu$) für bewölkte Tage, denen unser Stichprobenmittelwert $\bar{x}$ entstammt? Genau diese Art von Frage versuchen statistische Tests zu beantworten.

```{r eis, fig.cap="Theoretische Stichprobenverteilung (unter Annahme der Nullhypothese)"}
mu <- 94.2
sigma <- 11.8
n <- 5
barx <- 103.0
fun <- function(x) {
  dnorm(x, mu, sigma)
}
stich <- function(x) {
  dnorm(x, mu, sigma / sqrt(n))
}
ggplot(data.frame(x = c(mu - 2 * sigma, mu + 2 * sigma)), aes(x)) +
  stat_function(n = 250, fun = fun, aes(color = "blue")) +
  stat_function(n = 250, fun = stich, aes(color = "red")) +
  geom_vline(xintercept = barx, color = "red", linetype = "dashed") +
  scale_x_continuous(NULL,
                     expand = c(0, 0),
                     breaks = c(80, 90, 110, barx),
                     labels = c(80, 90, 110, expression(bar(x) == 103))) +
  scale_y_continuous(expand = c(0, 0),
                     limits = c(0, stich(mu) * 1.05),
                     name   = NULL) +
  scale_color_manual(NULL,
                     values = c("blue" = goethe_blue,
                                      "red" = emo_red),
                     labels = expression(x[0], bar(x)[0]~für~n == 5)) +
  theme_goethe()
```


### Test wählen und Voraussetzungen prüfen

Je nachdem, was überprüft werden soll, was über die Grundgesamtheit bekannt ist und wie die Stichprobe beschaffen ist, müssen verschiedene Testverfahren angewendet werden.

Statistische Tests unterscheiden sich zunächst in Bezug auf ihre Prüfgröße (und sind auch nach ihrer Prüfgröße benannt). Wir werden zunächst den $z$-Test kennenlernen, der mit dem (uns seit [Sitzung 3](#z-transformation) bekannten) $z$-Wert als Prüfgröße arbeitet.

Der $z$-Test hat zum Ziel, den Mittelwert einer Stichprobe mit den zu erwartenden Werten bei einer bekannten Verteilung zu vergleichen.

Um den $z$-Test anwenden zu können, müssen also folgende Voraussetzungen gegeben sein: 

- Das Ziel der Untersuchung ist es, eine signifikante Abweichung des Mittelwerts festzustellen.
- Das arithmetische Mittel $\mu$ und die Standardabweichung $\sigma$ der (ursprünglichen) Grundgesamtheit müssen bekannt sein. 
- Der Test muss anhand einer reinen Zufallsstichprobe erfolgen.
- Die Stichprobenverteilung muss (annähernd) normalverteilt sein, das heißt:
  - *entweder* die Grundgesamtheit ist (annähernd) normalverteilt,
  - *oder* die Stichprobe hat die Größe $n\geq30$.

#### Beispiel

In unserem Beispiel (Besuchszahlen der Eissporthalle) sind diese Voraussetzungen gegeben. Wir können und wollen also einen $z$-Test durchführen.


### Hypothesen formulieren

Es müssen immer zwei Hypothesen formuliert werden: die Nullhypothese und die Alternativhypothese. Die Nullhypothese geht immer davon aus, dass es keine Abweichung gibt, die Alternativhypothese formuliert eine Abweichung.

Dabei werden zwei Verteilungen konstruiert: Die bekannte Grundgesamtheit (in unserem Beispiel: Besuchszahlen insgesamt) $x_0$ mit Mittelwert $\mu_0$ und eine neue Verteilung (Besuchszahlen an bewölkten Tagen) $x$ mit Mittelwert $\mu$.

Die Hypothesen sind theoriegeleitet (formulieren also eine begründete Vermutung) und stehen stets am Anfang der statistischen Untersuchung. Es ist unzulässig, sie im Nachhinein anzupassen.

#### Nullhypothese

Die Nullhypothese (engl. *null hypothesis*) geht immer davon aus, das die forscherische Vermutung nicht stimmt. Im $z$-Test besagt die Nullhypothese, dass es zwischen dem Mittelwert $\mu_0$ und dem Mittelwert $\mu$ keinen Unterschied gibt. Generell heißt die Nullhypothese:

\[
H_0 : \mu = \mu_0
(\#eq:zh0)
\]

#### Alternativhypothese

Die Alternativhypothese (engl. *alternative hypothesis*) stellt die Vermutung dar, die überprüft werden soll. Dabei gibt es zwei unterschiedliche Möglichkeiten: ungerichtete und gerichtete Alternativhypothesen.

##### Ungerichtete Alternativhypothese

Die ungerichtete Alternativhypothese besagt nur, *dass* es einen Unterschied zwischen $\mu$ und $\mu_0$ gibt, aber nicht in welche Richtung (größer oder kleiner). Sie lautet daher:

\[
H_1 : \mu \neq \mu_0
(\#eq:zh1u)
\]

##### Gerichtete Alternativhypothese

Die gerichtete Alternativhyptothese gibt eine Richtung des vermuteten Unterschieds (nach oben oder unten) vor. Sie lautet entweder:

\[
H_1 : \mu < \mu_0 \quad \textrm{(abwärts gerichtet)}
(\#eq:zh1l)
\]

oder:

\[
H_1 : \mu > \mu_0 \quad \textrm{(aufwärts gerichtet)}
(\#eq:zh1g)
\]

#### Beispiel 

In unserem Beispiel geben wir eine Richtung vor, denn wir vermuten ja, dass die Besuchszahlen an bewölkten Tagen *höher* sind. Wir schreiben also:

\[\begin{aligned}
H_0: \mu = 94{,}2\\[4pt]
H_1: \mu>94{,}2
\end{aligned}\]

### Signifikanzniveau entscheiden

Das Signifikanzniveau $\alpha$ (engl. *significance level*) entscheidet, wie *unwahrscheinlich* eine Prüfgröße unter Annahme der Nullhypothese sein muss, damit wir die Nullhypothese ablehnen können (und damit unsere Annahme bestätigen).

Übliche Werte für das Signifikanzniveau sind $\alpha=0{,}05$ oder $\alpha=0{,}01$.

Für die Wahl des Signifikanzniveaus ist jeweils der Kontext entscheidend: Wenn die irrtümliche Bestätigung der forscherischen Annahme gravierende Auswirkungen hat, möchte man das Signifikanzniveau besonders niedrig wählen um diese Art von Fehler auszuschließen. 

Auch das Signifikanzniveau muss vor der statistischen Erhebung formuliert werden, und es ist unzulässig, es im Nachhinein an das Ergebnis anzupassen.

#### Beispiel

Ein Irrtum in der statistischen Signifikanz der Besucherzahl hat vermutlich keine gravierenden Folgen. Wir legen das Signifikanzniveau auf $\alpha=0{,}05$ fest.

### Ablehnungsbereich bestimmen

Zusammen mit der (Un-)Gerichtetheit der Alternativhypothese bestimmt das Signifikanzniveau $\alpha$ den *Ablehnungsbereich* -- also den Bereich für die zu errechnende Prüfgröße $z$, in dem die Nullhypothese abgelehnt würde.

Der Ablehnungsbereich für die ungerichtete Alternativhypothese ist $\frac{\alpha}{2}$ auf beiden Seiten (s. Abbildung \@ref(fig:ablung)). Die kritischen Werte sind dann die Schwellen des Ablehnungsbereich auf beiden Seiten:

$$
z \leq z_{\alpha/2} \quad \textrm{und} \quad z \geq z_{(1-\alpha/2)} \quad \textrm{für} \quad H_1: \mu \neq \mu_0
(\#eq:zkritneq)
$$

```{r ablung, fig.cap="Kritische Werte für $z$ bei ungerichteter Alternativhypothese und $\\alpha=0{,}05$"}
ggplot(data.frame(x=c(-3, 3)), aes(x)) +
  stat_function(n=250,xlim=c(-3,qnorm(0.025)),fun=dnorm, geom="area", fill=light_blue) +
  stat_function(n=250,xlim=c(qnorm(0.975),3),fun=dnorm, geom="area", fill=light_blue) +
  stat_function(n=250,fun=dnorm, color=goethe_blue) +
  scale_x_continuous("z", breaks=c(qnorm(0.025), 0, qnorm(0.975)), labels=c(paste0("~",round(qnorm(0.025),2)), 0, paste0("~",round(qnorm(0.975),2))), expand = c(0,0)) +
  scale_y_continuous(NULL, expand = c(0,0), limits=c(0,dnorm(0)*1.05)) +
  theme_goethe()
```
Bei den gerichteten Alternativhypothesen ist der Ablehnungsbereich jeweils nur auf einer Seite (s. Abbildungen \@ref(fig:ablger1) und \@ref(fig:ablger2)). Die kritischen Werte ergeben sich aus:

$$
z \leq z_{\alpha} \quad \textrm{für} \quad H_1: \mu < \mu_0
(\#eq:zkritless)
$$

$$
z \geq z_{(1-\alpha)} \quad \textrm{für} \quad H_1: \mu > \mu_0
(\#eq:zkritgreat)
$$

```{r ablger1, fig.cap="Kritischer Wert für $z$ bei gerichteter Alternativhypothese nach unten und $\\alpha=0{,}05$"}
ggplot(data.frame(x=c(-3, 3)), aes(x)) +
  stat_function(n=250,xlim=c(-3, qnorm(0.05)),fun=dnorm, geom="area", fill=light_blue) +
  stat_function(n=250,fun=dnorm, color=goethe_blue) +
  scale_x_continuous("z", breaks=c(0, qnorm(0.05)), labels=c(0, "~-1,65"), expand = c(0,0)) +
  scale_y_continuous(NULL, expand = c(0,0), limits=c(0,dnorm(0)*1.05)) +
  theme_goethe()
```

```{r ablger2, fig.cap="Kritischer Wert für $z$ bei gerichteter Alternativhypothese nach oben und $\\alpha=0{,}05$"}
ggplot(data.frame(x=c(-3, 3)), aes(x)) +
  stat_function(n=250,xlim=c(qnorm(0.95),3),fun=dnorm, geom="area", fill=light_blue) +
  stat_function(n=250,fun=dnorm, color=goethe_blue) +
  scale_x_continuous("z", breaks=c(0, qnorm(0.95)), labels=c(0, "~1,65"), expand = c(0,0)) +
  scale_y_continuous(NULL, expand = c(0,0), limits=c(0,dnorm(0)*1.05)) +
  theme_goethe()
```


#### Beispiel

In unserem Beispiel haben wir eine gerichtete Alternativhypothese nach oben und ein Signifikanzniveau von $\alpha=0{,}05$ verwendet. Der kritische Wert (bei dessen Überschreitung wir die Nullhypothese ablehnen und unsere Vermutung bestätigt sehen) lautet also:

\[
z \geq z_{95\%}\approx 1{,}65
\]

Der Mittelwert unserer Stichprobe fällt höher aus als $\mu$. Aber übersteigt er auch den kritischen Wert (und ist damit statistisch signifikant)?

### Prüfgröße berechnen

Für den $z$-Test ist die Prüfgröße der $z$-Wert der Stichprobe, und zwar standardisiert in Bezug auf $\mu_0$ und den Standardfehler ($\sigma_{\bar{x}}$):

\[
z=\frac{\bar{x}-\mu_0}{\sigma_{\bar{x}}}
(\#eq:trans)
\]

Wie wir bereits wissen, ergibt sich der Standardfehler ($\sigma_{\bar{x}}$) wiederum aus der Stichprobengröße ($n$) und der Standardabweichung der Grundgesamtheit ($\sigma$):

\[
\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}
(\#eq:serr)
\]

Durch einsetzen ergibt sich die generelle Formel für die Prüfgröße des $z$-Tests:

\[
z=\sqrt{n}\cdot\frac{\bar{x}-\mu_0}{\sigma}
(\#eq:5z)
\]

Das grundsätzliche Schema dieser Formel werden wir in anderen Tests wiedererkennen.

#### Beispiel

An dieser Stelle (also *nachdem* wir uns für einen Test und ein Signifikanzniveau entschieden und den kritischen Wert berechnet haben) dürften wir streng genommen erst die Stichprobe erheben.

Diese ergibt bei $n=5$ den Mittelwert $\bar{x}=103{,}0$. Die Verteilung $x_0$ (also unter Annahme der Nullhypothese) hatte die Kennwerte $\mu_0=94{,}2$ und $\sigma=11{,}8$.

Wir setzen ein in die Formel aus Gleichung \@ref(eq:5z):

\[\begin{aligned}
z&=\sqrt{n}\cdot\frac{\bar{x}-\mu_0}{\sigma}\\[4pt]
 &\approx\sqrt{5}\cdot\frac{103{,}0-94{,}2}{11{,}8}\\[4pt]
 &\approx1{,}67
\end{aligned}\]

### Ergebnis inerpretieren

Je nachdem, ob die Prüfgröße in den Ablehnungsbereich fällt (ob der kritische Wert also unter- bzw. überschritten wird), können wir die Nullhypothese ablehnen (und damit unsere Alternativhypothese bestätigen) oder nicht.

Eine Ablehnung der Nullhypothese bedeutet, dass wir ein *statistisch signifikantes Ergebnis zugunsten unserer Vermutung* vorliegen haben.

Diese Art von Ergebnis wird oft falsch interpretiert. Bei einem Signifikanzniveau von $\alpha=0{,}01$ heißt das zum Beispiel, dass die beobachteten Werte nur mit 1% Wahrscheinlichkeit vorkommen, wenn unsere Vermutung *nicht* stimmt. Wichtig dabei: Das ist etwas ganz anderes als zu behaupten, dass unsere Vermutung zu 99% stimme. Über die Wahrscheinlichkeit, dass eine Hypothese stimmt (oder nicht) können wir mit den Methoden der klassischen Statistik keine Aussage machen!

#### Beispiel

In unserem Beispiel liegt der $z$-Wert knapp über dem kritischen Wert von 1,65. Wir können also die Nullhypothese ablehnen und unsere Alternativhypothese annehmen. Unsere statistische Untersuchung hat gezeigt, dass die Eissporthalle an bewölkten Tagen besser besucht ist als an sonnigen (und zwar mit Signifikanzniveau $\alpha=0,05$).

Gut, dass wir eine gerichtete Alternativhypothese aufgestellt haben. Hätten wir nur vermutet, dass sich die Besuchszahlen je nach Wetter unterscheiden (ohne Angabe einer Richtung), dann wäre der kritische Wert nicht erreicht worden und wir hätten die Nullhypothese beibehalten müssen. Hinterher die Hypothesen anzupassen ist natürlich nicht zulässig!

```{r}
rtip("R hat in der Grundversion keinen dezidierten Befehl für einen $z$-Test. Mit der Funktion `qnorm()` können kritische Werte jedoch einfach bestimmt werden.")
```

## Die `r symbol_header("t")`-Verteilung {#t-verteilung}

Wenn die Standardabweichung $\sigma$ eines Merkmals in der Grundgesamtheit *unbekannt* ist, kann sie durch die Standardabweichung $s$ der Stichprobe geschätzt werden (s. [Sitzung 4](schätzstatistik-1.html)). Dann ist die Stichprobenverteilung für $\bar{x}$ jedoch nicht mehr normalverteilt, sondern sie folgt einer $t$-Verteilung.

Im Gegensatz zur Standardnormalverteilung (die wir für den $z$-Test benutzen) gibt es aber nicht nur eine $t$-Verteilung, sondern die Form der $t$-Verteilung hängt von so genannten Freiheitsgraden (engl. *degrees of freedom*) ab. Mit steigender Zahl der Freiheitsgrade nähert sich die $t$-Verteilung einer Standardnormalverteilung an (s. Abbildung \@ref(fig:tdf)).

```{r tdf, cache=T, fig.cap="$t$-Verteilungen mit verschiedenen Freiheitsgraden"}
t3 <- function(x){dt(x,3)}
t6 <- function(x){dt(x,6)}
t12 <- function(x){dt(x,12)}
ggplot(data.frame(x=c(-4, 4)), aes(x)) +
  stat_function(n=250,fun=t3, aes(color="red")) +
  stat_function(n=250,fun=t6, aes(color="orange")) +
  stat_function(n=250,fun=t12, aes(color="green")) +
  stat_function(n=250,fun=dnorm, aes(color="blue"))+
  scale_x_continuous(NULL, breaks=0, expand = c(0,0)) +
  scale_color_manual(NULL,values = c("red"=emo_red, "orange"=orange, "green"=green, "blue"=goethe_blue), breaks=c("red", "orange", "green", "blue"), labels=expression(t[3],t[6],t[12],z))+  
  scale_y_continuous(NULL, expand = c(0,0), limits=c(0,dnorm(0)*1.05))+
  theme_goethe()
```


### Freiheitsgrade

In Anlehnung an @bortz kürzen wir Freiheitsgrade mit $\mathit{df}$ ab. Dort findet sich auch eine brauchbare Erklärung dieses Phänomens:

> Die Freiheitsgrade, welche mit einem Kennwert verbunden sind, entsprechen der Anzahl der Werte, die bei seiner Berechnung frei variieren können. Der Mittelwert $\bar{x}$ besitzt beispielsweise $n$ Freiheitsgrade, weil es keinerlei Bedingung gibt, der die $n$ Werte genügen müssen. Dies ist für die Varianz $s^2=\mathit{QS}/(n-1)$ nicht der Fall. Nur $n-1$ Abweichungen, welche in die Berechnung der Quadratsumme $\mathit{QS}=\sum_i(x_i-\bar{x})^2$ eingehen, können frei variieren. [D]ie Summe der Abweichungen von ihrem Mittelwert [ist] null, d.h. $\sum_i(x_i-\bar{x})=0$. Von $n$ Abweichungen können deshalb nur $n - 1$ frei variieren. Ergeben sich beispielsweise bei einer Stichprobe aus drei Werten die Abweichungen $x_1 - \bar{x} = -4$ und $x_2 - \bar{x} = 0$, muss zwangsläufig $x_3 -\bar{x} = 4$ sein, damit die Summe aller Abweichungen null ergibt. Bei der Varianzberechnung ist eine der $n$ Abweichungen festgelegt, d.h. die Varianz hat nur $n - 1$ Freiheitsgrade. Man schreibt die Stichprobenvarianz deshalb gelegentlich auch als $s^2 = \mathit{QS}/\mathit{df}$. Da die Varianz mit $n - 1$ Freiheitsgraden verbunden ist, gilt dies auch für die Standardabweichung $s$. [@bortz: 121]


## 1-Stichproben-`r symbol_header("t")`-Test {#t-test}

Der 1-Stichproben-$t$-Test vergleicht (wie der $z$-Test) die Werte einer Stichprobe mit der Grundgesamtheit. Das Vorgehen ist dabei analog zum $z$-Test, mit dem einzigen Unterschied, dass eine $t$-Verteilung mit $(n-1)$ Freiheitsgraden herangezogen wird.

Wir besprechen den 1-Stichproben-$t$-Test direkt an einem Beispiel:

Beim Frankfurter Amt für Wohnungswesen betrage die durchschnittliche Bearbeitungsdauer von Anträgen auf Wohngeld 30,2 Tage und sei normalverteilt. Wir vermuten, dass die Bearbeitungszeit zu Anfang des Wintersemesters höher ist als im Jahresdurchschnitt und planen eine zufällige Stichprobe von 12 Anträgen mit Einreichungsdatum im Oktober.

### Test wählen und Voraussetzungen prüfen

Um den 1-Stichproben-$t$-Test durzuführen müssen folgende Voraussetzungen erfüllt sein:

- Das Ziel der Untersuchung ist es, eine statistisch signifikante Abweichung des Mittelwerts einer Stichprobe im Vergleich zu einer Grundgesamtheit festzustellen.
- Das zu untersuchende Merkmal ist in der Grundgesamtheit normalverteilt.
- Das arithmetische Mittel ($\mu$) des Merkmals in der Grundgesamtheit ist bekannt. (Im Gegensatz zum $z$-Test ist $\sigma$ hier unbekannt!)
- Der Test erfolgt anhand einer reinen Zufallsstichprobe.

#### Beispiel

In unserem Beispiel (Bearbeitungszeit Wohngeldanträge) sind diese Bedingungen erfüllt und wir können einen 1-Stichproben-$t$-Test durchführen.

### Hypothesen formulieren

Die Hypothesen werden genauso wie beim $z$-Test formuliert:

#### Nullhypothese

\[
H_0 : \mu = \mu_0
(\#eq:th0)
\]

#### Alternativhypothese

\[
H_1 : \mu \neq \mu_0 \quad \textrm{(ungerichtet)}
(\#eq:th1u)
\]

oder

\[
H_1 : \mu < \mu_0 \quad \textrm{(abwärts gerichtet)}
(\#eq:th1l)
\]

oder

\[
H_1 : \mu > \mu_0 \quad \textrm{(aufwärts gerichtet)}
(\#eq:th1g)
\]

#### Beispiel 

In unserem Beispiel geben wir eine Richtung vor, denn wir vermuten ja, dass die Bearbeitungsdauer zu Semesteranfang *höher* ist. Wir schreiben also:

\[\begin{aligned}
H_0: \mu = 30{,}2\\
H_1: \mu>30{,}2
\end{aligned}\]

### Signifikanzniveau entscheiden

Wie beim $z$-Test entscheidet das Signifikanzniveau $\alpha$, wie *unwahrscheinlich* eine Prüfgröße unter Annahme der Nullhypothese sein muss, damit wir die Nullhypothese ablehnen können (und damit unsere Annahme bestätigen).

Übliche Werte für das Signifikanzniveau sind auch beim $t$-Test $\alpha=0{,}05$ oder $\alpha=0{,}01$.

#### Beispiel

Ein Irrtum zugunsten der Alternativhypothese hat bei unserer Untersuchung keine gravierenden Folgen. Angenommen, wir wollen uns in der Analyse trotzdem ganz sicher sein. Dann entscheiden wir uns für das Signifikanzniveau $\alpha=0{,}01$.

### Ablehnungsbereich bestimmen

Genau wie beim $z$-Test bestimmt das Signifikanzniveau $\alpha$ den *Ablehnungsbereich* -- also den Bereich für die zu errechnende Prüfgröße $t$, in dem die Nullhypothese abgelehnt würde.

Der Ablehnungsbereich für die ungerichtete Alternativhypothese ist $\frac{\alpha}{2}$ auf beiden Seiten. Die kritischen Werte sind dann die Schwellen des Ablehnungsbereich auf beiden Seiten:

$$
t \leq t_{\mathit{df};\alpha/2} \quad \textrm{und} \quad t \geq t_{\mathit{df};(1-\alpha/2)} \quad \textrm{für} \quad H_1: \mu \neq \mu_0
(\#eq:tkritneq)
$$

Bei den gerichteten Alternativhypothesen ist der Ablehnungsbereich jeweils nur auf einer Seite. Die kritischen Werte ergeben sich aus:

$$
t \leq t_{\mathit{df};\alpha} \quad \textrm{für} \quad H_1: \mu < \mu_0
(\#eq:kritless)
$$

$$
t \geq t_{\mathit{df};(1-\alpha)} \quad \textrm{für} \quad H_1: \mu > \mu_0
(\#eq:kritgreater)
$$

Die kritischen Werte für $t$ bei gegebenem Freiheitsgrad $(n-1)$ und Flächenabschnitt lassen sich aus der [Tabelle für $t$-Vereilungen](#tabelle-t) ablesen. Dabei ist zu beachten, dass aufgrund der Symmetrie die Werte für Flächenanteile unter 50% nicht in der Tabelle verzeichnet sind. Es gilt die Formel:

$$
P(-t_\mathit{df})=1-P(t_\mathit{df})
(\#eq:negt)
$$

So ist zum Beispiel der Wert für $t_{5;1\%}=-t_{5;99\%}=-3{,}365$.

#### Beispiel

In unserem Beispiel haben wir eine gerichtete Alternativhypothese nach oben und ein Signifikanzniveau von $\alpha=0{,}01$ verwendet. Wir haben uns zudem für eine Stichprobengröße von $n=12$ entschieden, woraus der Freiheitsgrad $\mathit{df}=n-1=11$ resultiert.

Der kritische Wert (bei dessen Überschreitung wir die Nullhypothese ablehnen und unsere Vermutung bestätigt sehen) lautet also:

$$
\begin{aligned}
t &\geq t_{\mathit{df};(1-\alpha)}\\[4pt]
t &\geq t_{11;99\%}\\[4pt]
t &\geq 2,718
\end{aligned}
$$

Graphisch ist der Ablehnungsbereich für unser Beispiel in Abbildung \@ref(fig:tkrit) dargestellt.

```{r tkrit, cache=T, fig.cap="Ablehnungsbereich bei gerichteter Alternativhypothese nach oben, $n=12$ und $\\alpha=0{,}01$"}
t11 <- function(x){dt(x,11)}

ggplot(data.frame(x=c(-4, 4)), aes(x)) +
  stat_function(n=250,fun=t11, fill=light_blue, geom="area",xlim=c(qt(0.99,11),4))+
  stat_function(n=250,fun=t11, aes(color="blue")) +
  scale_x_continuous(NULL, breaks=c(0,qt(0.99,11)), labels=expression(0,t["11;99%"]==2.718), expand = c(0,0)) +
  scale_color_manual(NULL,values = c("blue"=goethe_blue), breaks=c("blue"), labels=expression(t[11]))+  
  scale_y_continuous(NULL, expand = c(0,0), limits=c(0,dnorm(0)*1.05))+
  theme_goethe()
```

### Prüfgröße berechnen

Die Formel für die Berechnung der Prüfgröße $t$ im 1-Stichproben-$t$-Test lautet ganz ähnlich wie die für die Prüfgröße $z$ im $z$-Test -- mit dem Unterschied, dass statt der (hier unbekannten) Standardabweichung der Grundgesamtheit ($\sigma$) die Standardabweichung der Stichprobe ($s$) eingesetzt wird:

\[
t=\sqrt{n}\cdot\frac{\bar{x}-\mu_0}{s}
(\#eq:t)
\]

Zum direkten Vergleich noch einmal die Prüfgröße im $z$-Test:

\[
z=\sqrt{n}\cdot\frac{\bar{x}-\mu_0}{\sigma}
\]

#### Beispiel (ausführlich)

Wir erheben die Stichprobe von $n=12$ Anträgen im Oktober und erhalten folgende Werte für die Bearbeitungsdauer (in Tagen):

\[
45\quad41\quad37\quad41\quad35\quad44\quad34\quad44\quad38\quad41\quad39\quad36
\]

Wir errechnen zunächst das arithmetische Mittel $\bar{x}$ (s. [Sitzung 2](#arithmetisches-mittel)):

\[\begin{aligned}
\bar{x}&=\frac{\sum\limits_{i=1}^nx_i}{n}\\[5pt]
&=\frac{45+41+37+41+35+44+34+44+38+41+39+36}{12}\\
&\approx 39{,}58
\end{aligned}\]

Damit können wir die Standardabweichung $s$ berechnen:

\[\begin{aligned}
s&=\sqrt{\frac{\sum\limits_{i=1}^n(x_i-\bar{x})^2}{n-1}}\\[6pt]
&\approx\sqrt{\frac{29{,}38+2{,}02+6{,}66+2{,}02+20{,}98+19{,}54+31{,}14+19{,}54+2{,}5+2{,}02+0{,}34+12{,}82}{11}}\\
&\approx 3{,}67
\end{aligned}\]

Schließlich setzen wir diese Werte in die Formel für die Prüfgröße $t$ \@ref(eq:t) ein:

\[\begin{aligned}
t&=\sqrt{n}\cdot\frac{\bar{x}-\mu_0}{s}\\[6pt]
&\approx\sqrt{12}\cdot\frac{39{,}58-30{,}2}{3{,}67}\\
&\approx8{,}854
\end{aligned}\]

### Ergebnis interpretieren

Genau wie beim $z$-Test kommt es darauf an, ob die Prüfgröße in den Ablehnungsbereich fällt (ob der kritische Wert also unter- bzw. überschritten wird). Wenn dies der Fall ist, können wir die Nullhypothese ablehnen (und damit unsere Alternativhypothese bestätigen). Wenn nicht, müssen wir die Nullhypothese beibehalten.

#### Beispiel

In unserem Beispiel liegt der $t$-Wert deutlich über dem kritischen Wert von 2,718. Wir können also die Nullhypothese ablehnen und unsere Alternativhypothese annehmen. Unsere statistische Untersuchung hat gezeigt, dass die Bearbeitungsdauer von Anträgen, die im Oktober eingehen, länger ist als im Jahresdurchschnitt (und zwar mit Signifikanzniveau $\alpha=0,01$).

```{r}
rtip("In R kann ein $t$-Test mit dem Befehl `t.test()` durchgeführt werden. Neben der Prüfgröße $t$ gibt der Befehl einen $p$-Wert aus -- ist dieser kleiner als $\\alpha$, so liegt eine signifikante Abweichung vor.")
```

## Tipps zur Vertiefung {-}

- YouTube-Kanal "Kurzes Tutorium Statistik": [p-Wert, Nullhypothese, Signifikanzniveau - die Idee erklärt](https://www.youtube.com/watch?v=gSyGVDMcg-U)
- YouTube-Kanal "Benedict K": [p-Wert: einseitiger und beidseitiger Hypothesentest / Signifikanztest - erklärt](https://www.youtube.com/watch?v=sNlxShUM4io)
- YouTube-Kanal "Kurzes Tutorium Statistik": [Einstichproben t-Test](https://www.youtube.com/watch?v=rbYg5IsOYaM)
- Kapitel 7, 8.1 in @bortz
- Kapitel 8.2.2.1 und 8.2.3 in @delange 
- Kapitel 5.5.2 in @bahrenberg
- Kapitel 9 in @klemm
- *Englisch:* Kapitel 9.1 in @burt

<!--chapter:end:05_Grundlagen_der_Teststatistik.Rmd-->

## Übungsaufgaben {-}

\nopagebreak

`r naechste("aufgabe", T) #1`

Sie interessieren sich für die durchschnittliche Haushaltsgröße in Frankfurt im europäischen Vergleich. In der EU sei die durchschnittliche Haushaltsgröße 2,30 Personen mit einer Standardabweichung von 1,42.

Sie vermuten, dass Frankfurter Haushalte sich in ihrer Größe vom europäischen Durchschnitt unterscheiden, können aber nicht sagen, in welche Richtung.

a) Welche Stichprobengröße ist für einen $z$-Test in diesem Fall nötig und warum?
b) Formulieren Sie Null- und Alternativhypothese.
c) Sie entscheiden Sich für ein Signifikanzniveau von $\alpha=0{,}05$. Notieren Sie die kritischen Werte.
d) Eine Stichprobe von 40 Frankfurter Haushalten ergibt eine durchschnittliche Größe von 1,82. Berechnen Sie die Prüfgröße $z$.
e) Wie bewerten Sie das Ergebnis?


`r naechste("aufgabe") #2`

Bestimmen Sie die folgenden kritischen Werte:

a) $t_{4;0{,}5\%}$
a) $t_{19;0{,}1\%}$
a) $t_{7;2{,}5\%}$
a) $t_{13;5\%}$
a) $t_{11;97{,}5\%}$
a) $t_{3;95\%}$
a) $t_{6;99{,}5\%}$
a) $t_{16;99{,}9\%}$
a) $t_{5;99\%}$
a) $t_{20;1\%}$

`r naechste("aufgabe") #3`

Die Prüfungsergebnisse für eine Klausur im Geographiestudium seien normalverteilt mit einer mittleren Punktzahl von 61,5 und einer Standardabweichung von 10,3. Sie vermuten, dass berufstätige Studierende im Durchschnitt schlechter abschneiden, weil ihnen die Vorbereitungszeit fehlt. Eine Zufallsstichprobe berufstätiger Studierender ergibt die Prüfungsergebnisse: `42 78 46 65`

Prüfen Sie Ihre Vermutung. Begründen Sie die Wahl des Tests und des Signifikanzniveaus.

`r naechste("aufgabe") #4`

Sie vermuten, dass Angestellte mit Migrationshintergrund in einem bestimmten Betrieb weniger als das Durchschnittsgehalt verdienen. Die Personalabteilung bestätigt Ihnen gegenüber die annähernde Normalverteilung der Bruttogehälter mit Mittelwert $\mu=3042{,}43$ (in EUR). Sie planen, das Bruttogehalt von sechs zufälligen Angestellten mit Migrationshintergrund direkt zu ermitteln.\nopagebreak 
  
a) Welchen Test führen Sie durch?
a) Formulieren Sie die Hypothesen.
b) Bestimmen Sie den kritischen Wert bei Signifikanzniveau $\alpha=0{,}01$.

`r naechste("aufgabe") #5`

*(Fortführung von Aufgabe 4)*

Sie ermitteln die folgenden Werte (in EUR):
\[
2927{,}35\quad2930{,}68\quad2903{,}58\quad3032{,}59\quad3013{,}37\quad2979{,}4
\]

a) Berechnen Sie die Prüfgröße.
b) Welche Schlüsse ziehen Sie aus der Untersuchung?

`r naechste("aufgabe") #6`

In Ermberg ist die Verteilung der Mietpreise für Ladenflächen pro Quadratmeter (in €) annähernd normalverteilt mit Mittelwert 11,8 und Varianz 5,2.

Die Baudezernentin sagt, dass die Ladenmieten im Neubaugebiet Auwiese deutlich günstiger seien als im Gemeindedurchschnitt. Um die Behauptung zu überprüfen, erheben Sie die folgende Zufallsstichprobe von Ladenmieten im Neubaugebiet (pro m² in €):

```{r}
set.seed(134323)
rnorm(5, 10, sqrt(5.2)) %>%
  round(2) -> preise
```

$$8{,}54\quad7{,}16\quad14{,}47\quad11{,}84\quad10{,}27$$

Prüfen Sie die Behauptung. Schließen Sie einen Fehler 1. Art zu 95% aus.

`r naechste("aufgabe") #7`

In einem landwirtschaftlichen Großbetrieb wird ein neues Düngemittel für Zuckerrüben getestet. Zunächst wird es nur auf sechs zufällig ausgewählten Feldern (von 60) eingesetzt.

Der durchschnittliche Ertrag aller 60 Felder beträgt 69 Tonnen pro Hektar (t/ha). Für die sechs Felder mit dem neuen Düngemittel wurden folgende Ertragswerte erhoben:

```{r}
tibble(
  Feld = 1:6,
  `Ertrag in t/ha` = c(93, 74, 65, 69, 89, 85),
) -> ex_05_7

tabelle(ex_05_7, full_width = F)
```

Prüfen Sie, ob der Einsatz des neuen Düngemittels zu einem signifikanten Unterschied im Ertrag der Felder geführt hat. Akzeptieren Sie in Ihrer Analyse 5% als Wahrscheinlichkeit für einen Fehler 1. Art.

<!--chapter:end:05_Aufgaben.Rmd-->

# Formelsammlung und Wertetabellen {.unnumbered #formeln}

```{r}
target <- knitr::opts_knit$get("rmarkdown.pandoc.to")
source_formeln <- sprintf("formelsammlung/formelsammlung_%s.Rmd",
                          knitr::opts_knit$get("rmarkdown.pandoc.to"))
```

```{r formelsammlung, child = source_formeln}
```

<!--chapter:end:Formelsammlung.Rmd-->

# Lösungen der Übungsaufgaben {-}

```{r}
counter <- list(sitzung = 0, lösung = 0)
knitr::opts_chunk$set(fig.pos = "H")
```

## Sitzung 1 {-}

`r naechste("lösung", T)`

-- keine Musterlösung --

`r naechste("lösung")`

-- keine Musterlösungen --

`r naechste("lösung")`

```{r}
library(tidyverse)
tribble(
  ~Variable, ~Skalenniveau, ~Variablentyp, ~Anmerkungen,
  "Lebensalter in Jahren", "Verhältnisskala",
    "diskret", "ganze Zahlen vorausgesetzt",
  "Regenmenge in mm", "Verhältnisskala", "stetig", "",
  "Güteklasse", "Ordinalskala", "qualitativ",  "",
  "Passagieraufkommen", "Verhältnisskala", "diskret", "",
  "Baujahr", "Intervallskala", "diskret", "",
  "Geschwindigkeit in km/h", "Verhältnisskala", "stetig",
    "bei ganzzahligen Werten: diskret",
  "Sozialstatus (Unter-, Mittel und Oberschicht)",
    "Ordinalskala", "qualitativ", "",
  "Temperatur in °F", "Intervallskala", "stetig", "",
  "Fläche eines Bundeslands in km²", "Verhältnisskala",
    "stetig", "",
  "Temperatur in K", "Verhältnisskala",
    "stetig", "0 K ist ein natürlicher Nullpunkt",
  "Einwohnerzahl", "Verhältnisskala", "diskret", "",
  "Pegelstand", "Intervallskala", "stetig", "willkürlicher Nullpunkt",
  "Staatsangehörigkeit", "Nominalskala", "qualitativ", "",
  "Interesse an Statistik (gering bis hoch)", "Ordinalskala", "qualitativ", "",
  "Klausurnote", "Ordinalskala (Intervall- auch vertretbar)", "qualitativ",
    "wird jedoch oft metrisch verwendet",
  "Bodentyp", "Nominalskala", "qualitativ", "",
  "Entfernung zum Stadtzentrum in km", "Verhältnisskala", "stetig", "",
  "Körpergröße", "Verhältnisskala", "stetig", "",
  "Kleidergröße (S bis XXL)", "Ordinalskala", "qualitativ", "",
  "Monatliches Nettoeinkommen", "Verhältnisskala", "stetig",
    "oder diskret für Cent-Beträge") %>%
  bind_cols(` ` = paste0(letters[1:20], abcparen()), .) %>%
  tabelle(hold = T)
```

`r naechste("lösung")`

#### a)

Die Werte sind im Bereich zwischen 3 und 210 Stunden. Eine Klassengröße von 25 Stunden bietet sich an, es sind jedoch auch andere Größen denkbar. Da die Variable diskret zu sein scheint, können die Klassengrenzen als ganze Zahlen angegeben werden.

```{r}

klassieren(boot::aircondit7$hours,
           breaks = seq(0, 225, 25),
           unit = "h") -> tbbl
tbbl %>%
  transmute(`Wert $x_i$` = x,
            `Häufigkeit $f_i$` = f) %>%
  tabelle(hold = T, full_width = F)
```

#### b)

Das Resultat sollte je nach gewählter Klassengröße in etwa so aussehen:

```{r}
boot::aircondit7 %>%
  tibble() %>%
  ggplot(aes(x = hours)) +
    geom_histogram(breaks = seq(0, 225, 25), closed = "right") +
    scale_x_continuous("Häufigkeit", breaks = seq(0, 225, 25)) +
    scale_y_continuous("Lebensdauer in Stunden", breaks = seq(0, 9, 1)) +
    theme_goethe()
```

#### c)

Die Verteilung ist unregelmäßig abfallend.

`r naechste("lösung")`

Sind die folgenden Aussagen wahr oder unwahr?

a) wahr
a) wahr
a) unwahr
a) wahr
a) unwahr
a) unwahr
a) wahr
a) wahr
a) unwahr
a) unwahr
a) wahr
a) wahr
a) unwahr
a) unwahr
a) unwahr
a) wahr
a) wahr
a) wahr

<!--chapter:end:01_Loesungen.Rmd-->

## Sitzung 2 {-}

`r naechste("lösung", T)`

#### a)

```{r}
set.seed(4525)
runif(6, 10, 80) %>%
  round() %>%
  lectuR::get_mean() -> mean_a

tribble(
  ~Schritt, ~Lösung,
  "Formel", mean_a$formel,
  "Einsetzen", mean_a$einsetzen,
  "Ergebnis", mean_a$ergebnis
) %>% tabelle(hold = T)
```

#### b)

```{r}
set.seed(4525)
runif(8, -1, 1) %>%
  round(3) %>%
  lectuR::get_mean() -> mean_b

tribble(
  ~Schritt, ~Lösung,
  "Formel", mean_b$formel,
  "Einsetzen", mean_b$einsetzen,
  "Ergebnis", mean_b$ergebnis
) %>% tabelle(hold = T)
```

#### c)

```{r}
set.seed(4525)
runif(10, 600, 1000) %>%
  round(2) %>%
  lectuR::get_mean() -> mean_c
tribble(
  ~Schritt, ~Lösung,
  "Formel", mean_a$formel,
  "Einsetzen", mean_c$einsetzen,
  "Ergebnis", mean_c$ergebnis
) %>% tabelle(hold = T)
```

`r naechste("lösung")`

#### a)

```{r}
set.seed(4525)
runif(6, 10, 80) %>%
  round() -> a
  lectuR::get_var(a) -> var_a
  lectuR::get_sd(a) -> sd_a

tribble(
  ~Schritt, ~Lösung,
  "Varianz: Formel", var_a$formel,
  "Varianz: Einsetzen", var_a$einsetzen,
  "Varianz: Ergebnis", var_a$ergebnis,
  "Standardabweichung: Formel", sd_a$formel,
  "Standardabweichung: Einsetzen", sd_a$einsetzen,
  "Varianz: Ergebnis", sd_a$ergebnis
) %>% tabelle(hold = T)
```

#### b)

```{r}
set.seed(4525)
runif(8, -1, 1) %>%
  round(3) -> b

  lectuR::get_var(b) -> var_b
  lectuR::get_sd(b) -> sd_b

tribble(
  ~Schritt, ~Lösung,
  "Varianz: Formel", var_b$formel,
  "Varianz: Einsetzen", var_b$einsetzen,
  "Varianz: Ergebnis", var_b$ergebnis,
  "Standardabweichung: Formel", sd_b$formel,
  "Standardabweichung: Einsetzen", sd_b$einsetzen,
  "Varianz: Ergebnis", sd_b$ergebnis
) %>% tabelle(hold = T)
```

#### c)

```{r}
set.seed(4525)
runif(10, 600, 1000) %>%
  round(2) -> c
  lectuR::get_var(c) -> var_c
  lectuR::get_sd(c) -> sd_c

tribble(
  ~Schritt, ~Lösung,
  "Varianz: Formel", var_c$formel,
  "Varianz: Einsetzen", var_c$einsetzen,
  "Varianz: Ergebnis", var_c$ergebnis,
  "Standardabweichung: Formel", sd_c$formel,
  "Standardabweichung: Einsetzen", sd_c$einsetzen,
  "Varianz: Ergebnis", sd_c$ergebnis
) %>% tabelle(hold = T)
```


`r naechste("lösung")`

```{r}
xs <- scan("img/2_exercise")
```

#### a)

Die geordnete Liste ist:

```{r}
cat(sort(xs))
```

Für das arithmetische Mittel und die Varianz ist diese Tabelle hilfreich:

```{r}
df <- data.frame(table(xs))
df$xs <- as.numeric(levels(df$xs)[df$xs])
df[, 3] <- df$xs * df$Freq
df[, 4] <- df$xs - mean(xs)
df[, 5] <- (df$xs - mean(xs))^2
df[, 6] <- df$Freq*(df$xs - mean(xs))^2
df[] <- round(df,2)
df[] <- lapply(format(df, decimal.mark=","), as.character)
tabelle(df, hold = T, col.names = c("$x_i$", "$f_i$", "$f_i\\cdot x_i$", "$(x_i-\\bar{x})$", "$(x_i-\\bar{x})^2$", "$f_i\\cdot(x_i-\\bar{x})^2$"))
```

Der häufigste Wert (und damit der Modalwert) ist 2.

Die Stichprobengröße ist ungerade ($n=13$), daher ist der Median: $$x_{(\frac{n+1}{2})} = x_{(7)} = 2$$

Das arithmetische Mittel berechnet sich einfacher mit den Werten aus der Tabelle:

\[\bar{x}={\displaystyle\frac{\sum\limits_{x=1}^nx_i}{n}}=\frac{3+8+6+8+5+6}{13}=\frac{37}{13}\approx2.85\]

#### b)

Die Spannweite ist: $$R=x_{(n)}-x_{(1)}=7-1=6$$

Der Quartilsabstand ist: $$\mathit{IQR}=Q_3-Q_1=4-2=2$$

Für die Varianz bieten sich ebenfalls die Tabellenwerte an: $$s^2=\frac{\sum\limits_{x=1}^n(x_i-\bar{x})^2}{n-1}\approx\frac{10,22+ 2,86+ 0,05+ 2,66+ 4,64+17,25}{13-1}=\frac{37,68}{12}=3.14$$

Schließlich ist die Standardabweichung: $$s=\sqrt{s^2}\approx\sqrt{3,14}\approx1,77$$

#### c)

Da der untere Angelpunkt und der Median zusammenfallen, sieht der Boxplot etwas ungewöhnlich aus:

```{r, fig.height=6}
boxplot(xs)
```

`r naechste("lösung")`

#### a)

Für den Quartilsabstand brauchen wir den Klassendurchschnitt und kumulative Häufigkeiten:


```{r}
lectuR::klassieren(DAAG::fossum$totlngth,
                   "cm",
                   seq(75, 97.5, 2.5)) -> tbbl

tbbl %>%
  select(x, k, f, fkum) %>%
  tabelle(hold = T, col.names = c("$x$", "$k_i$", "$f_i$", "$f_{kum}$"))
```

Bei $n=43$ ist $Q_1=\frac{x_{(11)}+x_{(12)}}{2}$ und $Q_3=\frac{x_{(32)}+x_{(33)}}{2}$.

Aus der Tabelle mit kumulativen Häufigkeiten können wir $Q_1=86{,}25$ und $Q_3=91{,}25$ ablesen.

Der Quartilsabstand beträgt dann

\[\begin{aligned}
\mathit{IQR}&=Q_3-Q_1\\
            &=91{,}25-86{,}25\\
            &=5
\end{aligned}\]

#### b)

Um die Berechnung des arithmetischen Mittels zu vereinfachen berechnen wir den Klassendurchschnitt und Zwischensummen:

```{r}
tbbl %>%
  select(x, k, f, fkum, prod) %>%
  tabelle(hold = T,
          col.names = c("$x$", "$k_i$", "$f_i$",
                        "$f_{kum}$", "$f_i \\cdot k_i$"))
```

Die Summen für das arithmetische Mittel entnehmen wir dann einfach der letzten Spalte:

\[\begin{aligned}
  \bar{x}&=\frac{\sum\limits_{i=1}^nx_i}{n} \\
         &=\frac{76{,}25+ 243{,}75+ 418{,}75+ 603{,}75+1242{,}50+ 821{,}25+ 187{,}50+ 192{,}50}{43} \\
         &=\frac{3786{,}25}{43} \\
         &\approx88{,}05
\end{aligned}\]

#### c)

Für die Varianz erweitern wir die Tabelle:

```{r}
tbbl %>%
  select(x, k, f, diff, diffsq, prodsq) %>%
  tabelle(hold = T, col.names = c("$x_i$", "$k_i$", "$f_i$",
                                  "$(k_i - \\bar{x})$", "$(k_i - \\bar{x})^2$",
                                  "$f_i \\cdot (k_i - \\bar{x})^2$"))
```

Die Varianz beträgt:

\[\begin{aligned}
  s^2&=\frac{\sum\limits_{i=1}^{n}(x_{i}-\bar{x})^2}{n-1} \\
     &=\frac{139{,}24+138{,}72+ 92{,}45+ 22{,}68+  6{,}86+ 92{,}16+ 64{,}98+134{,}48}{43-1}\\
     &=\frac{691{,}57}{42}\\
     &\approx{16{,}47}
\end{aligned}\]

#### d)

Somit beträgt die Standardabweichung 

\[\begin{aligned}
  s&=\sqrt{s^2}\\
   &\approx\sqrt{16{,}47}\\
   &\approx4{,}06
\end{aligned}\]

`r naechste("lösung")`

#### a)

```{r}
set.seed(1616)
ziegelei <- round(rnorm(6,80,10))
moebellager <- round(rnorm(6,70,18))
mean_ziegelei <- get_mean(ziegelei)
mean_moebellager <- get_mean(moebellager, "y")

tribble(
  ~Schritt, ~Lösung,
  "Formel", lectuR::get_mean()$formel,
  "Einsetzen", mean_ziegelei$einsetzen,
  "Ergebnis", mean_ziegelei$ergebnis,
  "Einsetzen", mean_moebellager$einsetzen,
  "Ergebnis", mean_moebellager$ergebnis,
  "Antwortsatz", sprintf("%s weist im Mittel die größere Passant\\*innenzahl auf.",
                         ifelse(mean_moebellager$raw > mean_ziegelei$raw,
                                "Das Möbellager", "Die Ziegelei"))
) %>% tabelle(hold = T)
```

#### b)

```{r}
iqr_ziegellager <- lectuR::get_iqr(ziegelei, T)
iqr_moebellager <- lectuR::get_iqr(moebellager, T, "y")

tribble(
  ~Schritt, ~Lösung,
  "Formel", lectuR::get_iqr()$formel,
  "Einsetzen", iqr_ziegellager$einsetzen,
  "Ergebnis", iqr_ziegellager$ergebnis,
  "Einsetzen", iqr_moebellager$einsetzen,
  "Ergebnis", iqr_moebellager$ergebnis,
  "Antwortsatz", sprintf(
     "%s hat den größeren Quartilsabstand für die Passant\\*innenzahl.",
     ifelse(iqr_moebellager$raw > iqr_ziegellager$raw,
            "Das Möbellager", "Die Ziegelei"))) %>%
  tabelle(hold = T)
```

`r naechste("lösung")`

#### a)

Es gibt eine Hierarchie der Werte (Ordinal-), sinnvolle Abstände (Intervall-) und einen sinnvollen Nullpunkt (Verhältnis-). Deshalb sind die angegebenen Werte als verhältnisskaliert zu verstehen.

#### b)

Klassen könnten z.&nbsp;B. wie in der folgenden Tabelle gewählt werden. Um die Berechnung des arithmetischen Mittels zu vereinfachen berechnen wir gleich den Klassendurchschnitt und Zwischensummen:

```{r}

tribble(
  ~Jahr, ~`Niederschlag (mm)`,
  1970,	384.52,
  1971,	493.65,
  1972,	364.65,
  1973,	661.32,
  1974,	785.27,
  1975,	603.45,
  1976,	527.75,
  1977,	471.81,
  1978,	525.65,
  1979,	455.64,
  1980,	433.01,
  1981,	535.12,
  1982,	421.36,
  1983,	499.29,
  1984,	555.21,
  1985,	398.88,
  1986,	391.96,
  1987,	453.41,
  1988,	459.84,
  1989,	483.78
) -> data

data$`Niederschlag (mm)` %>%
  lectuR::klassieren("mm") -> tbbl

tbbl %>%
  select(x, k, f, fkum, prod) %>%
  tabelle(hold = T, col.names = c("$x$", "$k_i$", "$f_i$", "$f_{kum}$", "$f_i \\cdot k_i$"))
```

#### c)

Der Modalwert der so klassierten Stichprobe ist die Klasse von 400 bis unter 500 mm und kann auch mit dem Klassenmittelwert 450 mm angegeben werden.

#### d)

Bei $n=20$ ist $Q_1=\frac{x_{(5)}+x_{(6)}}{2}$ und $Q_3=\frac{x_{(15)}+x_{(16)}}{2}$.

Aus einer geordneten Liste könnten wir also 

\[\begin{aligned}
Q_1&=\frac{x_{(5)}+x_{(6)}}{2}\\
   &=\frac{421{,}36+433{,}01}{2}\\
   &\approx427{,}19
\end{aligned}\]

und

\[\begin{aligned}
Q_3&=\frac{x_{(15)}+x_{(16)}}{2}\\
   &=\frac{527{,}75+235{,}12}{2}\\
   &\approx531{,}44
\end{aligned}\]

bestimmen.

Wenn uns nur die klassierte Verteilung zur Verfügung steht oder wenn der Datensatz besonders unübersichtlich ist, ist es auch legitim, aus der kumulativen Häufigkeit $Q_1=450$ und $Q_3=550$ für die klassierte Verteilung abzulesen.

Je nachdem beträgt der Quartilsabstand $\mathit{IQR}=Q_3-Q_1$ dann 104,24 oder 100 mm.

#### e)

Die Summen für das arithmetische Mittel entnehmen wir der letzten Spalte der Wertetabelle:

\[\begin{aligned}
  \bar{x}&=\frac{\sum\limits_{i=1}^nx_i}{n} \\
         &=\frac{1400+4050+2200+1300+750}{20} \\
         &=\frac{9700}{20} \\
         &\approx485
\end{aligned}\]

#### f)

Für die Standardabweichung erweitern wir die Tabelle:

```{r}
tbbl %>%
  select(x, k, f, diff, diffsq, prodsq) %>%
  tabelle(hold = T, col.names = c("$x_i$", "$k_i$", "$f_i$", "$(k_i - \\bar{x})$", "$(k_i - \\bar{x})^2$", "$f_i \\cdot (k_i - \\bar{x})^2$"))
```

Die Varianz beträgt:

\[\begin{aligned}
  s^2&=\frac{\sum\limits_{i=1}^{n}(x_{i}-\bar{x})^2}{n-1} \\
     &=\frac{72900+11025+16900+54450+70225}{20-1}\\
     &=\frac{225500}{19}\\
     &\approx{11868{,}42}
\end{aligned}\]

Somit beträgt die Standardabweichung 

\[\begin{aligned}
  s&=\sqrt{s^2}\\
   &\approx\sqrt{11868{,}42}\\
   &\approx108{,}94
\end{aligned}\]

#### g)

Auch der Boxplot lässt sich anhand der klassierten Werte zeichnen:

```{r solve_2_6_g, fig.height=5, fig.width=3, out.width='35%'}
purrr::map2(tbbl$f, tbbl$k, function(f, k){
   rep(k, f)
}) %>%
  unlist() %>%
  tibble(y = .) %>%
  ggplot(aes(y=y)) +
    stat_boxplot(geom = 'errorbar', width=0.5) +
    geom_boxplot(fill = mustard_yellow) +
    scale_x_continuous(limits = c(-0.6,0.4), breaks = NULL) +
    scale_y_continuous(NULL) +
    theme_goethe() +
    theme(axis.line = element_blank(),
          panel.border = element_rect(color = "black",
                                      fill = NA,
                                      size = 1))
```

<!--chapter:end:02_Loesungen.Rmd-->

## Sitzung 3 {-}

`r naechste("lösung", T)`

#### a)

Zunächst brauchen wir das arithmetische Mittel:

```{r}
m <- get_mean(ex_3_1_a)

tribble(
  ~Schritt, ~Musterlösung,
  "Formel", m$formel,
  "Einsetzen", m$einsetzen,
  "Ergebnis", m$ergebnis,
) %>% tabelle(hold = T)
```

Und die Standardabweichung:

```{r}
s <- get_sd(ex_3_1_a)

tribble(
  ~Schritt, ~Lösung,
  "Formel", s$formel,
  "Einsetzen", s$einsetzen,
  "Ergebnis", s$ergebnis,
) %>% tabelle(hold = T)
```

Dann lässt sich die Formel bestimmen:

```{r}
z <- get_z_trans(sd = s$raw, mean = m$raw)

tribble(
  ~Schritt, ~Musterlösung,
  "Formel", z$formel,
  "Einsetzen", z$general,
) %>% tabelle(hold = T)
```

Und schließlich die einzelnen Werte berechnen. Hier sind die Berechnungen zum Prüfen ausformuliert, das wird in der Klausur nicht für jeden Wert erwartet.

```{r}
map2(ex_3_1_a, seq_along(ex_3_1_a), function(x, i) {
  get_z_trans(sd = s$raw, mean = m$raw, x = x, symbol = i)
}) -> calc

tibble(
  `$x_i$` = ex_3_1_a,
  Berechnung = map_chr(calc, "quick")
) %>%
tabelle(hold = T)
```

#### b)

```{r}
m <- 221.54

sd <- get_sd(variance = 13.02)
rz <- get_z_trans(mean = m, sd = sd$raw)
```

Zunächst die Standardabweichung:

```{r}
tribble(
  ~Schritt, ~Musterlösung,
  "Formel", sd$formel,
  "Einsetzen", sd$einsetzen,
  "Ergebnis", sd$ergebnis,
) %>% tabelle(hold = T)
```

Dann die Formel:

```{r}
tribble(
  ~Schritt, ~Musterlösung,
  "Formel", get_z_trans()$formel,
  "Umformen", rz$formel,
  "Einsetzen", rz$general_reverse,
) %>% tabelle(hold = T)
```

Schließlich die einzelnen Werte:

```{r}
map2(ex_3_1_b, seq_along(ex_3_1_b), function(z, i) {
  get_z_trans(sd = sd$raw, mean = m, z = z, symbol = i)
}) -> calc

tibble(
  `$z_i$` = ex_3_1_b,
  Berechnung = map_chr(calc, "quick_reverse")
) %>%
tabelle(full_width = F, hold = T)
```

`r naechste("lösung")`

```{r}
mu <- 32.2
sigmasq <- 19.36
```

#### a) 

$\sigma$ lässt sich berechnen durch:

```{r}
sigma <- get_sd(var = sigmasq, pop = T)
tribble(
  ~Schritt, ~Lösung,
  "Formel", sigma$formel,
  "Einsetzen", sigma$einsetzen,
  "Lösung", sigma$ergebnis
) %>%
tabelle(hold = T)
```

Dann geht es zunächst darum, die $x$-Werte in $z$-Werte zu transformieren:

```{r}
xs <- ex_3_2_a
z <- get_z_trans(mean = mu, sd = sigma$raw, pop = T)
tribble(
  ~Schritt, ~Lösung,
  "Formel", z$formel,
  "Einsetzen", z$general
) %>% tabelle(align = "lc", hold = T)
```

Durch Einsetzen ergeben sich die folgenden Werte. (So ausführlich muss es in der Klausur nicht sein.)

```{r}
map2(xs, seq_along(xs), function(x, i) {
  get_z_trans(sd = sigma$raw, mean = mu, x = x, symbol = i, pop = T)
}) -> calc

tibble(
  `$x_i$` = xs,
  Berechnung = map_chr(calc, "quick")
) %>%
tabelle(full_width = F, align = "rc", hold = T)
```

Für die positiven $z$-Werte können die Unterschreitungs&shy;wahrscheinlichkeiten direkt in der Wertetabelle nachgeschaut werden. Für negative $z$-Werte gilt die Formel:

\[ P(z\leq -z_p) = 1-P(z \leq z_p) \]

Die Unterschreitungswerte ergeben:

```{r}
map(calc, "raw") %>%
  map(get_p_under) -> ps

tibble(
   `$x_i$` = xs,
   `$z_i$` = map(calc, "raw"),
   Formel = ifelse(map(ps, ~ is.null(.$umformen)),
                   map(ps, "formel"),
                   map(ps, "umformen")),
   Ergebnis = map(ps, "ergebnis"),
   `In Prozent` = map(ps, ~ sprintf("%s%s",
                                    round(.$raw * 100, 2),
                                    percent()))
) %>% tabelle(hold = T)
```

#### b)

```{r}
ex_3_2_b -> ps
```

Es handelt sich um Überschreitungs&shy;wahrscheinlichkeiten, aber aus der Tabelle lassen sich nur Unterschreitungswerte ablesen. Weil die Normalverteilung symmetrisch ist, gilt aber:

\[ P(x>x_p)=1-P(x\leq x_p)\]

So lässt sich jeweils sagen:

```{r}

(1 - ps) %>%
map2(seq_along(ps), get_z_under) %>%
map(function(x) {
  if (is.null(x$umformen)) {
    x$umformen <- x$formel
    x$einsetzen <- ""
  }
  return(x)
}) -> calc

tibble(
  `Überschr. $p_{i}$` = ps,
  `Unterschr. $(1-p_{1})$` = 1 - ps,
  Berechnung = map(calc, "umformen"),
  `....` = map(calc, "einsetzen"),
  Ergebnis = map(calc, "ergebnis")
) %>% tabelle(hold = T)
```

Für die Rücktransformation gilt die Formel:

```{r}
sprintf("$%s$", get_z_trans(z = 0, mean = mu, sd = sigma$raw, pop = T)$formel) %>%
  knitr::asis_output()
```

```{r}
map(calc, "raw") %>%
  map2(seq_along(ps), ~ get_z_trans(z = .x, mean = mu, sd = sigma$raw, symbol = .y)) -> calcz

tibble(
  `$z_i$` = map(calc, "raw"),
  Einsetzen = map(calcz, "einsetzen"),
  `$x_i$` = map(calcz, "ergebnis")
) %>% tabelle(hold = T)
```

#### c)

Die mittleren 95% der Werte liegen zwischen einem unteren Wert $x_{2{,}5\%}$ (der zu 2,5% unterschritten wird) und einem oberen Wert $x_{97{,}5\%}$ (der zu 2,5% überschritten wird).

Der obere $z$-Wert lässt sich leicht finden: $z_{97{,}5\%} \approx 1{,}96$

Durch Symmetrie wissen wir dann auch, dass: $z_{2{,}5\%} \approx -1{,}96$

Nun noch rückwärts transformieren:

```{r}
ober <- get_z_trans(z = 1.96, mean = mu, sd = sigma$raw, pop = T, symbol = "o")
unter <- get_z_trans(z = -1.96, mean = mu, sd = sigma$raw, pop = T, symbol = "u")
tribble(
  ~Schritt, ~Lösung,
  "Formel", get_z_trans(z = 1.96, mean = mu, sd = sigma$raw, pop = T)$formel,
  "Untergrenze: Einsetzen", unter$einsetzen,
  "Untergrenze: Ergebnis",  unter$ergebnis,
  "Obergrenze: Einsetzen",  ober$einsetzen,
  "Obergrenze: Ergebnis",   ober$ergebnis,
  "Antwortsatz",            "Die mittleren 95 Prozent der Werte liegen zwischen %s und %s." %>% sprintf(unter$raw, ober$raw)
) %>% tabelle(hold = T)
```

#### d) 

Es ist immer einfacher, mit Unterschreitungs&shy;wahrscheinlichkeiten zu arbeiten. Zwischen 30 und 40 heißt auch: unter 40, aber nicht unter 30. Formal sieht das so aus:

$$P(30 < x \leq 40) = P(x \leq 40) - P(x \leq 30)$$

Diese Unterschreitungs&shy;wahrscheinlichkeiten bestimmen wir wieder über die $z$-Transformation:

```{r}
zunter <- get_z_trans(x = 30, mean = mu, sd = sigma$raw, pop = T, symbol = "u")
zober  <- get_z_trans(x = 40, mean = mu, sd = sigma$raw, pop = T, symbol = "o")
punter <- get_p_under(zunter$raw)
pober  <- get_p_under(zober$raw)
tribble(
  ~Schritt, ~Lösung,
  "Formel", get_z_trans(pop = T)$formel,
  "Untergrenze: $z$-Wert", zunter$quick,
  "Untergrenze: Unterschr.", punter$ergebnis,
  "Obergrenze: $z$-Wert", zober$quick,
  "Obergrenze: Unterschr.", pober$ergebnis,
  "Intervall", sprintf("$P(30 < x \\leq 40) = P(x \\leq 40) - P(x \\leq 30)$"),
  "Intervall einsetzen", sprintf("$P(30 < x \\leq 40) \\approx P(z \\leq %s) - P(z \\leq %s)$",
                                 pober$fmt, punter$fmt),
  "Intervall Ergebnis", sprintf("$P(30 < x \\leq 40) \\approx %s$",
                                fmt(pober$raw - punter$raw, 4)),
  "Antwortsatz", sprintf(
    "Ein zufälliger Wert der Verteilung liegt mit %s-prozentiger Wahrscheinlichkeit zwischen 30 und 40.",
    round((pober$raw - punter$raw) * 100, 2)
  )
) %>% tabelle(hold = T)
```

`r naechste("lösung")`

#### a)

Siehe b)

#### b)

Die Dichtefunktion mit kritischem Wert sollte in etwa so aussehen:

```{r}
ggplot(data.frame(x = c(2.32, 15.7)), aes(x)) +
    stat_function(fun = function(x) {dnorm(x, 9.01, 2.23)}) +
    geom_vline(xintercept = 10,
               color = goethe_blue,
               linetype = "dashed") +
  scale_y_continuous(expand=c(0,0), breaks=NULL) +
  scale_x_continuous() +
  annotate(geom="blank", x=9.01, y=dnorm(9.01,9.01,2.23)*1.05) +
  xlab("Höchstwasserstand in m") +
  ylab(NULL) +
  theme_goethe()
```

#### c)

$$z_p=\frac{x_p- \mu}{\sigma} = \frac{10-9,01}{2,23}\approx0,44$$

#### d)

$$p=P(z<z_p)\approx P(z<0,44)\approx0,6700$$

Die Wahrscheinlichkeit, dass der Deich unbeschädigt bleibt, beträgt 67%.

`r naechste("lösung")`

#### a)

Die Übertretungswahrscheinlichkeit beträgt:

$$P(z>z_p) = 1- P(z<z_p) \approx 1-0,6700 = 0,3300 = 33\% $$

#### b)

Für $x_p=12$ ergibt sich:

$$ z_p=\frac{x_p- \mu}{\sigma} = \frac{12-9,01}{2,23}\approx1,34 $$

Und für die Übertretungswahrscheinlichkeit:

$$P(z>z_p) = 1- P(z<z_p) \approx 1-0,9099 = 0,0901= 9,01\% $$

#### c)

Wir kennen $P(x < 12)\approx0,9099$ aus Aufgabe 2 b) und $P(x<10)\approx0,6700$ aus Aufgabe 1 d). Also rechnen wir:

$$P(10<x<12) = P(x<12) - P(x<10) \approx 0,9099 - 0,6700 = 0,2399$$

#### d)

Für die Obergrenze soll gelten: $P(x<x_o) = 0,9$. Der Tabelle entnehmen wir $z_o \approx 1,28$. Entsprechend ist $z_u\approx-1,28$.

Die Umkehrung der $z$-Transformation ergibt:

$$\begin{aligned}
x_o&=z_o\cdot\sigma + \mu\approx1,28\cdot2,23 +9,01\approx11,86\\
x_u&=z_u\cdot\sigma + \mu\approx-1,28\cdot2.23 +9.01\approx6,16
\end{aligned}$$

Die mittleren 80% der Werte liegen also zwichen 6,16 und 11,86&nbsp;m.

`r naechste("lösung")`

#### a)

$$p=P(x<x_p)=1-P(x>x_p)=1-\frac{1}{200}=1-0,005=0,995$$

#### b)

$$z_{99,5\%}\approx2,58$$

#### c)

$$x_{99,5\%}=z_{99,5\%}\cdot\sigma + \mu\approx2,58\cdot2,23+9,01\approx14,76$$

Der neue Deich muss 14,76&nbsp;m hoch sein.

`r naechste("lösung")`

#### a)

- $z_p=1$ und $P(z<1)\approx84,13\%$, also $P(z>1)\approx15,87\%$

#### b)

- $z_p=-2$ und $P(z<-2) = 1-P(z<2) \approx 1-0,9772 = 0,0228$
- Es kann also 2,28 Mal in 100 Jahren (oder: in etwa 2 von 100 Jahren, in weniger als 3 von 100 Jahren) mit weniger als 200&nbsp;mm Regen gerechnet werden.

#### c)

- $z_u=-2$ und $P(z<z_u)\approx 0,0228$ (siehe b)
- $z_o=\frac{x_o- \mu}{\sigma}=\frac{550-400}{100}=1,5$ und $P(z<z_o) \approx 0,9332$
- $P(200 < x < 550) = P(x < 550) - P(x<200) \approx 91,04\%$

#### d)

- Gesucht ist $x_p$, für das gilt: $P(x>x_p) = \frac{2}{100}=0,02$
- Daraus folgt: $P(x<x_p) = 0,98$ und $z_p\approx2,05$
- $x_p = 605$

#### e)

- $z_{12,5\%}\approx -1,15$ und $z_{87,5\%}= 1,15$
- Die mittleren 75% liegen zwischen $x_u=285$ und $x_o=515$ mm.

`r naechste("lösung")`

**Für die Ziegelei:**

```{r}
var_ziegelei <- lectuR::get_var(alt=T, ziegelei)
sd_ziegelei <- lectuR::get_sd(alt=T, ziegelei)
tribble(
  ~Schritt, ~Lösung,
  "Varianz: Formel", lectuR::get_var()$formel,
  "Varianz: Einsetzen", var_ziegelei$einsetzen,
  "Varianz: Ergebnis", var_ziegelei$ergebnis,
  "Standardabweichung: Formel", lectuR::get_sd()$formel,
  "Standardabweichung: Ergebnis", sd_ziegelei$ergebnis,
  "Variationskoeffizient: Formel",  "$v=\\frac{s}{|\\bar{x}|}\\cdot100\\%\\quad$",
  "Variationskoeffizient: Einsetzen", sprintf(
     "$v\\approx\\frac{%s}{%s}\\cdot100\\%%$",
     fmt(sd_ziegelei$raw), fmt(mean_ziegelei$raw)
  ),
  "Variationskoeffizient: Ergebnis", sprintf(
    "$v \\approx %s\\%%$",
    lectuR::fmt(sd_ziegelei$raw / mean_ziegelei$raw * 100))
) %>% tabelle(hold = T)
```

**Für das Möbellager:**

```{r}
var_moebellager <- lectuR::get_var(moebellager, alt=T, symbol="y")
sd_moebellager <- lectuR::get_sd(moebellager, alt=T, symbol="y")
tribble(
  ~Schritt, ~Lösung,
  "Varianz: Formel", lectuR::get_var()$formel,
  "Varianz: Einsetzen", var_moebellager$einsetzen,
  "Varianz: Ergebnis", var_moebellager$ergebnis,
  "Standardabweichung: Formel", sd_moebellager$formel,
  "Standardabweichung: Ergebnis", sd_moebellager$ergebnis,
  "Variationskoeffizient: Formel",  "$v=\\frac{s}{|\\bar{x}|}\\cdot100\\%$",
  "Variationskoeffizient: Einsetzen", sprintf(
     "$v\\approx\\frac{%s}{%s}\\cdot100\\%%$",
     fmt(sd_moebellager$raw), fmt(mean_moebellager$raw)
  ),
  "Variationskoeffizient: Ergebnis", sprintf("$v \\approx %s\\%%$",
                                             lectuR::fmt(sd_moebellager$raw/mean_moebellager$raw*100))
) %>% tabelle(hold = T)
```

<!--chapter:end:03_Loesungen.Rmd-->

## Sitzung 4 {-}

`r naechste("lösung", T)`

a)

    $\mu = \bar{x} = 162$

    $\sigma = s \approx 13{,}30$

b)

    $\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}\approx\frac{13{,}30}{\sqrt{6}} \approx 5,43$

`r naechste("lösung")`

a)

    $\sigma _{\bar{x}}=\frac{\sigma}{\sqrt{n}}=\frac{4}{\sqrt{9}}\approx1{,}33$

b)

    $\frac{\mathit{KIB}}{2}=z_{(1-\alpha/2)} \cdot \sigma_{\bar{x}}$

    $\frac{\mathit{KIB}}{2}= z_{97{,}5\%}\cdot \sigma_{\bar{x}}$

    $\frac{\mathit{KIB}}{2}\approx 1{,}96 \cdot 1{,}33 \approx 2{,}61$

    $\mathit{KIB}=5{,}22$

c)

    $\frac{\mathit{KIB}}{2}=z_{(1-\alpha/2)} \cdot \sigma_{\bar{x}}$

    $z_{(1-\alpha/2)} = \frac{\mathit{KIB}}{2 \cdot \sigma_{\bar{x}}}\approx\frac{1}{2 \cdot 1{,}33}\approx0{,}38$

    $1-\frac{\alpha}{2} \approx 0{,}648$

    $-\frac{\alpha}{2} \approx 0{,}648 - 1$

    $\frac{\alpha}{2} \approx 0{,}352$

    $\alpha \approx 0{,}704$

    Das Konfidenzniveau beträgt ca. 29,6%.

d)

    $\frac{\mathit{KIB}}{2} = z_{(1-\alpha/2)} \cdot \sigma_{\bar{x}}$

    $\sigma_{\bar{x}} = \frac{\mathit{KIB}}{2\cdot z_{95\%}}$

    $\sigma_{\bar{x}} = \frac{2}{2 \cdot z_{95\%}}$

    $\sigma_{\bar{x}} \approx \frac{2}{2 \cdot 1{,}65}$

    $\sigma_{\bar{x}} \approx 0{,}61$

    $\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$

    $n = \big(\frac{\sigma}{\sigma_{\bar{x}}}\big)^2$

    $n \approx \big(\frac{4}{0{,}61}\big)^2\approx43$

`r naechste("lösung")`

#### a)

$\alpha=0{,}1$

$\sigma=\sqrt{\sigma^2}=\sqrt{4096}=64$

$\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}=\frac{64}{\sqrt{40}}\approx10{,}12$

$\frac{\mathit{KIB}}{2}=z_{95\%} \cdot \sigma_{\bar{x}}$

$\frac{\mathit{KIB}}{2}\approx 1{,}65 \cdot 10{,}12\approx16{,}70$

$\textrm{Untergrenze} = \bar{x} - \frac{\mathit{KIB}}{2} \approx 2650 - 16{,}70 = 2633{,}30$

$\textrm{Obergrenze} = \bar{x} + \frac{\mathit{KIB}}{2} \approx 2650 + 16{,}70 = 2666{,}70$

#### b)

$\mathit{KIB}=20$

$\frac{\mathit{KIB}}{2}=z_{(1-\alpha/2)} \cdot \sigma_{\bar{x}}$

$z_{(1-\alpha/2)}=\frac{\mathit{KIB}}{2\cdot \sigma_{\bar{x}}}$

$z_{(1-\alpha/2)}=\frac{20}{2 \cdot 10{,}12}\approx0{,}99$

$1-\frac{\alpha}{2}\approx0{,}8389$

$\alpha\approx 0{,}3222$

Das Konfidenzniveau beträgt ca. 67,78%.

`r naechste("lösung")`

#### a)

```{r}
data <- c(116.5, 94.5, 101.5, 109.0, 125.0, 112.5, 100.5)
mean <- get_mean(data)
tribble(
  ~Schritt, ~Lösung,
  "Formel", mean$formel,
  "Einsetzen", mean$einsetzen,
  "Ergebnis", mean$ergebnis
) %>% tabelle(hold = T)
```

#### b)

```{r}
sf <- get_stderr(data, sigma=11.5)
tribble(
  ~Schritt, ~Lösung,
  "Formel", sf$formel,
  "Einsetzen", sf$einsetzen,
  "Ergebnis", sf$ergebnis
) %>% tabelle(hold = T)
```

#### c)

```{r}
kib2 <- get_intervall(stderr=sf$raw, alpha = 0.05)
tribble(
  ~Schritt, ~Lösung,
  "Formel", kib2$formel,
  "Einsetzen", kib2$einsetzen,
  "Ergebnis", kib2$ergebnis,
  "Antwortsatz", "Die tatsächliche durchschnittliche Lieferzeit liegt mit 95%s Wahrscheinlichkeit zwischen %s und %s Tagen (%s $\\pm$ %s)." %>%
    sprintf(percent(), mean$raw-kib2$raw, mean$raw+kib2$raw, mean$raw, kib2$raw)
) %>% tabelle(hold = T)
```

#### d)

```{r}
sf <- get_intervall(kib2=kib2$raw, alpha=0.01)
n <- get_stderr(sigma=11.5, stderr=sf$raw)
tribble(
  ~Schritt, ~Lösung,
  "Standardfehler: Formel", sf$formel,
  "Standardfehler: Umformen", sf$umformen,
  "Standardfehler: Einsetzen", sf$einsetzen,
  "Standardfehler: Ergebnis", sf$ergebnis,
  "$n$: Formel", n$formel,
  "$n$: Umformen", n$umformen,
  "$n$: Einsetzen", n$einsetzen,
  "$n$: Ergebnis", n$ergebnis,
  "Antwortsatz", "Es müssten %s zusätzliche Messungen  vorgenommen werden (%s insgesamt)." %>%
    sprintf(ceiling(n$raw)-7, ceiling(n$raw))
) %>% tabelle(hold = T)
```

<!--chapter:end:04_Loesungen.Rmd-->

## Sitzung 5 {-}

`r naechste("lösung", T)`

a) Ob die Grundgesamtheit normalverteilt ist oder nicht, ist nicht bekannt. (Vermutlich ist das sogar nicht der Fall.) Deshalb muss die Stichprobengröße mindestens 30 betragen.

b) $H_0 : \mu = 2{,}30$

    $H_1 : \mu \neq 2{,}30$

c) $z \leq -1{,}96$ und $z \geq 1{,}96$

d) $z=\sqrt{n}\cdot\frac{\bar{x}-\mu}{\sigma}$

    $z=\sqrt{40}\cdot\frac{1{,}82-2{,}30}{1{,}42}\approx-2{,}14$

e) Der $z$-Wert ist mit -2,14 kleiner als der kritische Wert -1,96 und damit im Ablehnungsbereich. Die Nullhypothese kann verworfen werden. Die Vermutung, dass sich die Frankfurter Haushaltsgröße vom europäischen Durchschnitt unterscheidet, ist damit bestätigt.

`r naechste("lösung") #2`

a)  -4,604
a)  -3,579
a)  -2,365
a)  -1,771
a)  2,201
a)  2,353
a)  3,707
a)  3,686
a)  3,365
a)  -2,528

`r naechste("lösung") #3`

1. Voraussetzungen prüfen (Test wählen):

    $z$-Test, da $\sigma$ bekannt

2. Hypothesen formulieren:

    $H_0 : \mu = 61{,}5$

    $H_1 : \mu < 61{,}5$

3. Signifikanzniveau entscheiden:

    Signifikanzniveau z.B. $\alpha=0,05$, weil ein zu großes $\alpha$ hier nicht in besonderer Weise problematisch ist.

4. Kritischen Wert bestimmen:

    $z \leq -1{,}65$

5. Prüfgröße berechnen:

    Zunächst muss $\bar{x} = 57{,}75$ berechnet werden (s. Sitzung 2)

    $z=\sqrt{n}\cdot\frac{\bar{x}-\mu}{\sigma}$

    $z\approx\sqrt{4}\cdot\frac{57{,}75-61{,}5}{10{,}3}\approx-0{,}73$

6. Nullhypothese ablehnen oder beibehalten:

    Der kritsche Wert wurde nicht erreicht. Die Nullhypothese muss beibehalten werden, eine systematisch schlechtere Prüfungsleistung von berufstätigen Studierenden ließ sich hier nicht bestätigen.

`r naechste("lösung") #4`

a) Es geht um den Vergleich des Mittelwerts einer Stichprobe mit dem Mittelwert der Grundgesamtheit bei unbekanntem $\sigma$,s deshalb 1-Stichproben-$t$-Test.

b) Gerichtete Alternativhypothese nach unten:

    \[\begin{aligned}
    H_0: \mu=3042,43\\
    H_1: \mu < 3042,43
    \end{aligned}\] 

c) Stichprobengröße 6, also 5 Freiheitsgrade:

    \[\begin{aligned}
    t &\leq t_{5;1\%}\\
    t &\leq -3,365
    \end{aligned}\] 

`r naechste("lösung") #5`

a) Wir berechnen zunächst die Parameter der Stichprobe (s. Sitzung 2):

    \[\begin{aligned}
    \bar{x}&\approx2964,50\\
    s&\approx 51,93
    \end{aligned}\] 

    Und setzen anschließend ein:

    \[\begin{aligned}
    t &= \sqrt{n}\cdot\frac{\bar{x}-\mu_0}{s}\\[5pt]
    &=\sqrt{6}\cdot\frac{2964,50-3042,43}{51,93}\\
    &\approx-3,676
    \end{aligned}\]

b) Der kritische Wert wurde unterschritten, die Nullhypothese wird abgelehnt. Wir haben gezeigt, dass in diesem Betrieb Angestellte mit Migrationshintergrund schlechter bezahlt werden ($\alpha=0,01$).

`r naechste("lösung") #6`

```{r cache = F}
set.seed(134323)
rnorm(5, 10, sqrt(5.2)) %>%
  round(2) -> preise
mittel <- get_mean(preise)
sigma <- get_sd(pop = T, variance = 5.2)
z <- get_z_test(preise, mu = 11.8, sigma = sigma$raw, mode = "abwärts")

tribble(
  ~Schritt, ~Lösung,
  "Test wählen", "Varianz bekannt, deshalb $z$-Test",
  "Nullhypothese", z$nullhypothese,
  "Alternativhypothese", z$alternativhypothese,
  "Signifikanzniveau", z$alpha,
  "Ablehnungsbereich", z$ablehnungsbereich$formel,
  "Ablehnungsbereich", z$ablehnungsbereich$einsetzen,
  "Ablehnungsbereich", z$ablehnungsbereich$ergebnis,
  "Mittel: Formel", mittel$formel,
  "Mittel: Einsetzen", mittel$einsetzen,
  "Mittel: Ergebnis", mittel$ergebnis,
  "Standardabweichung", sigma$quick,
  "Prüfgröße: Formel", z$formel,
  "Prüfgröße: Einsetzen", z$einsetzen,
  "Prüfgröße: Ergebnis", z$ergebnis,
  "Interpretieren", "Der Ablehnungsbereich wurde nicht erreicht.",
  "Interpretieren", "Die Nullhypothese muss beibehalten werden.",
  "Interpretieren", "Die Behauptung, im Neubaugebiet seien die Mietpreise günstiger, konnte nicht bestätigt werden.",
) %>% tabelle(hold = T)
```
`r naechste("lösung") #7`

```{r}
data <- ex_05_7$`Ertrag in t/ha`
mu0 <- 69
barx <- get_mean(data)
var <- get_var(data)
s <- get_sd(data)
t <- get_t1_test(barx = barx$raw,
                 s = s$raw,
                 n = 6,
                 mu = mu0,
                 mode = "ungerichtet")
tribble(
  ~Schritt,                            ~Lösung,
  "Test wählen",                       t$wählen,
  "Nullhypothese",                     t$nullhypothese,
  "Alternativhypothese",               t$alternativhypothese,
  "Signifikanzniveau",                 t$alpha,
  "Freiheitsgrade",                    t$df,
  "Ablehnungsbereich: Formel",         t$ablehnungsbereich$formel,
  "Ablehnungsbereich: Einsetzen",      t$ablehnungsbereich$einsetzen,
  "Ablehnungsbereich: Ergebnis",       t$ablehnungsbereich$ergebnis,
  "Mittel: Formel",                    barx$formel,
  "Mittel: Einsetzen",                 barx$einsetzen,
  "Mittel: Ergebnis",                  barx$ergebnis,
  "Varianz: Formel",                   var$formel,
  "Varianz: Einsetzen",                var$einsetzen,
  "Varianz: Ergebnis",                 var$ergebnis,
  "Standardabweichung",                s$quick,
  "Prüfgröße: Formel",                 t$formel,
  "Prüfgröße: Einsetzen",              t$einsetzen,
  "Prüfgröße: Ergebnis",               t$ergebnis,
  "Interpretieren: Ablehnungsbereich", t$interpretieren$ablehnungsbereich,
  "Interpretieren: Hypothese",         t$interpretieren$hypothese,
  "Interpretieren: Inhalt",
  ifelse(t$test,
         "Der Ertrag mit dem neuen Düngemittel ist signifikant %s als ohne ($\\alpha=0{,}05$)." %>%
           sprintf(ifelse(barx$raw > mu0, "höher", "niedriger")),
         "Der Ertrag weicht nicht signifikant ab ($\\alpha=0{,}05$)."),
) %>% tabelle(hold = T)
```

<!--chapter:end:05_Loesungen.Rmd-->

# Quellenverzeichnis {-}

<!--chapter:end:Quellen.Rmd-->

